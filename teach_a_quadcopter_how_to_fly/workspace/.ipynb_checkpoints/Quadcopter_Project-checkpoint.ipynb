{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Train a Quadcopter How to Fly\n",
    "\n",
    "Design an agent to fly a quadcopter, and then train it using a reinforcement learning algorithm of your choice! \n",
    "\n",
    "Try to apply the techniques you have learnt, but also feel free to come up with innovative ideas and test them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Take a look at the files in the directory to better understand the structure of the project. \n",
    "\n",
    "- `task.py`: Define your task (environment) in this file.\n",
    "- `agents/`: Folder containing reinforcement learning agents.\n",
    "    - `policy_search.py`: A sample agent has been provided here.\n",
    "    - `agent.py`: Develop your agent here.\n",
    "- `physics_sim.py`: This file contains the simulator for the quadcopter.  **DO NOT MODIFY THIS FILE**.\n",
    "\n",
    "For this project, you will define your own task in `task.py`.  Although we have provided a example task to get you started, you are encouraged to change it.  Later in this notebook, you will learn more about how to amend this file.\n",
    "\n",
    "You will also design a reinforcement learning agent in `agent.py` to complete your chosen task.  \n",
    "\n",
    "You are welcome to create any additional files to help you to organize your code.  For instance, you may find it useful to define a `model.py` file defining any needed neural network architectures.\n",
    "\n",
    "## Controlling the Quadcopter\n",
    "\n",
    "We provide a sample agent in the code cell below to show you how to use the sim to control the quadcopter.  This agent is even simpler than the sample agent that you'll examine (in `agents/policy_search.py`) later in this notebook!\n",
    "\n",
    "The agent controls the quadcopter by setting the revolutions per second on each of its four rotors.  The provided agent in the `Basic_Agent` class below always selects a random action for each of the four rotors.  These four speeds are returned by the `act` method as a list of four floating-point numbers.  \n",
    "\n",
    "For this project, the agent that you will implement in `agents/agent.py` will have a far more intelligent method for selecting actions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Basic_Agent():\n",
    "    def __init__(self, task):\n",
    "        self.task = task\n",
    "    \n",
    "    def act(self):\n",
    "        new_thrust = random.gauss(450., 25.)\n",
    "        return [new_thrust + random.gauss(0., 1.) for x in range(4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to have the agent select actions to control the quadcopter.  \n",
    "\n",
    "Feel free to change the provided values of `runtime`, `init_pose`, `init_velocities`, and `init_angle_velocities` below to change the starting conditions of the quadcopter.\n",
    "\n",
    "The `labels` list below annotates statistics that are saved while running the simulation.  All of this information is saved in a text file `data.txt` and stored in the dictionary `results`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "from task import Task\n",
    "\n",
    "# Modify the values below to give the quadcopter a different starting position.\n",
    "runtime = 5.                                     # time limit of the episode\n",
    "init_pose = np.array([0., 0., 10., 0., 0., 0.])  # initial pose\n",
    "init_velocities = np.array([0., 0., 0.])         # initial velocities\n",
    "init_angle_velocities = np.array([0., 0., 0.])   # initial angle velocities\n",
    "file_output = 'data.txt'                         # file name for saved results\n",
    "\n",
    "# Setup\n",
    "task = Task(init_pose, init_velocities, init_angle_velocities, runtime)\n",
    "agent = Basic_Agent(task)\n",
    "done = False\n",
    "labels = ['time', 'x', 'y', 'z', 'phi', 'theta', 'psi', 'x_velocity',\n",
    "          'y_velocity', 'z_velocity', 'phi_velocity', 'theta_velocity',\n",
    "          'psi_velocity', 'rotor_speed1', 'rotor_speed2', 'rotor_speed3', 'rotor_speed4']\n",
    "results = {x : [] for x in labels}\n",
    "\n",
    "# Run the simulation, and save the results.\n",
    "with open(file_output, 'w') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(labels)\n",
    "    while True:\n",
    "        rotor_speeds = agent.act()\n",
    "        _, _, done = task.step(rotor_speeds)\n",
    "        to_write = [task.sim.time] + list(task.sim.pose) + list(task.sim.v) + list(task.sim.angular_v) + list(rotor_speeds)\n",
    "        for ii in range(len(labels)):\n",
    "            results[labels[ii]].append(to_write[ii])\n",
    "        writer.writerow(to_write)\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to visualize how the position of the quadcopter evolved during the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7defe34a8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(results['time'], results['x'], label='x')\n",
    "plt.plot(results['time'], results['y'], label='y')\n",
    "plt.plot(results['time'], results['z'], label='z')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell visualizes the velocity of the quadcopter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7da5b4a20>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['time'], results['x_velocity'], label='x_hat')\n",
    "plt.plot(results['time'], results['y_velocity'], label='y_hat')\n",
    "plt.plot(results['time'], results['z_velocity'], label='z_hat')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can plot the Euler angles (the rotation of the quadcopter over the $x$-, $y$-, and $z$-axes),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7dc5f1ba8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['time'], results['phi'], label='phi')\n",
    "plt.plot(results['time'], results['theta'], label='theta')\n",
    "plt.plot(results['time'], results['psi'], label='psi')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before plotting the velocities (in radians per second) corresponding to each of the Euler angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7da4b2e48>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['time'], results['phi_velocity'], label='phi_velocity')\n",
    "plt.plot(results['time'], results['theta_velocity'], label='theta_velocity')\n",
    "plt.plot(results['time'], results['psi_velocity'], label='psi_velocity')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can use the code cell below to print the agent's choice of actions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzsnXmYHFW5/z+nu6vX6Vkzkz0kAUJCdiCBAIawg2zKJqKy43VFr1cv6L0s+kNFxQ3lulyvgKISRVbBKAHDEvZACIEkkIQsk5nMPj29d1XX+f1xqnt6ZnqbZCYzSerzPDx0qk9Xn+6pfus973nf7yuklNjY2NjYHLg4RnoCNjY2NjbDi23obWxsbA5wbENvY2Njc4BjG3obGxubAxzb0NvY2Ngc4NiG3sbGxuYAxzb0NjY2Ngc4tqG3sbGxOcCxDb2NjY3NAY5rpCcAMGbMGDl16tSRnoaNjY3NfsWaNWvapZT1pcaNCkM/depUXn/99ZGeho2Njc1+hRBieznj7NCNjY2NzQGObehtbGxsDnBsQ29jY2NzgDMqYvQ2e46u6zQ2NpJIJEZ6KjY2g8br9TJp0iQ0TRvpqRzQ2IZ+P6exsZFgMMjUqVMRQoz0dGxsykZKSUdHB42NjUybNm2kp3NAY4du9nMSiQR1dXW2kbfZ7xBCUFdXZ69G9wG2oT8AsI28zf6Kfe3uG2xDb2NjM6p49oP1/H7t0yM9jQMK29Db7DVOp5MFCxYwZ84czjvvPLq7u4uO37ZtG3/84x/3+n2vueYaGhoamDNnzl6fa7Dce++9fOELXyg6pv/nfP3117nhhhuGdV4vvfQS119//bC+x55QzveV4fcP3cw/H7lpmGd0cGEbepu9xufzsXbtWtavX09tbS1333130fF7YugNwxhw7KqrrmLFihV7dY7hpP/nPOaYY7jrrruG9T1XrFjBWWedNazvMdyc+fwWrl0RGelpHFDYht5mSFmyZAm7du0CVFbF1772NebMmcPcuXNZvnw5ADfddBPPP/88CxYs4Mc//jGJRIKrr76auXPnsnDhQv71r38Bygu85JJLOO+88zjjjDMGvNfSpUupra0tOp+rrrqKr3zlK5x88snceOONRKNRrrnmGhYtWsTChQt59NFHATj22GN55513sq9btmwZa9asobOzk4985CPMmzeP4447jnXr1uV9jwcffDD774qKiryfc9WqVZx77rkABc972223cc0117Bs2TKmT5+evTFEo1HOOecc5s+fz5w5c7LfZX+efvppTjvttD7HmpubWbp0aXbV9fzzzwPwz3/+kyVLlnDUUUdxySWXEIko4/raa69x/PHHM3/+fBYvXkw4HC76N7rwwgs566yzOPzww/nP//zP7Pvec889zJgxg5NOOonVq1cX/Tvl4tJNvHrZw23KwE6vPID45uPv8G5Tz5Ce88gJldx63uyyxqbTaZ5++mmuvfZaAB566CHWrl3LW2+9RXt7O4sWLWLp0qXccccd3Hnnnfztb38D4Ic//CEAb7/9Nhs3buSMM87gvffeA1QoYt26dSUNejHee+89Vq5cidPp5Bvf+AannHIKv/3tb+nu7mbx4sWcdtppXHbZZfz5z3/mm9/8Js3NzTQ1NXH00UfzxS9+kYULF/LII4/wzDPPcMUVV7B27dqy3rf/51y1alX2uVtvvbXgeTdu3Mi//vUvwuEwRxxxBJ/97GdZsWIFEyZM4IknngAgFAoNeL/29nY0TaOqqqrP8T/+8Y+ceeaZ/Nd//RfpdJpYLEZ7ezu33347K1euJBAI8L3vfY8f/ehH3HTTTXzsYx9j+fLlLFq0iJ6eHnw+Hz/96U+B/H+jtWvX8uabb+LxeDjiiCP44he/iMvl4tZbb2XNmjVUVVVx8skns3DhwrK+N5cu0fbt4uuAx/bobfaaeDzOggULqKuro7Ozk9NPPx2AF154gY9//OM4nU7Gjh3LSSedxGuvvTbg9S+88AKf+tSnAJg5cyaHHHJI1oicfvrpe2XkAS655BKcTiegvNg77riDBQsWsGzZMhKJBDt27ODSSy/lL3/5CwB//vOfueSSSwbM7ZRTTqGjoyOvkR0sxc57zjnn4PF4GDNmDA0NDbS0tDB37lxWrlzJjTfeyPPPPz/AmGc+W76Vz6JFi7jnnnu47bbbePvttwkGg7z88su8++67nHDCCSxYsID77ruP7du3s2nTJsaPH8+iRYsAqKysxOVyFf0bnXrqqVRVVeH1ejnyyCPZvn07r7zyCsuWLaO+vh63283HPvaxsr8blyFx65DQU4P7Um0KUpZHL4TYBoSBNGBIKY8RQvwAOA9IAVuAq6WU3db4rwPXWuNvkFL+YxjmbtOPcj3voSYTow+FQpx77rncfffd3HDDDUgpy3p9sXGBQGCv55d7Diklf/3rXzniiCMGjKurq2PdunUsX76cX/3qVwXn1j8l0OVyYZpmdnwqVdpAFTuvx+PJHnM6nRiGwYwZM1izZg1PPvkkX//61znjjDO45ZZb+rz+73//O1/5ylcGnHfp0qU899xzPPHEE3zqU5/ia1/7GjU1NZx++un86U9/6jN23bp1eVMei/2N8s039/MMFpchcZnQ3dPJuLpxe3QOm74MxqM/WUq5QEp5jPXvp4A5Usp5wHvA1wGEEEcClwGzgbOA/xFCOIdwzjajlKqqKu666y7uvPNOdF1n6dKlLF++nHQ6TVtbG8899xyLFy8mGAwSDoezr1u6dCl/+MMfABVm2bFjR15DPBSceeaZ/OxnP8sarjfffDP73GWXXcb3v/99QqEQc+fOHTC3VatWMWbMGCorK/ucc+rUqaxZswaARx99FF1XAeb+nzOXcs6bS1NTE36/n09+8pN89atf5Y033ujzvJSSdevWsWDBggGv3b59Ow0NDVx//fVce+21vPHGGxx33HGsXr2azZs3AxCLxXjvvfeYOXMmTU1N2ZVXOBzGMIxB/42OPfZYVq1aRUdHB7quZ1dL5eCywjY9nc1lv8amOHsco5dS/jPnny8DF1uPLwAekFImgQ+EEJuBxcBLezxLm/2GhQsXMn/+fB544AE++clP8tJLLzF//nyEEHz/+99n3Lhx1NXV4XK5mD9/PldddRWf+9zn+MxnPsPcuXNxuVzce++9fbzEQnz84x9n1apVtLe3M2nSJL75zW9m9wcKcfPNN/PlL3+ZefPmIaVk6tSp2Rj6xRdfzJe+9CVuvvnm7PjbbruNq6++mnnz5uH3+7nvvvsGnPP666/nggsuYPHixZx66qnZFcS8efP6fM7cGHU5583l7bff5mtf+xoOhwNN0/jFL37R5/k1a9awcOHCvF70qlWr+MEPfoCmaVRUVPC73/2O+vp67r33Xj7+8Y+TTCYBuP3225kxYwbLly/ni1/8IvF4HJ/Px8qVKwf9Nxo/fjy33XYbS5YsYfz48Rx11FGk0+minzGD29qIjXS1ljXepjSinOW1EOIDoAuQwK+klL/u9/zjwHIp5f1CiJ8DL0sp77ee+z/g71LKB/ufN8Mxxxwj7cYje8aGDRuYNWvWSE/DZoS5/fbbOeyww7jssstGeiqDpv81/OrCWQTj0PGzmznx9MtHcGajHyHEmpwoS0HK9ehPkFI2CSEagKeEEBullM9Zb/RfgAH8IfPeeV4/4G4ihPg08GmAKVOmlDkNGxubfPz3f//3SE9hSDBNM+vRJ8OdIzuZA4iyYvRSyibr/63Aw6hQDEKIK4FzgU/I3qVBIzA55+WTgKY85/y1lPIYKeUx9fUlWx7a2NgcBIQTMTxWjD4ZLl5hbVM+JQ29ECIghAhmHgNnAOuFEGcBNwLnSyljOS95DLhMCOERQkwDDgdeHfqp29jYHGiEOndnH6diQ1sTcjBTTuhmLPCwtcnjAv4opVxhbbJ6UKEcUHH5z0gp3xFC/Bl4FxXS+byUsrxdGBsbm4OacGdr1vs0YrYMwlBR0tBLKbcC8/McP6zIa74NfHvvpmZjY3OwEeluIZNkasRtQz9U2JWxNjY2o4Z4d+8GrEzER3AmBxa2obfZa0ZCpnjnzp2cfPLJzJo1i9mzZ2e1WPYVtkzx4ChXpjgR7co+NpN256mhwjb0NnvNSMgUu1wufvjDH7JhwwZefvll7r77bt59991BnWO4sWWKB48eyXESrEIum73HNvQ2Q8q+kinOVFuCkhqYNWtW9n1zsWWK9y+Z4lS0N9NGlqEZZFMetkzxgcTfb4Ldbw/tOcfNhbPvKGvoSMkUb9u2jTfffJNjjz027/O2TPH+I1OcjkWzj4Vt6IcM26O32WvyyRRH4ilWPrNq2GWKI5EIF110ET/5yU8KioLZMsX7j0xxOtFbkiN0W5R+qLA9+gOJMj3voSafTPHHzz0bIuVVNu6pTLGu61x00UV84hOf4MILLyzrHLZM8eiWKc7NtHHodvnNUGF79DZDRq5MsUzEOPHoo4dNplhKybXXXsusWbPyGrdC2DLFo1umWFqZNoYDHIZt6IcK26O3GVIyMsUP/e1JPnHOuazduWtYZIpXr17N73//e+bOnZs1bt/5znf48Ic/XPR1tkzxKJcpTqm5xHzg1M3S423KoiyZ4uHGlinec0arTHH3e+vRdAjMnjPSUzkoOFBkiv947YksXN1BSx10VTv56BPrR3h2o5uhlim2sRkUQqr/pJR73FLOpnwOFJlioeuknKBrApcx8k7ogYIdo7cZNgTFN/FsbPrj0NPoGhgugdM29EOGbehthgVh/UbLbR9nYwMqpTLlgrTt0Q8ptqG3GVbMtJ0LbVM+Tt3EcEHa5cg2CbfZe2xDbzMs9Hr09q/VpnychomhgelyoNmXzpBhG3qbYUXaht5mEDgNieESpDWnbeiHENvQ2+w1+WSKMx69aQ78tQ6FTHEikWDx4sXMnz+f2bNnc+utt+7V+QbLbbfdxp133ll0zNq1a3nyySez/37ssce4447hrV7+05/+xLe/Pfp6/pTzfQG4LEMvNWe2SbjN3mMbepu9Jp9MccbQyzybsUMhU+zxeHjmmWd46623WLt2LStWrODll18e1DmGm/6G/vzzz+emm24a1vfc32WKXbok7RJITUMzwDBsaz8U2IbeZkjpL1P8X7d8c1hkioUQWTlgXdfRdT1vvv6yZcv4xje+wUknncRPf/pT2trauOiii1i0aBGLFi1i9erVmKbJ1KlT+zRMOeyww2hpaWH79u2ceuqpzJs3j1NPPZUdO3bkfY9MwV97eztTp04llUpxyy23sHz5chYsWMDy5cv7NN8odN6rrrqKG264geOPP57p06dn5Y8LSQ3nIqVk7dq1WfnmDO+88w6LFy9mwYIFzJs3j/fffx+A+++/P3v83/7t37IZUitWrOCoo45i/vz5nHrqqcDgZZUBvv3tb3PEEUdw2mmnsWnTpgHzzYdmQFpzIN0aLhMikc7SL7IpSVkFU0KIbUAYSAOGlPIYIUQtsByYCmwDLpVSdgn1a/sp8GEgBlwlpXwj33lthpbvvfo9NnZuHNJzzqydyY2LbyxrbK5MsZDw6MqVrF+/fthkitPpNEcffTSbN2/m85//fEGZ4u7ubp599lkALr/8cv793/+dE088kR07dnDmmWeyYcMGLrjgAh5++GGuvvpqXnnlFaZOncrYsWM577zzuOKKK7jyyiv57W9/yw033MAjjzxS8rtwu91861vf4vXXX+fnP/85oG5cGb7whS8UPG9zczMvvPACGzdu5Pzzz+fiiy/OKzXcnzfffDMrN5HLL3/5S770pS/xiU98glQqRTqdZsOGDSxfvpzVq1ejaRqf+9zn+MMf/sDZZ5/N9ddfz3PPPce0adPo7FSGdrCyyuvWreOBBx7gzTffxDAMjjrqKI4++uiS35vLUBuxuN0AdHXsprp6bMnX2RRnMB79yVLKBTnltjcBT0spDweetv4NcDZwuPXfp4FfDDiTTUmklDSGG0d6GmXRX6b41NNOQwAvvvEGF15w/rDJFDudTtauXUtjYyOvvvoq69fnL5fPlchduXIlX/jCF1iwYAHnn38+PT09hMPhrAY7wAMPPJB9zUsvvcTll18OwKc+9SleeOGFPfuS+lHsvB/5yEdwOBwceeSRtLS0APmlhvuzYsUKzj777AHHlyxZwne+8x2+973vsX37dnw+H08//TRr1qxh0aJFLFiwgKeffpqtW7fy8ssvs3TpUqZNmwaQ/e4HK6v8/PPP89GPfhS/309lZSXnn39+Wd+LZoCpORFupaMT62wp63U2xdkbCYQLgGXW4/uAVcCN1vHfSVUS+bIQoloIMV5K2bw3Ez3YePWFP5P46m3w14eYNKk8LZtyPe+hZoBM8c9/zr+ddhoqTF9amGpPZYozVFdXs2zZMlasWMGcOQO1dXLPYZomL730Ej6fr8+YJUuWsHnzZtra2njkkUcKSgrkCw/lyhQnEnvW5zT3vLliYZnvJp/U8BVXXNHnHP/85z/561//OuDcl19+OcceeyxPPPEEZ555Jr/5zW+QUnLllVfy3e9+t8/Yxx57rGyZ4mKyyv0/U7m4dTA1F8LjBSAa6hj0OWwGUq5HL4F/CiHWCCE+bR0bmzHe1v8brOMTgZ05r220jtkMgm2vvkFDCHa+X15sczSQkSn+0Y9+hK7rnHD00Tz86N+GRaa4ra0tG1OPx+OsXLmSmTNnlpzjGWeckQ2lANnwgxCCj370o3zlK19h1qxZ1NXVAXD88cfzwAMPAPCHP/yBE088ccA5c2WKc1sKFpMpLue8ueSTGs4lFAphGEZ23rls3bqV6dOnc8MNN3D++eezbt06Tj31VB588EFaW1sBFYPfvn07S5Ys4dlnn+WDDz7IHofByyovXbqUhx9+mHg8Tjgc5vHHHy/6+QBSKR23DlJz4fT5AYiH7Rj9UFCuR3+ClLJJCNEAPCWEKBYIzncbH+AOWDeMTwNMmTKlzGkcPMStJWuoc/+60BcuXMjcuXP4y4oVfPzcc3lx4/phkSlubm7myiuvJJ1OY5oml156abYfazHuuusuPv/5zzNv3ryszvovf/lLQIV4Fi1a1CeWftddd3HNNdfwgx/8gPr6eu65554B5/zqV7/KpZdeyu9//3tOOeWU7PGTTz45283q61//+oB5lDpvLvmkhnN56qmnBvSKzbB8+XLuv/9+NE1j3Lhx3HLLLdTW1nL77bdzxhlnYJommqZx9913c9xxx/HrX/+aCy+8ENM0aWho4Kmnnhq0rPJRRx3Fxz72MRYsWMAhhxzChz70oaLjAUKhNuV5ujWcPrXRniyzeY1NcQYtUyyEuA2IANcDy6SUzUKI8cAqKeURQohfWY//ZI3flBlX6Jy2TPFA/viFs1i4cjvbvnY5Z197c8Fxo1GmOB6LwNZtAMQq3dRNmTGyEzoIuO6667juuus47rjjRnoqgyZzDW/e+Cb6Ry5n3RmTqZixkOk/f4wtXz6Pcz/z/ZGe4qilXJnikqEbIURACBHMPAbOANYDjwFXWsOuBB61Hj8GXCEUxwEhOz6/B1ixXiMVLzFw9CHNnNx5W71yn/Cb3/xmvzTyuUS61CpWeLy4K1RYSI9GRnJKBwzlhG7GAg9bGysu4I9SyhVCiNeAPwshrgV2AJdY459EpVZuRqVXXj3ksz4IEEnVd9RM7n+G3jTTOK3Hwjb0NmUSD7XjARweH54K1fw8HY+O7KQOEEoaeinlVmB+nuMdwKl5jkvg80Myu4MYR0pVBKZTe5bFMZJIMyfTxjb0NmWS6OkCwOnz46tUm8rpxMB6AZvBY1fGjlKcKZWilrZ6aO5P2IbeZk9IRJShd/kq8FeOAUDuhyva0Yht6EcprpSKc8v90tDnxuhHbh42+xd6rAcALRCkoroeADOVGskpHTDYhn6U4tKVV2zq+9+FLmWvR2/H6G3KxbA2Xj0VVVSNmaAOJvs6OumeHlrvvBNp3wAGhW3oRymaZejZDwx9f5niUFdO7nMeOz8UMsUZ0uk0CxcuLCuHfiixZYoHRznfVzquDL03WEOwSkkvCL2veuV7f19Ox2/+j6a1Lw3PRA9QbEM/StEs+y73sbTuntBfpvh/f3tv9jkxRIa+kMTwT3/607LrCGyZ4r1DSomZR0xtqDATKh7vq6rDqblIuUCk+v7Ntn+gKpl3Nb03bPM4ELEN/SjFrSsLKfX9S497yZIlNO/eDYCJ5Obv3TksMsUAjY2NPPHEE1x33XUF52PLFA+hTPF55zF/wQKOW7x4WGSKzaTKMKuoVhk3KRc49L79DCKN2wDo2Gkb+sGwN6Jm+zX3PLia5qZ2vnHDBSM9lbxkuuuIQXihu7/zHZIbhlam2DNrJuO+8Y2yxmZkii/9yDkAPLJyJes3bhw2meIvf/nLfP/73y+oJ5PBlikeGpniOTNn8cAdd/Cv9zcPj0yxlUocrBkPgO4CYfRrXGPF8fVo8b+5TV8OWo++6o+/YfEffjLS0yiIJxOa3w9CN/1lipd96AQAXnzzDS7+8IeHRab4b3/7Gw0NDWVpnNsyxUMjU3zZeR8GYOmio4dHpjipvJuqunEAGBo49b7qp46oCu8YdsXsoDhoPfq6SBNV8dEpgZqMR3FbjozI04qvEOV63kNNf5ni39z7O7584ccwy0y42ROZ4tWrV/PYY4/x5JNPkkgk6Onp4ZOf/CT3339/0XPYMsV7LlMsrbZ+mdz2oZYpFrqO4QBvQFXFGk5wGH0NvTNhVYzbFbOD4qD16CtTu3GnUsTjoy9PvTtXg7v/0nUUk5EpvvtX/4eu6xy/+Gge+vuKYZEp/u53v0tjYyPbtm3jgQce4JRTTslr5PtjyxTvuUzxXx5VUsPPv/jisMgUO1IGKa3337omcBl9nQB3XP0eMhu3NuVx0Hr03dJgHIKulg58UyeM9HT60NW2O/t4MB79aGDhwoXMnjWTv6xYwUcvOo/X33hrWGSK9xRbpnjPZIpvvfVWrrzkYhZfeCFen4/7fv/7ovPdE5lih5EmlWOR0i6Bs7+hT1i/h+Toc9BGM4OWKR4ORkKm+NkTjqShQyL+7z5mnrB4n753KV5d9TDBz6gwzPp5fi7585qCY0ejTHHH9vfwh1PEvQJPUhKYPbDrk83QMtwyxaZhkNy4EVOAQ4L3yCMRjqEJCGSu4Yc+Mp8xu1MsfXkDAI+fPQdvNM3pz23Ijl29eBa1PbB+cS2X/G71kLz//syQyRQfqGSWhNGdW/bdm5omNL9VclikozX7WKRLt+IbdWScB4fI24XGZugZbpli3QpxJlTPblKJofeonYaJ0cejd+Dql4vgs7ZARGr/SjseaQ5aQ69Z10lP8/v77k03PQG/WgodxW8uie627GNHeuRXXIPHmrMQCFl8s9Wml654mNbI6OwollGRjFuGXo8NfdaLUzcxXL2uQVpzoOUYetMw8FnZaA599GejjSYOWkOf8RQS7Y377D1ly7skul0QKv6eqZ7eH3s5Hv1oM6RCSiQgHepHa6btH2UpTCnRm3fgam7ao9fHjTiGOXzfc9rKtDE9qtOAkRiarJfca9dlyD4evely9jH0Uau9JoBT37/2rkaag9LQSymzF5ARais+eAh555nn+GBFA7s3FA/f6FGVn5x0lfbovV4vHR0do8vYS5ACsNLr0rahL0ln+26CMYlHH/yNW0rJttA2OhPDtxqQqSSmAK9f5e9Lfe9DN1JKOjo68Hq9ADgNMLRej97U+hr6rqbN2cf98+ttinNQZt2kEilc1nUiw6F99r47tjUyDdi46W3GnVN4XNqq+ot7Sxv6SZMm0djYSFvbvrthlSLa1qy8s24X7oQBaR3N7R3paY1apJQkWptxWU6qQ4LT4Sz+ohxMabI7upuQFqLDMzy1IYmWZqSUOE2DXW0dmE6BP7H3xtbr9TJp0iRAefSmq/dzS03DrauQjcPloq1xM37ruUKGPrFxI9rEiTjzFJQdzByUhj4e7S0fd0T3XeGFozMJCGKdxY2yGVfzS3jBWcLQa5qWrWIcLfzllk8waWucHafPZN4jG0n+6jvMOumjIz2tUctDP/oZs379P+wcC5NbIHrPDzhmSflqnC3RFi578DKOrj2de8/70bDM8aVrLmVTfZpzlz/H6v+4nEAKjl717pC+h6arDdgMUtNwSohH2glUj6Nn9078QMwDLn3g70JKyeaPX4b7Yx9hxk23Denc9ncOytBNItTrxTtj+ygfN9GDz9LM0kPdJcaqeGjSA45yy0tHEY60JO0E4VHVp4lw1wjPaPQSj8YY96f/ZXs9hI9TGi9tOzaUeFVfOmLqekp1DO515SKlJBA26KyCOm8diWoPlT2S5BAX82mG2oDN4lY7vz1WbD7W3gxAqAI0Y+DvwkwmccaTfPCunXbZn4PS0Mc627OPtcS+iR/Lji1Ud1ubk5HiUq8ikcRwqHilYz/ccxJpk7QTnF5l6JORfRce29947rt3URPWef0kJ7WHLQUg0rxtUOdoDbVx6XNpxu0cnhh9rLUdzYB4pUvJGoypIRiDLRvfLvscL25p569riichaAZIrTfIIKyiuZ4ulW6c6lafL1LRmzWXS7RLrZRFU8vAJw9yyjb0QginEOJNIcTfrH+fKoR4QwixVgjxghDiMOu4RwixXAixWQjxihBi6vBMfc+JWRuwJuBJ7BtL2rruJdzWPcURLb6KcCR1km4wnQLnfrjnlPHonV4VUU3FbKXBfESadtPw6B9Yc5jgxGXnUjdZFb4l23eXeGVf2jsbuXi15IhNw9NIftcGlQ5s1Ki/Z8WU6QC899qTBV/Tnzv/sYkfPVVYWtg0TRWPd+dEkz1qXyf7e+1RDkM84Mxr6LvbdgIQCNub//0ZjEf/JSB3bfgL4BNSygXAH4GMCtS1QJeU8jDgx8D3hmKiQ0k8pDz6riB495Fkxta3Xs4+dsaLX4jOlE5Sg7TTUTJGPxpxpE3SDtB8SkwsZUvKDiAdifLOldfhkAb/OEnyoeNvZOIRCwEwQ4MLdUXblKespYbHK+i2PHetQfVxnTL3eABCVhOQUoQTOm81hogXSYmMRcI4JaD1it04ferGEu9R34eMxki5IO1zZ52mPvNsVYY+GJGjKwttFFCWoRdCTALOAX6Tc1gQ57UpAAAgAElEQVQCGVWjKiCTAHwBcJ/1+EHgVDFYGbthJh5WmQkdQVVpty8uitCObQA01YIWL/6DdOhpdA2kU+DcD0M3DhNMJ7j96vJID1HO9d4gpeTKv1/Jig9WjPRUkKkUmz/zOQKNW/nhRx0smzoLp7+GmknTMAWIyOC+r1iHWgG4hinlMLF5PQDVU9Sm/+GLlRSy0VpeDcorWzuZ3LWLGTveKTgmlFnFWHF5AKdXOQrxsNqDcMQSxDwgNbdKQzX7ft6w9T1oaUh2jJ4stNFAuR79T4D/REU7MlwHPCmEaAQ+BWSaYU4EdgJIKQ0gBAyQ1BNCfFoI8boQ4vV9nRqoR1W3+UhQ4JQQbWke9vc0W7sJe6GrxoUnXvzG4kqZ+7ehT0tMh0ALKENvJIav/Vy5xIwYb7S+wdq28rzQ4UKaJk1f/wbm669y31nQNFVy0QlqMezQNKJecEUHF4JJWWqn7tTwOCx601YiXphyyFwAPGPGkXCD1l3eSm31lna+8NZDfHrNg5gFkgvCXZahzxGzc1k5+5m6EldCJ+4FPOpmkAz39DlHvKt3761t87qy5nawUNLQCyHOBVqllP2Vtf4d+LCUchJwD5DJ68rnvQ/460opfy2lPEZKeUx9ff0gp7136FHlIcQrVDywdUthT2Oo8HTptNQKUn4PvoQAo3DTb0030d0C6XDslzF6Z1piOsEfrAZGh6Rsh9V7IJQc2Y3h1h/cSc8TT/DgSYI35sBvj/sm1RN6W//F/OCODS7GbFoe73AZemdnG61VMLFhNqAknXsqHfh6ypvnunUfcGTnNmrSPSSN/Bd0tFsZaYent94i4yjoVpMRLZEm6SFr6Ls7+lYRJ3MqyhvfHdjg5mCmHI/+BOB8IcQ24AHgFCHEE8B8KeUr1pjlwPHW40ZgMoAQwoUK64wqAQ/DalpgVKkY4GDT2QZNKkZll6S7zoMe8OKPg4wVLmzRdImhCUynI1tEsz+hQjcCb7AGADM1PJuEgyFTNbp7BLVkZCpFx7338uJseGYR/O+HfsiU2Zf0GZP0OfGWCO0NOG9EGUKPDmlz6C8YbyhKW5VgfPX07LFkjY+qHmjtzrmOu3cMcGDawknGvP0qAnCkdWKp/DeHeI86TyZTC8BToRyFjNyCO2GS8joQ1s0g1L6rzzn0nOyurm2le9QeTJQ09FLKr0spJ0kppwKXAc+g4vBVQogZ1rDT6d2ofQy40np8MfCMHGU7I2nL0AurSUN49wfD+n7RLWupiAli9TWYFUFcJkRyyrn7o+lS5RM7Hftl6EZ59AJ/lfp+ZWrktcNbwq18516D8f9aP2JzSDU1IaRk82TBrUf9iOkzBrb9S/ld+AcZ6RJxtWLyJpXmzVAipcQfNuiognpf78rb0dBAfQhe36gauXe8+yzGTxaw8f5/7/P6F7e0c/JuJUHuNiCayK86mbRqLRw+f/aYt1K1MTSsAkJvQpLyOLJjwv0KD9M57QVTLXumGXSgskd59Fbs/Xrgr0KIt1Ax+q9ZT/8fUCeE2Ax8BbhpKCY6lGRCCb7xU4DezazhYusrzwAgpkxDVCkvt+mDwlWF7pQqHJEu5/7p0afBdAiCVZZh0EdeUrZx5/sc1gyTG0cuA6h9kwonjK08lGVHnZV3jBHwUBEHPV04tNcfpyUh7EtBJFV6IzcdCiHL/Jt0NbWgGRCrdPWRZaiePguvDts2PU9P6w5SD17BU61B4hufJJLTte2Vd3Yyu21btqFIokANSabWQgv0Shf4Ki1HIalWhL4kGB6td5M21NrnHKbVMD3kB0dniaLEg4xBGXop5Sop5bnW44ellHOllPOllMuklFut4wkp5SVSysOklIszx0cVlhLfmEPnAWCEhnc5v3uT2gCsm3ssmtX4uKOx8CrCk8kndjpwStBHgUc8GFxpFboJ1jSoA6nyjdZw0bND5XDvq7qJfOx6V3m2wUmHFRxjVgSpSEBTc/mhB5flJftS0BnvKTrWTKdZc8qJPHnHjWWduymTQ1/bt8fu1KNPAiC8411W3XchPw/5mfqMn85XPKx8UvWtlVISef4FXGnJmsPU1l2sO78BNmJq3m5/VfZYsEZVCstkElPX8aVUaqXLit0nevqmoYpEAsMBnVXg7hn5cOFo4qCsjJWpFCYwbdaxpAXI8PB2lNd37cJwwLxFp+MfewgAkbb8S0vTNPGkQLpdSJdygxKjIGtlMDhNkE4HPl8FaQEYI1/AkmpR8VxvQmLKkdnh7tmhjGbNtAUFxzirVbii8f3SDWoyuFLq5uXVoaureFVo285tBKMGoQ3lbVb2bFDZK5kc+gzBw9XGbEtoFz9xx7lwpSAR0JjQLIj989eEEzo7OmPM2fIyPT54Z6p6XaLA/DL7Zp7K6uyxSstRkKkkkdbt6rHPj7tC3QxS/SquRSJJwg2xgMBvF0314aA09CKVIqXB+JrxRH0gYsObFeJsj7C7FqaPmULtFNX0OtmVfzM2Eu7GAUiPG5xqqRzbzwqOnGmVGiqEIKWNkiYRHer7DsYlEX14b+yFMFpb6PHB9MMKt670jFErvq4d5Xv07mTvjav/BmV/tryj8ic8ZTYOSX2gtt4yOfQZtIkT1fFuuPlxjYDLz9QHHqCpTjDtrd38/rmNvLhxN8e0bGTN4YLp3goAYl35U5kzQn7+YG32WIV10yOl07HT+j4CFdlNfr3f7yJTUZ6o0KiIDN+2oIxHCP3PNwbk8Y9mDlJDr5Nygc9XQ8wLrvjwxpADXQYdNU6cDifjpqr9a6Mn/xK70/L0hceDcKkqwfh+phWjDL3VoMIJYojFr/YEV48ybBXxkUuxdHZF6KiEIyYeXnBMYLwyqJEyi5EA3MleoxbrKO7Rt7+nwojlajylm7cS9sLkKX37/jq8XmSln4teFYxrTDL+lpupOfxIWi6cR3W3IHX/d9j4j2fxpdJsP1QyvlZ95kRPe763wbTCqf7q3pIbn9ulejLoBu1NKtTpqKzBXzNGzS3e92blTKVJaWBU+vGlwAgNz9859Je7abrrYRKrHhqW8w8HB6ehNwySGridHhI+gRYfPkOUjoapDkkidSrGeci4ySRdQCT/KiJk/cCFzw9uy9BH9y9D7zIBp7q0dBc4CuRO70s8YbXPUZGAnmTxOPZw4Q2lCFcIfO7C6uD1U48EIFVCyrrPeXMNfYlGOoldymDmrgKK4exsp60aJow5csBz/sNm4kiZVJ5zDpXnnw/A6dfdycbJcOLbb1H/8t9JaHDozMloFVZOfDj/flhmw7WiZmz2WGZFKPQ0YUvewF1dT8AaY8b7/oZcepqUG8watRJo2vBqWZ9xsGxq3gjABztLF2UlNm5k0zGL0FtGVmjtoDT0Tt1Ad6kLKel14kkM3zJv16vP4jQFxjgV4/RqGhE/OGP5NygzZdxOXwBhxeiTkZExTHuCkTZxGSCtBhLGKDH0vpi6mVckoD3cWmL08FARNokFizcUmXC4it/LnvJu7gkjgS8JaeuXrPeU0MlpV5/dW6ah782hH9jzwDt7NtqUKYy79RYyKif1VZNoOqOeQFxy6o71vDVNcNaRF+HL5MRHC8zP2rCvspIVMhguJQkSsyQNfHUTqaq1Nmn7FeK5UiaGJvCMVY1MGt95heGgq1PdrNrLSOGMbt6KGYmQ3L5jWOZSLgeloXfoJrrlVKV8Gr5hDNFve30VAIFDZ2aPxYqsIuKWR+YMVCAsgadUfP+J0ScSCXVRWR694Rxo6Nc3t3DWb7/HppZ9o1OvmzoV0d6beVvjvk8ES/f04E1BMugrOi7YMIa0A0QJKesMrdEQgQQkKpShNUqE+bSQupY8ZSRymaaJP2LQXgljA2MHPD/26zcx/fHHcFZW9jl+/hn/xksz1XyapqeZMvsSfFZacTqa32kRKZ20gGBl301ftSJMo1sSxZXjp1Fdr/YHSPb9EO4U6G5B1VSlAhra/n7pD7kHJMJq4zjcUTpbb/OWbQB8sHXnsMylXA5KQ+80TAxLJC/t8xJIgJEYng268Fa1mTXtmJOzx+JeB+4C1Y8J64J2V1TjcCndj1R8ZDYP94SYlT2R0RU3XAJnvyYRT774MOevuI9//81/0hoe/jS4rkQX1RGJtJQ4epq3D/t79idmyWykq6uLjnM4nUR94IqVt2/U3NWCPwl6UMkCmNHi14qvR3nO/jLE/KKhCJoBqYATzaENeF44HDhytGkyTJ59CTtPSPPUQsHUWfXgryVgxd7NAtey0JViq8vZ930MFzgNSdpa1dZNmkVlRQ1Jl7o55KIqyh0cMvcEAJKt5WtY6U3riX3vCGS4dE2NTKhr1ihjpd3TolJqe3b2V5DZtxy8ht5lNQGpqEBLQ/fu4ZFBEC2tdFbAnJknZo+pMvf84/WI8nK9VXUIt/oR6fGRV38sl3iPypMWTmXo03kanPvfeZeT10m+9ecXuP2b3yKSHN6snLZIGzURSFaqv3m8bXgL5PLR+M6LADjqx5ccG/cJPGXq3XR07lShm+qA9eLiK4GKiFpJutMQ6inukXbtsr6nwEBjXhSXmyumH8+GpSnOnqVi9/5M8VyBVGFHSim29kd3CRyGRETjJF0wbtwhvbH7fobenYK028WMQ+bR4wPRVX7R1GvPPs6/XjXZuK50uEdYKwkzWnrVFU2oFVZPgWyjfcVBaehdusTI7IdZqVot24dO2CzXU/J1xmipFVT7arLHUgEP/jiQHui1ZRqDB2rqcWqWR5/cf/LoE1bhC1bGUNrpwNXPozetm0E46OKzf3uY33/2RpIFNFCGgu1N7xFMQMoq+jG68md+DCdtm9X1VXHIrJJjE34nvlh5+0Y9rTtxAKLeylZJFF4hSdOkMgIxSwm4eWfx0EakUa18XBWVRcflY9riz/KLCNTMvRQAf40Ve0/m93AcejpbPZtL2iVw6RJHPEnMC1V+NfmUBs5++vbelCo09Lg9hILg7ik/Jtv01ktMf8fF9vUvlxwrrIwlES8d/8psMhsjnFBxcBp6Q5K2PHqXVX3XvnPLkJz7jdv+m3dnz2btUcfwypKTqG816anpuwFnBHx4dTA6B97lTSu/ubJ2PC6r5+po0HMvl0TE8ui1jEcvcPaz4Z4etSHY8OlZPDfHwbIXn+Qf135p2ObUtlXp25jjVZxZhksvuR9/809s7xy6WH68qZG0gHEzlpQcm/JrSviuDImoWIe6hpxjJwDgSBauQu7YuQ0tDW0qO5H2xuLXfNzay/DW1BYdl5fJi+Frm6FmKgC+qrGYgKNAlbfD6N03yyXtErgMiTNukPCAKzebK8fQG/E4LhNMS9kyEnDgjZSfTZe2+jjrZfQ3dlgFao4Cuj25SGuTWcZG9jd8kBr63ibEvnqldxNuLV5oUi67XvgH7UHJqpkxNozr4K3p0HxUv42soKrsa/1gYM/NjA5PVf0EnFb8M13ESxttJKy2gZkaANM1UFPfGw0Rd8PsxtW4jg/x0kzBhPXPDducYru2AeCzqjlLNfaIxEM0XPMtXvnJfw3ZHGRHF51BOHLa/JJj0wEfwRhE46VXHimrn6p//CRMIXEmCxufrW89D0C4TlnUnpbiexWx5m0ABMaMKzquHPz+OpJuVayYD6dhks5r6B24DNCSaRLeXgV0XVOvydDTbmXAeNVvJh4cXNFUZvNbL7BZnEumEtlVhpyG0C1DXyKkNtwctIbetDz6yomqgCk2iLzlYtR2x9g8uYLaZT7WnB7nfy/1M/ejn+0zxmltTLVsH9hDUySSmEBN/SRcHqXSlx4FMr/lktk4FlanoLTLgdbPo9fiSRIeCV9+m6vOuptEjSAQNzCKeKN7g251Lxpz1ImYQuKKFV9yb9/0GpVx0DZuG7I5uEIJuoMwoaqq5FgZrMKfgqbG0vtGhuWBVo6dSMotcBYJgXW8r/K+jXEqjBjvKB43TnYq41k1fmrJeZTCqwVIaiq1OR8uQ6JrA1tZpDVl6D0Jk5Sn11wZmgrpZOjarW5awqdWwalKPxVxSJXYh8i+v5XunC6jYthpva+WLONGYonHORIjq1d1UBp6twGmleddf4gqBDHKzFsuhp6IUxsxqfN1cUVPmJ+d9gtWXbGGc2dc1Gecp14ts7vzZH84kimSbvAFatG8+5+h1y1Dn9lfMPMocHoTBkkv4KvBeeQFeCw549YPhifXWFhCWrWzFpD0grtEJXSLlX8daA4NWZtJf9ggUuGgnK6aDqvys2nLwBVff0zLA62bMI2U1utt5iPetE3NZbqS4Uh1F+6JAGB2t6M7YdyEQ0vOoxSl5DCcem84tc8cXE40AzwJ0D29IVDDJbIGF6C7LVNoqKQWZK1VNPVWebn0mrX53b8IK+9Yq8GLuwxDL6zP6yiy0toXHHSGXpommgGmpi6amnENmIAsUKk6GDa/o8rLXZUe+NzLMOOMvOMqrDL3WPvA7A9HSielAQ5Htrm2uR+pVxpJFRZxuHsNvdbvGvck0qQ8Aiyj57L6AjRteKPk+Zu642zaPbi6Aq0nhgn4Jk4i6RV4SjT26HnnTQDGdkmaw3uvay5Nk2AEYkF36cGA18oT795VuGdBBmFJ83oaJqG7VdFQwXl0tKE74dCj1XWZDpdwbsI99PihvnZgsdSekG8DNYNmyGwmXC5pTRl6fwJ0b29ajqE50HI2+aOdqvI0U4HrHq+Kppo2lSfe5s209ywjTJq5nn1l/Cwz8h+uYc4sK8VBZ+iNuPpDSqsMvabCR9wLjhLL+XLY8q4yVJ6xE8BfeAOrwSpz17sHbvw4UoYy9IDb0t2W+sjL/JZLpkmE0zL0UnPhSoPMyTDyJiWGp/dHHRg3GYCOD0qXlD/y1/v5y6//H+kCvUfz4YkaxH0gXC4Mj8CXkEU99fQ2q9zegK3v7X11pdG8A1ca9KqKssZXWlo40bbSKXkO63p21ozB0ETRdoJad5juCjh0lrUhXCLn3hmN0+OHmuCEsuZdCt1VuIG5CqfmMUeahiellDnTvt40z7TmwJXjQMSt1YlmKVvWTlO/sdCOMoqmpMRnhdAL7SHk4rGG+BJgGsU99UyxYLEb8L7ggDL0qe3bib9dfLmbyEgSW1WnPreTuFfgHAKd8s4tKqbaYClUFmLStCMxBcjwQM/UpffmE3sCyjCY+5Gh161UUJfb6v2puXCZkMzxHv0JSdrXuwyvn66qhhNNpTt9zXjmV5z+wsO8saX8vGRfLE08YGVreJ0EEpKoXnhD1t8SJeVSBnP32y+V/T6FaH9XpeyZteX1Rm6Yrppw6wUUTnNxJdS14QgGMdyOoobeE07REwRf3XhSrt6bRCG0WIoen6DGU1N0XLkYmhiQapshN0EiF9OtZY2U9Ad6j2tO3DlOcsraq/BWq+/4kLnqZpZqLb0iS8d7qMgY+lIhFktG3BRK0yneVVx8zmF59Jpt6IeO1ju+xY6rryoaZ4tZaVS4e5fRiSKVqoNB7tqK4YDps48tOm5ssIqID0R04A/NlTJ7Db3Pyl8eBR2ayiXTHzbT+1NqVrpbSGWQRJMp/Akwvb3f/yEzjsFwgNlZWoMm0RGncoeLTU8vL2s+UkoqopJkQK3gTJ9GMA6hVP6whZE2GNORpmOyuh5CG0vHyUux611VFalNKC8EUj/NakySxxHoj5Y0SLhBOJ2k3Y6st5mPiohJrMIJDidxLzgTxR0Id0KthDRnnkqmPaD/Bmqf99J7w6l9n+i9TmRO9ylTc+LO+VlkpB8CtSrD7ZDJs0hoIMpQsGzZsRGPddMotpkNIGMhVWBpLc7adxaXk3ZYN7bhatxeLgeUoU9/sA4zEqPn4b8UHBO2Gh+InNLtpNeFdwj2O73t7XQHJcHxA5X+chFCEClQ5u7Se7MPvAG1DJUlloejCdMqEMlkDGWyb6KWoW9qb8GdBvy93//EsXPorgBnGT9KT0IZYPPNRweEXza3tPPVX32VnpwwXE8iRFUU9Aq1wpA+b1Gp4qad71CRgOaGIEm3hMa9Vx3stmo0ag89qqzxwdoqdCc4ImXEi5MmSeurTLtdeHQwzIHGKrNPkKxUg5Oe0lLF3rgk6Rs6E5HWBFoBQ68ZvbIZfXD3XifOyt5wqOnWVDN0q6lNJlumytrfqHBX0BkEVxkSG02be5u8OEt43okOlYYdCqrfaHuJVWgmBdQ9wovyA8rQhywPueu+/y04Jtat0ihzNTp0n5tAHFLJvRMPC3bHiFVKKGPzKu4TuPMIm2UbgwN+y9CPhg5N5ZLWlZH1ZJo8W99zxtC37FKZRo5Ab7xac/vpCYC7jB9lRoyrpqmFDc19/16P33U1n7rrCVY8+uPssW3NG6mOgFllrY4CAdWJKZR/9bDr9X8A0FQ1nViVJNieRM9TwTwY9NZWEhpMn1m6WArA4XAQ84GrDBkEd9JUG9uAdGv4khDTB+Zsd297Hy0Naet7SLlFUaliM5XCkwLdX1hSebBkNlb736BTVrGTdOfR0/F4s4/dNTn5/BkHokv9nqW1iq8ZOzk7JFJRXtFU567ewjFngT2EDF3tO61zq+8lVKJvgNOS//CkyiuAGy7KNvRCCKcQ4k0hxN+sfwshxLeFEO8JITYIIW7IOX6XEGKzEGKdEKI8N2YISCQMki5IbG8n/kb+3fZESMU9Hd7ebvO6P0BFHDq7964SsqYnjR6k6EZshqTPiSc+8A+v6WC4rWKu4P5n6KWlA6JZG8mZ7Ju4VTHb3aS+Y1c/xcNYQOCPFP+caVPis+4FY3fBi6/1CkU1h+JMWLcFdxqirz6dPd645S1cJrjqVOzWFVSiYu0782e0dFl9Xc1pJ5Cs1BjfKdka2rvrQnSrhiMzx00uPdgi7neUzA4CFRLIpB1KnxtfCrryCPRtW7caAMcY1Z5P9xY39Kl29TsxAuVlCpWD6VbhlmQ/NdOwVcOSz9A7vL1xeX/9pN4nrMKobqvQUSQSpAXU1x+SHRINavijEkp0gopb54i7KRhayhCyxiaCyn5EO4rrJrmsS9oBJIe5ZWkxBuPRfwnIreC4CpgMzJRSzgIesI6fDRxu/fdp4Bd7P83ycCdg9ZGCpCbp/MUdecckrcYHTl+voU8HqvDq0Nmy57KmHV27qY6CGSxPACrlcym9m354cmKVfn8Qw6EapYxGoi+sxmjvW71pGmqN6rbymTM31HhYGfqY1fszs2mWIVnhIhAt8SPr7sKfgPYqQTAGkZfvzT73p0fvY+ZW9XpvY++Pr2e7iqF6x6sKaHe1ylEvpGCZ2raDpAuch5+MUV3LmDC837y+6LxK4elJ0VMh8OcxZIVI+krr3RhpE28S0l7lXQqPF5cJHXnSdtutHrT+ySon3vC4sjfNfHTvsHq0BgKFBw0SaRn6eL84eNhKjcyNx2fI/Z1Wje9tqi6sPaAeq+hLJFMk3OD19MpAp6r8VEQEPW3FJYJ1S/uoo1oMSAXuT9jq4KVXqw3qZKi4cFqucmv3CDYfKcvQCyEmAecAv8k5/FngW1KqTstSysxa+ALgd1LxMlAthCgt2beXSF3Ho0N30MFzcxx0vfQu4d0Dv9hkNNNtPifVrVLlcXc1l85bLsT6daqbjbuuuAxtBj3gVVKxqYGa2qZHGQTh9JAeJa34+mN0tLPj+uvo+uGNfZ+wMoQ81vfrtGL1KUvsLGn9MCv6qTgaQQ/+JKSKyBO07tyEQ8Ku2cpY1zWuY2dnjHBCx/HifbjTEA5AXauBbt0c4y1qaV1rFcb561QMN1ZAwdK1O0JHDUwZW4uYoNIcd697vtTXUZRAWBINDi4EkvJ7CMTBMAoHd7ticaVcaeWXC8sohtoGhhPi1o1t7Ay1wE57VZinUKP0yE4Ve3ZWlq7kLRu3hkNCrF/NSrRb/U4dOWGaDC5f7wbsmMm92WxOy4GIdiuz40gaJPvdJ2RdHU4Ju0soUpo9KgQYqdLQSsTSYz1qpSMa1OqilFSxKw0J6/7e1Vw6q2y4KNej/wnwn0DuVXEo8DEhxOtCiL8LITKNMCcCubfQRutYH4QQn7Ze+3pb297LD6QtHfeAM8gb8xtwGvDQf3ye9bv6broZljqk5u+9gJ216o/WvXvPmwM0blBFNpVlloubgQAOCZFdvauIVDyOO52zhHU4lEefHn2GPr7qcZCQ7tejNLNx7LPymV1W0ZdhbZaZ1g+lpv/3ZMWOm7cUFtpq36kkI1wTJtA01kF9U5yn1jfywEtbmba1m64aB7uOmsj4NnhrzUr1flaK4qQjlYHzWd2HjAKpi1UdabqqNQ6p8+M44mgAujbuuUdvxiIEoxAPDjRixTAqAlTGoKt7W8Exzd2tBBKAT53bZe17RPNIG5gd7RgOOGyO0mrH58GfgO54/k3pkFWs5S4zJbQsrP2aWFdfWYKolQOf8dJzcfnVdZHQYGxd71yc1meNW6FYZyo9wNBXTFM3hqY3VhWdliMSJ+oB3aepTJ4isfSk1cHLP0mZOxktrpvkMiBkLYpCrSPXZaqkoRdCnAu0Sin7K+d7gISU8hjgf4HfZl6S5zQDvjkp5a+llMdIKY+pr9/7iymd2RQJ+Lnp+l/w3kQ4Yss7PL62r/HONBjxBnsNvbdeLWd72vd8aRXfpqJaE49YWNZ4UaU8/+atvUakKxPvy9koTjtBpEe+FV9/wi/8C4CN/Zs9W560z9pI1qyUuIw0AlY+/dh+tQZuK3a8693CMrFhS4TLXTOG5NzJTGwWvP/KY7y96mcctgPSJ8yibvFSXCa8/6yKJDpCyuOqmqI2yH3jVZw8X6u+UPMGakPQHgwydUyA6sUnq2YlTXvuiMTfV0V0es0gc9Erq/HqsHtX4ZtMe+dO/EkQAeXdZqpCY90DN5pdoSidQRhXZW1o+v04gOYC3bZiLep3Exhb/r5CKTKZbpGOvrntCSsH3pWzb5bBbe2pxD29EsUAmuXpJ62QoEs3SfXTyhl//Enqte8VT5F1xVJE/JB2q+IsqRdOz9YjylGsGj9JpW+WKLTUDAhbH7R5W2EAACAASURBVCvfDXhfUY5HfwJwvhBiGyoOf4oQ4n6Up/5Xa8zDwDzrcSMqdp9hErD3deQliLaoZZH0VzKzbhbdS6dT1Q3jX/tln3Fpq3LTV9nbbd4/YToAia7yBJDy4WhpQnfChLnHlTVeq1E3t9xNwS7rx4Wv17MZrYa+7S2lrx6L9Qv0Wobeb/UIdVsemWE1nHBEI5hAxbjpfV4WHK820bq3FxbyilsGItAwgYlnXozLhPoPnuTIHS/gAOZcdzPzz/okAOnN7wKgRZMkNXBYsebg5KlA/lZ92195FAfQGJxIQ9DDoYcfRqICqjv0gumYpWi09M0dDQMWtUVxWg2wd2/bWHBMqHU7DgnOoDJ67kp1M0mFBlZcq2IpkdXayWjMtzcOFNYDSHW2Ygqom3B43uf3hEy8PdrdN2yWtDbqnf6BlcOZ32ncC05HryHPfFbd0nl3pUz0fh79vCNPor0SHLs7ima8eOImMb8D0+vGq0O0iBBa2qomrqyfTNwDziLSBlJKXIbKsAOIh/Z9H4QMJQ29lPLrUspJUsqpwGXAM1LKTwKPAKdYw04CMlfMY8AVVvbNcUBISjnst7Juy9sTViOR8774KwwHuLe83negJQMcyMnJrWiwMhHCe64Z7e/sIRyUaA0zyhvfoO6F4ZbeeGqkXX1NjtyNYsfoM/TpcBit2TLc/bRLMhvHXsvAu60QTkZ+2RVPKsmJQF2f1407TPkJyd2Fl7e6tUyvHj+V2ad/koQGE9uambYlSdsENzUz51M1eTrdFeBrsXqjRg0igV4DERw3CcMpceVpGtH2jrpWWhuOQQhBlU8jUaUxoVPyXld+g1iK1i3qhuOfUry2oj++cdaNr6mwlHC0XWWAeKx+rAFrg9sID9wgDIRNohW9BUlalbr+QwW+b9nTTdgH4xum531+T8gY+ni/FYduFTtpgYENTryWoU96+nrrPksIT7dksTNtBHOpdFfSNEGjss3kg5bCm6bemCTpc2ZDR8VSJk2rmrimfiJJT3GpYqnrOICU36rKLtW4fRjZmzz6O4CLhBBvA98FrrOOPwlsBTajQjqf26sZlknI6siuWRd7be0kYl4G/KAzHV8CNQ3ZY1Xj1eaeKKNApRCVoRTxMlMrAaomqgyCZI48csQq5nLleDaGc2ArvpEm/vprCAkpZ56843QawwEuj/Kg/dYNNVNIpcVTxL2Ao++lN33GIpIukJ2Fy/7TOWEfl9dL2/QA09+HKa3gOf1D2XFtEwKMaYGOpg/wxSSxQI6Bc3tIeMGdJ0c9tmMnJuCc2rsqM2pqGd8J73cUr4AsRKxZGePxs44f1OsqJylZiHiRcGJGi95Xp67lQK36f/8G3NIwCEYhUdkbEvRb13+sQDhBRGKEfTCx7pC8z+8JbiuMlwr39ZgzXdU8FQM3foPVap4pT9+q2UCV+s2mrTab7lRvWnIfpk+kukfw7up/5J+UlARikAq4syvpUFvh3hQymcQUMKaugZTHgVYkRVW3Wg3qfqs3Qxk9ZoeLQRl6KeUqKeW51uNuKeU5Usq5UsolUsq3rONSSvl5KeWh1nOvFz/r0BDtsC76Mb25tjGvKuPuQypFygnVwV6PsiboVzeF6J6lMSaMBHUhiV7pyioylmL8ocqDTXf3ehqZHH8t54I3neAYZR59yzOPYjjgvYkCV7/SbmGkMZyAQ2WZ+ILK0EurkMqdTGcrOXOprVWeuCtUpGjN2vgaO1m14wscdzQVCaU7Mu/q3iYh5hGH09ANbz3/JwJRSFb0XdOnvAJPPk+sJUJnFUwZ37tnJCdMx5eCHZteLDyvIqQ7u+jxwezpswf1unpLlGtb51aiqfz514a1sR20MpiqxqjwUP8mF+Gt7+JKg1HV6zEHrRVlqjt/OMEZS9Ljh1pfXd7n9wSPtS+mR/p615nuThVjJw14Tebm1d/QBy2pA2mtFN26qgzuzyFLlgHQ8tqjeeeUCrWo7KYKPw7rRhTO0/ktg0ikiLuhxu9H9zqKShVHreJMM6A2y80R7P18wFTGJq24ZHBcr3Z2wieyJfNZUilSGgQDvZ53tV8j4nfgje6ZQd2yaxOVcaC6PHVCgCnjp6nenTnphKlMY/DK3o27tGPwHn1jV4wNzcPnPbS/8gqbx6OqN/sVmIi0ZeitG17QijWbliqgaiAx8GYonE4iFeCJFM5vc8STxN2gWSGAWRd+AYC2w6vwjetN15x68jnq+Jq/URkFo7JvLrjuEXjjZt+4bSqGvyNNW7XGIXW9450z1eZ616Y96ynsCCcJVcCEysH1Xa2boj6PK2TwH49eklfWwLQMZrVViBVsUCqTop/W0451SpjN0dBbWTrG0phP5wnzALjjBlGfGDKdGwCfdV0bsb77HRlPd8whA8OeVZW1mEDc3/dvWG3d1EgmkBmhMc9AQz/n9GtIC3Du3Jw3Tt+4+S1lBKuqsg5WtMDND5S6bNINmtOB4dHwFtmLDVvncfgrSDlBjGCXqQPG0BvhCCkX1I/tjSmmvI4Bht6hG6Rc4HH35ud6NSdRv0ZFBMz04L36TW+rHHpvzg+pFH6Ph6gPnDmbmbp1wXurej1K0wmOQUjyAtzzu4f47V3l1ak98YvfsfzG/1f2uc1YjEBjiO2TwJVHa96RNknnOF9BK7so04DBm5SkvHnEq4BYwIE/Wjjm6UqkiOesBmpmzIErLmbezT/uM27WCeeoHgO72gkkQfbLeDG8TioSEDd6DaLetI66LsHuyiCH1PXukdQee7J6sLuTXZFdPL3jae5eezcPv/9wwXnmosXSxPyirIYjuVRVV7Kl7v+39+Zhlt1lve/nt4a99lxz9VDV3dXp7swhCekEQhhCAoQ5COIVRfGKggpHFJUrRw94j3d41HuEox71KOgDR46g4oCAAh4IKkMgIZCETJ2h093p7qquufaw1t5rrd/94/fbteehqmvXlPV5njypXntV1dq71nrXu97f+36/h/iBr0uu+eun+a3P/ExzoNILg5lx1VEUH1U3VdHgZjT7pOo6SU5Wr41hPTgl20gVO8UQL7G2Y+5GQg+rNbUk5vOUTNhXMxBVIenY/OWNB3jshjvrtmd0M4P0Sri5FewAQqf5UTE9OMbMmGB4Js+ZheZummnd9WYOj2NXFrNX2i/GGqUAT9/7gnhMzTG0iRmVnnvbSVJ01FDXVrFrAr3MF8nFYWKgWnsvJ9T0X1gTKEVZ6b2bZv3dv5BOMJiD5eW199LPP6o6T4en1rbgVkhUnW0AQr2wlBmpesyGpsBYYxv96z73u7z9S39OvgezA+sf/gtHv/A/6z6jTuS+cy9mCOU9MULbqlMQBLVwHNScVcmK4mBJ99e7ECRaZ4nltEUm114r3nbrfUOFEFzxH3+T4RvrNWScgSFmRkxGT6obSmy8Xk89iGsFy5pOmjP3fxHHh5Pp/XWB/vA1VxBYMDYX8MpPv5Jf+Mov8Mff+2M+8PUPcO90Y8dxM/GixE2sXS9GCMGRT3ycL119K7c+ILntN7/G3/1RvYG6oU0yHC3kJZJZyiZNvrEFvaA7dtnx1W3JvQeUWXdj1xQgg4BEEUqJ1jfk9ZIdVolQ6NUHeqPokU9A2ml+6rFNg09PvZfBq15ftz0RT1OyQJTKLGobQeKtZxVKB9JMzEi++mjzwNKSdt2K7zlAUq/vlToYsqjuHq0tlEyoWYSl1jX9gu7eMWIJvFjz32Uz2TWBXhQ9Cg7szVYz9SAZI+nCSk2d3igHLd3mvXSWwTzMzq69u6J85iQA+67pTbSqQjFh4BSqTxyhfrQbGKmWIUKjKozUC245wFksInNw8snuAxpmsUzShdOPtW/jq+XRf/kMgYChw5cQ6JH22sAsGjJ6x3LUBen7FFwlUVxrIFFLkE7g+OAttCknuBIv3luWuXhwmAm9rps+UG+FV1GwXPSqv+ec1rg5kb6MfQPV9tZEzCLI2jx3Bn79eb/Ob97438nO/N8YwTAf/NoHcf0OC/h6oc9bp17MFVPj/PCff4hPv+kn8JMhV/zel3j83i+vvl7xIa20VyKECigNEgPh/JwalrrihtVtwrJxHTBbeJkGy8sIoJzcOJ0bgKwu4zW6OFWe1No99Xz87Tfxk7fUCwUawlBts2WfxRmVnIlE88AVwPjVV5H04NFv/GXTa66Wixg6cBlJXfcPCu3XicyyXO3XF6k0BnD+dOuY4eZVKdaIJ/FiYHWRQO4nuybQm66PG4d0TZ1OphLEfJirmbw1/RC/RaAvD45hhbBwpreAV4s9O0fZlIxec9Oavm9h2GZsThJU5Hn1BTC85+DqPqEpMNeQ0T95dp4wJwHB3Lfu6rp/RU/liX/vrRSxcvfXeWov3HzpKwhjNmZYFTIDtZ4QNCSCKtAHnHvmCUwJMtU8GAMghlSZ5+Qj32v5etxtX/Zp2ve6ava659Jr639PKo0VwuJ8dbxj6Wl1U/T3PqeuXxugNDzMgbkye045fO7jX+Et3/t7Xv3VCZ5ePskff69+TqOWYOG8ktJNtw5AvTCeifMrH/hlTrzqVgAe/OzHVl+zvTKeDcKuPiGVW/jGmnpYamKgXnaiXXugP6MWI8PU+o+7FYmK+mSDB3Ljk1ojN04NM5JuTg5Klgr0y7Pq72jW6NXXcuxFrwUg9kSziYyvp3L3Hb2WQT3rEBTa19LtEpR1d4+pa/qzZ1tPc3t6uMqKJyjFBFaHDp1+s2sCve2GeE59LdTIqMXRuZohHNMPW2b0YkwtaC0/s3alwtRSkVwWjPR4951rmL3qmJri/MSH1TF4HmUTsoPVWn9oijXV6M9/526MUH0G5Yc6+2UGQUhaly2XH+7urRl6HqOn5rmwP+SKa24ndFTGF9YMghiBrCvdgGoRFX7I7Cl1EzXTrS/IuO4eOfdY65JIwmtf9mnk2EvuWP16curyutcMPW05f0ZfoL5HeaZALg7j+6eaflZp4jB+3uTSD/08v/SPH+f2e77Bj999H//xnww+9sCf8dDcQy2PYeZxVRuXF6kXk4iZvP7t/4mCA6VHqomI5QW4DfGvFGt2M3KWyyxkBZZRf+KXHNUF1UjulP5cMhuocwOkkmN4FhgNdn0xTzb1yfdC2VbtvQVtWGO1aM8ESN/4KtyYZPzCBc4v1d9k5Eoe34CDh44xOKrOv0onTyuUuqxKNuJ6naBd3/1qj388jR9rr8W/GeyaQB/zJKWGPlpLLwQuna1On5pliW83n1Sx/SoYLJ9t30PbiiAMyC4FFLNmz62VFY6//hdZSMHZL3wOUPVGzwajZv1grRm992BVwMk/07n3+5lTj63ascnznXW1AWa+/TXsABLjAcbo0VWt8EKNVKsRSMKGpNu3lHfm8jktUTzYumVvYFItxi2fan4ULrp5UkUIkr1pxhy+/iWUTAgEpBoE1CoKlkvnVBYfnvseqWmT02NxDo02d07Fbn4lIJg/M0jm9hdx6L/+J4LnHeO675X5hX8o85///kcozzUL4p19Qi302cNrSwBaMbpnkpkxGKgxRo95YVOA9GOiKdCnViS5TPOTUMlp3R4497T6/M02f6f1YtuOegJpKGHEXbmu9YCyLTD8EFfLcFQGxxoRTpLCXpMD02W+fKI+kTNzLitJiNs2Qzpw027RVErdr6+uz+SoWvspzLeedfC17Ied6m7z2G92TaB3PCjF6zOWhF7UzNeICVm+JGiR0Q8eVj6d7oXuPp21nM+fZ3wJguzaRKsAXnrVzTx01GDkiRXCYhGz1EKBzzDWFOhLp1RwWUyCNdf5vZx+pJrFx+e79/je989/SwhMTO5VA0+6zbGiCQ5ghpLQrA8+ZR3oCxfUI3ZieA+tmDh6ndp/uvlme+70o1gh0KNsrunEuXAgQy5tYFj1f/Ckbs1ztYLl9+/7O/bPwv2jh5kabS4rHX/rmxj5g//GFd/4OhO/9xGSd/wIR/70b/n0da/ipofh9Z8u8Xf/8mtN37eonw6TNaW4iyG/J8neC5KFpWWklFqLvv4S9m1Rt0AeFlZI58EdaC7DBHGTeItAv3zuJADx0bXJNvRCyQaz3Bjoqwqca8G3tCObXjxN6CGqVmQPj3FwBr78yFfrttsFn3xSO7rFdRtku0BfLhAvKU0cgIFxNUxWbiE5ARC4epgrmSFwzC11mdoVgV76PgkP/IaTJaNrbqWaO64K9M1ve+yQ2jdcXJs5wCNPPUDaBWNk7dmPEILlKy4h5sOJT/13zFJAqeF8l2vM6M3Zs6zE4bFJQXKphNdB4nhOl1LyDmQWQmQHSVyA/EMPMD0M1x9TU56mNoVYWqiOtLeq0fuWwAgkJS1Hm24jlHXJsRvJOyBaLMZOa29Ocw3lhIl3/Cz2W9/ctL0i1FUx337om0qG+OsDL67roa8gLIvxl92Gma5m+4mYxcBP/ywfvu7NXP+khK80l/wKF1Ste+jQ5U2vrYf4kSPEfPjq5/8Hnh/ieKpVtJYgZtZljtMP3IMhIRxpznYDxybpQjms7wYpakXSbIMe0UagAn31nPRdl3gZgsTaF37LtqECvZ4Ezoy2V0M/cO1zMSUEj3y5bnu8EFLUdolCCNxYs6xHhTC3UNfGOXZA6QC1kyoOdAkonhkidGx1k1hjq/RGsSsCfajtxIJEfVY9MqlW6oPlamZr+RBazSWWPSMZcgkwlzur0TVy9gG1wBOf7M34uZHr3/Dz5B049bm/wixXjcErhKahMtkeKAchiaU850YgP+KQWZI8dbZ9T3B++iQAZyZtBpcEsyfu6/jz40vLuClJZupGoFprz9cFeggbFjN9U2D6kmBZBfDhifoumAqJzBhLabBbaA4tnVPHaq+hnHDFG/93bnjPbzS/D61gGS6rC7T4+DyuA49nL2FqpPVCcSve+vxDfPXYzSxmwJpt7r7xF1Wmd+DYdT3/zE5cfqtqMZy954ssFcs4pebkJnDMOoPw01pULbav+eYqE8oDYMmtD1TlhQUKDoztae5rv1gqdfUK86fUDVIme//cKwS2wPJB6onT7Fj7J5D0zUqW68DME8zUWFYmi+DV2CWWYmooqhU57RcrdXfPsBbIo41UcaibFBLpYWTcIebD8vLWTMfuikBfrAj6N0zPjepReVaqdU27DKHVXA8czzqspASxLnZ2jbgnlZ780JHndNmzNbde+zK+f0QwcmIBxwtXjcErSLP30s3TcwWySwGLQyaxyb2YoWD6m19pu395XtU2i5cdwZTwxDc/1/HnZ/Il/EQI+1XgqkjIujViTa1KN4GlnXZy6mlp7+E28wZCkE9BosV0bEHrjyRG2mdtvZKanALAyBV4avq7HDolmTuQxbAsJgZ77zQZSsV48w0HWE4ZxJZb/JFWchRiMDWxMZnxJS98M54NzpnTLK6sKOOahkw4jFnES6z63M5r9cuhVhIMySTxMpybaZgdWcmxnICJ0Y3P6H1bYNW4Ls2cUk9qRmZtk8OgPWjL1cXTkb1Tbfe1Lr8FLxNyeNrl8w+rKWcZ+KQKygSoQskWmG0WTee1O1rF4MUZGCBEtXa3omIqlB4cRege/zndt7/Z7IpAf+GMWggTDY/1g2OHcW0wC+ouKqUk5kNoN79txzLJp0zlMbkW5tTTxMgV67PGFUKwePkkCRf2nZdNwkzSMrB6DPRPnDxLOg/+WIrxK1UwXnjwq+2/QWe0e1/6OqA6+NWOTCFEJoBhlZE7Wi/IqxmjNwOQDRl9qG9WRrGIb0B2uH2w9lIGqVzzI4yndUMG9168yNbA+H5KtsQseHz93/6MvYtwbuJKDg4nscy1XRJvf+FhVlI2qZxsMqww8x4rSYiZG9OPbsQcLowZDM8Weez0UyQ9oKFVVToxkiVY1B0fpXNqkf3otS9u/nn6iezCmXoLTSPvspyEQ0Ot11IuBt8WdbIZC3qB3h7sTQywlkqgF64SGst0qNGTGCK51+Ty05IvPqHKNyvnHsfxIchUE8RSi8XsCsu6FCeS6nMThoHrgNFuEEp3FyUHRjH12tL8zMm1vMUNY1cE+nltk2Zl608W24qTS4BVMQcolzEkSLv1pGIx5ZDJqcnAXhH6aWH46NqmYmu55o0/Q8lC1RAbO4JMEyvszUF+/juq1pw6uJ+jN70agPLp9nMBZr5IPg5XPv92APzz7TuO3PwyiRL4SWdVeXJVFrdmwMQMaMrofVtg+mAWPfJxMI32HRbldIxMHmSDoXOgjUJGDvQmA92JuKMVLItlnvm26lL6pHWcV1zVu4RFhanRFIVUgsEVcFfqxbBiBZ9CcmNlBLzJAfZdgG/f9zWsEIx0Q5eQNs2em1cLzWJhiYUUHD14ddPPimUrUsUn67bbhTL5BCRjvfkfr4XAMuraDFef1NbRmSRjFrZf4xdrdW6I2Hv9YQYLYH7/LgCeOfFdAERNt045JjDbxO2c1q4xM9X9PUfNAbSkXMI3YHBgdFX/f6WDBHI/2RWBfkVPtyVG9je9VoyDrSdjAy32FLYJ9G46yWAe8ou9W37ZOZeCI1d119fDrTe8gYemVEAI7PogKE3175LbYQJT455Q6wV7LnsOR6eex4UsOB06b2KFMoUkjI8eZCEN1mKxrY3amafVU5ORrmaQmREVGGsHTMywOdCHpnoqsfRQWyfCTAorhOXGm46ug7Yt+6yRUlxguwGDj6/gJeD76UP8wPXr6zJxs0PEyzBzsv6JKF4IKSY39hIbuvoaEiWwH/snAGKD9R7FFc33iomNs+yymFUTyo0ktFRxfrb+BuUUA9wN1rmpENhGnT6Sq9fXMuvoTApjyvrPLJWV21OX9ub0696Cb0tuOnGSUwuLXNBlI7umHFi2m/WbKhS1XWmsJtCXHNFWqliUfcoWpOIZHK2jU1ho7VXcb3ZFoHf1Y312vHnByY0LnKK647oruqMm1rqVyx8YwpAw+9R3e/7dTsGneJFZmyEM5q/QWuKNUqt6PSGf6+5wZE4/SQgcuv5lxMwY8yMG6QUPv43McbwQ4iZNhBDMjsRwFgVyqbXWz5mnVKC3B6qBpSKLG9YMmJgB0NDVFNomlg+2F+J2GYwxhlU56KmH6oOmKBQpWZAcGGz1bWum7AiSRclVT0ty+9JcuX+Ay/a2HuTqRqATjNkn76/bnixCKbVx6o8AB1/0BgAmK62qDSUPQ69TVUxsUstByx56gIxevKyVKpZSEi/S8wTyWgljJnbNMlig13eG97deoO+I42CgrsFSD9Ux47o34R8Ked6jIX913/9iRc9RJGvKgatdSy0SHk9fg4nBakmr7JjtpYp1oDdMk6Tu0S8tXbw/9nrYFYHe17Xm4clm2zMvYRDXCpb5BXVCi1ibs0Lf2edPtp50bEWisDEqf5fd+TZKJviNo966B7yQ7xzow1CSXpxndgAOHlTGGe5ogpEFODXb3DIaylAtRGlThJXxQQYXBMtPfaflz587raYlkyPV8sbI8D5KJlCjl2K26LoJLRXoHVfidQkgCd0SO/14vQyCVSwrw5INwo+bTM3AcA4eHTzEG5+7/p5xZ7/yv104VR2aKrlFNeCV2sCDBiZuuJ2yCWNnVfKSGasvN9m67l5cmEGGIZkcuAOtz/dhbaFZ60gV5vNYAZSSG3uDWv35MSWEV9bJh9QL9PsOreNJTbc5xguyyS+2JXaCAy++kYwLF/71byhpD4uRQ1es7uI7NrGygBa+sb6WNEiMVisHftwi7rUurRp+QFmf7hkt6FZqIwvdb3ZFoA/yOeXX2sLf0o+bxHXVY0U7ONFCzhTA2aeyioXTvckgSClJFSSlZOtS0Fp4yQveyh/8zCjZt721bruw1AXndnGneWaxyMBSicVhgaU1xO3JvcR8eOTuf2naf6Ewy0ABwkopZuooSQ/O3H9Xy5/v6s6m4ZoOkqHkAG6sfsDECgCzPpiHtkXMB8eTlLsE+mFtGp6vyBNobLd53P9iCBKx1angu8aey+uvbS779crgMaWrs3S2qp1z7rEHMCSwRh36bhixGHPjFod0BSA1Vm/WUSkreEtzzD55QvV9D7U+hgHdfSTz1TWWQOtC+cmN1bmpIGM2dlD1GhbFIgUHRofW3k1Vsf6LF+WqomQ3Rt7yy7iO5NL7H1zVmNp/7Prq8TkxnBKUCs3XW8XNarBmkCyMx0h6UCw36+MYNbpaI3tVaar2s95MdkWgFwWXfBz2t+ix9hM2SQ8CP6CgNVlMp/VJPDClpmPz59vbt9WyXFpWxhbJi49AtmHzp//h37jzBT9bt13o9QSvS0Z/YnqZ4UVJebh6LBNXqU6gC/d/sWn/p07dT9IDoXVYxq9WJ3tjJl0h1DIHE5dUF/Vsy6JkK+kGUMMgVqA6hWqRlqWkE1xBuY1yZYWDl91ICAQX6muZMTfEi2/c6WroIBGmQ4xrbmV8HZPNFQ4eu5IQKM9Ws7Wz+nO0hzZWRgDAnxpdna1Ij9fXthPaC7a8ssCT31EdV9ae1kE0pXvrRaFGl1/f0GUbgbCLRusj5XQ2bRZLXRfo22HqMlWqIFaFxrohDlzP4hGb6x73KS0sk3dgosZHQsYdrLB6fLXIiuhgzVOUTMZJuTC91Fx7rw30Q7r1U26Ry9SuCPRmsUzBAdtsPllkKoEhYWlmjuJyVTa0FfuPXauCzHxvj1ezS8+QcSHM9O4stVaErS4Mr9B5Yvfxhx4gXgZnf7Vme8Utqp4btNCOeeaEDkRaJuLS65XEsjvderHIXFygEIPRA/VTniW7OknoeSWlTtkgOVBZE0l63bVqJg9eydwA2NP1g15rUa7sheGUasXzxxzecMPFSRQc2jvISgqMpWrAXNAti4kW9ngXS/qaagaaHp+qf02XCILcChf033joYOtOJTOVUfr1xeoT2WJFcjfbWjfmYhH6abqiOGm5/rqf1CreynZQFRrrhcGXvJRkCS59zCOXVJr3q+jF7KXZ5g406ZUIBYzV3LyNVFrNIpxvrgIYflWyOzM2RQhNEs2bRc+BXghhCiHuhHpSUgAAIABJREFUE0J8tmH77wshcjX/doQQnxJCPC6EuFsIMbVxh9sa0wvaq9+l1V1/9tQTeCsq0FvJ1nopE6NDrKRALPVm+XVeZ23GwNp7gHtFWJVA37l0s/iQ6g0eO1K9qAemrmc5CfG55unYRT17kNGZxuSRa3FtkItlKDbf6GK5AvmURGTqs8OSDabuOy5qPX3RcMOVdrVGLNsoV1awU4MsDkN2tr5GmnAhiF98iWz1OLJqUffp8QnuWEdbZS2j6RgrKYGzUl1lLGr9n5EDzeXEi+XALa9b/TpREeLSZCsKjIUcnjYcOXj182mH54BdY1Az/4zK6K11lFJ6ofIkldPtn90kijtR2+kWrCHQX/OTH2QlCSmPpvbXymL20uzZpu8TXpliDFJO9Xy29Hk0f7Y50Ju+xNdT+Kbt4MbA3CKXqbVk9O8BHq7dIIQ4DjS2QbwdWJBSHgU+BPzWRR1hD6jH+tYni6VLE/NnHqWkNTHsZOsMfDTtsJwCu4NvaS2zJ3V71vDFBYpOGDpIlrs88tnPqGm/g1fXmJ8IwdKwYGCh1OQgVZxTXRkjh9TEpGlazAxbGEsmTD/Y9POdfAk3ASTqM71yTGDpkfZ8pbzUMHksavqxjWz3rhl32GZ0ISQoq7+DWy6S6mBYsh7Cyy4lPVFk+fiLSbYwlV4LQggKaUsNTWl83ckyeezadt+2bvZdezOBUHrsZsN601BFR6hYRMzNkYvDpZff0vZnNfaB5/QNKrFnasOPG8DU115hSZVG4p6kvM6SnFNzLoVO74vHVmaEp4+pG47boJpppNR6RmGhuXRjeAFerL6N09FDWssXmrvVzAbdp610merpExZCTAKvAT5Ss80Efgd4X8PudwIVd4S/AW4XazXMXCOO16ziVyE2rDKe3PTT+HohJJZqHWxMQ5BPGSRyvQ1M5c6r9qxUh9Hri8XUUsAlt32gl1KSnp/Gs2HvVbfVveaPJtkzJzkxW9/WFSyoLH/4aHU0fnF8kPSiQfFUc+dNqhBQSogmKebaScdipaOgwaZR1Fi82YMdphcr72dsGDuApx5UcwEXZp7A8dsblqyH4OrbmLlllCO3vnFDfp6bSTCwAkFJP4msLOMbsFev+2wkZjzOwr4kbosAmRrdp8byXQ9nqcBCFpxE+wXhcoNUsTc/R8mCgfF1tDv2QCXJcpfU+ee4UF7nk1qyZhJWxteWBOT0kKDX0F0Uy1ZkPZrnT8xy1S+2QlrX64stpIotH4IaXa1SDMxS78OYG0mvt9IPowJ6bUP2u4HPSCnPNew7AZwGkFL6wBKw8StSNThe+5MlrR9l3dlz+DpYxtPts8piyibVo4BleVbd9QfX0xrWI4bOhgOvfTlpetljeLnAwqDEGKxvE4xP7iflwbe/86W67SKnPouhQ9Ue4vDAQYaXYPrJ5gXZdEFSbtFd5NsCW6slVspLtY5H6j1UF7/jHYSnVn/XlGp3e+Rrnwfg/NPqyUlcxFBaI887fhOlt32B51998ZO2AP7gACkPZs+oGQwr55JLgBPrT/fKvlfeSeba65u2G/EMXgwMr0RquUw+0znH8p16qWIxs8hyEvb2QecGIKZlSsq5BaSUJF3w16FcCZAerJmmbeMX244b3vgr3HvM4Myx+r+/k22W9ahgliSlhu6eQZ3klZebpYrNQBLWNCaUnPbyCv2ma6AXQrwWmJFS3luzbT/wZuD3W31Li21NTaZCiHcIIe4RQtxz4cL6hwhkEGjD6dZ39MF9SlXSX5ojdFWwTAy0v++4aYd0oSpI1IlQt2cNbNC0ZitMHSh8r73rzYnpFUYXfbzhZvOTg1er1r/Z79WLm5n5EiUbrJoseejyKzGAZ56uNyzJFVbIFEGmmj/jwDZWB2A8LYUgGgbSzJrF74Eenn4O36jkG5a1peCCrn/aHf5ua8UyDW4+MtJ1mrJXTJ1QnNKuXrFCmfzGPYA0cfR9H+DKj/5FiwOxlT+pV2ZgWeJlOpc0grhF0gUv8Cjcdx/jjyzyjcsFB4bW327aCUe3f5bzy+TnZpS8xzpbOTM1Mx2iR5+CClcfGONTr/wDpn7gt+u2p7QUg59vXhOzypJyg07WiJ5FCFq0Pyul3Or+yhRm+8oU3wK8XghxEvgkcBvwfeAo8LjenhRCVKZFzgAHAIQQFjAANK0GSin/REp5XEp5fGxsrPHlnslPn8ZAtTm1YnzyGKEAuby02h6VzrYPGH42iwEUnn647T4VzJUiZUsyNLHxBg0VLJ2pBB3szZ6ceZrRJTDHmtceDt70cgD80/XB2ykETRO9R65TnrcrDeYrTz1Z6cRoXkgNYtaqoUIl0BtWfYZmJqoX4cjEVNv3UeHwtS9mISuxz6onppzWQ4m3MSzZDqQPKEnf80+oYTunuPHyB71StiG1XCZehnCwcwAMtVTx2YUznHr/L5FLSz77AoOxdH/uUildbgkKK8w8pa+x1Pq61jI154OZXFs7qGEI/vFdL+XNx+s7rlJ6GMpvsSZW6xdbIblfd1W18JltDvTmlrlMdT0TpZTvl1JOSimngB8GviylHJJS7pVSTuntBb34CvAZ4G366x/U+/ft3Z3XMqyVRZRG9oxNkYuDyOfBc5W1XKZDnXhIvTZ9ovWEaC123qOQEKTX4Y7TK5bO6MMOTxjzT9yNIWFgojkLsy+9ATcuSc0srE7vlcMyyYLES9YvRB286nmEQGmpBOVqG9gzTyjvU2e4+XMLbTXpKMNwdcHYaCjdWDUX4b793VsZE+kBlocEA1rj3Z1XT3yNPePbib2XK43+/NkzqiRRkJRSG9cltBZKMRidVY9Z1mjnNRGRTJJy4SP/6fXIk+f4wztMlsUe0k5/jj2t9XVCt8DsMyo3tNbpqZvMVEuw9gb52w6PqqcEWWwI3FLW+cVWsLQEhVFsbpu0GwJ9EFNeAX0Mh23pR8rxUWBEZ/jvBX61D79jlVlt19buZEkmRpSCZd5DlpUn61CHEoA9ru7QM0+2V32sENdZcT/Xmm2dDQel9v231inVcTNyrLmEJKwY7pjFwemA719QmflccY6BQvOgl5PKspA1kMsmLDy1un1ZO1Glxpt7wqUTwwDCQgG/qDP6WP3TVUwP33gWDGa7L8YCuMNx9sxJFgvz+NqqbWhi440wNopLr1PdTsH8PMtFn3QRghalrs3AtwUDOk5l9PRrO0YzezAl/Mi/BixPwdLen8Sc/YW+ndPZSrnFLbIyrZoZYkPre6JPxFJKggOIb1CLc8U3VnoNiZXvEauxEawg4nECo3U3je2DrOlAC+M2TgkKW7Agu6ZAL6W8S0r52hbb0zVfu1LKN0spj0opb5JS9qYnsE6WtWlCvM3JIgxDKVgWS4hSmZIN2WT7kyKth0tyz3RXsEwWumu3XCxOQn20Ybl9Rm8vqp7kiu9tI/EDExy8AP/0oJqQPb94koE8hI0St8D8aJLkokFppqrb4urPeFTLE9QfoCrTrMxOU9blJbNB3tbRi6iFtUxAju8hFsBj99+1qocycmhjFk77QXZwQCUUSwXOnn4Kpwxk11Y33ij8mgXDicubF2xrSeuatCHgNy59N4/PXc0dV0717dgGK5INnktRT1sn12kmYxrmahdMYnj95d9aUtlhQtHCN9Zb0Y5e9WVJIQRuHCyvPniH5bIaHqx9uo07JEow30XOpB/s+MlYd17VcdPj7evkXhwcN8AolSlZYMfa1x/3HbmeUEBpdrbtPgCloES6AKXUxphKtCOmA70st++/tfSJk5ls7U06fvyFWCGcve8LAJw+9wiZApgtzB6K+/cysiC4oJ8SANClkwOXH2/av9I6OX/hzGpnkNXQ2+1k1O8prGEwJnNEBainvvlFRMElMGBwT//mFTaClbTAWSlz9nFV9rOG+jdI14lA15FdG45d8cKO++6/Xr0ee/s7+fT/907u/407+H9+YONbQiuk0mP4hpLNKOkWy0rDxHqoeCxnW0iUrwfHUoNNosFO0M/NEQtAttDJKsWapYpXu3ZqpsRFIqnUcc/1NfdtyY4P9OVldbKM7G9/snhxA8cNlZqc1Vm3+ujEMRZTwFJn8aG5/CwD+f6JP1VwVgN9+yEuq1ggEGCPtjbdHr39TgDsU08ThAHTpx/FAGItLo74kUtJlODkk9U1CrGyTNmE7IHmG0lF/3xl9hy+Li+ZDTfSpDa4aNX33Y59z3slAIUTj2AWSxTiEGvjI7BdKKRNUvmQRa1znhrfmhtTZUp0MQOJkc7rGpk7XsfEhz/MJT//8xc9ONYLpmnhaX2kUMv+jh1cv3l6xWN5qEVZcb24NhgN5ZU5XWaqSCTUHYNj4DQ8cC9XBBRrlHIt3Rm0cP4pNpsdH+gDLR26t0ZqtJFywiRZVJosjebbjezJZllKg7XcWZNi4ZnvY4UQbtAiUDviepG5U0ZvuyWKcRCJ1vMBsUuvwXfgwHTAowuPsnzuJADp/c290ge1jsrCM09Xvz/nkkuCcJpLPZVuh9zCDIFuAbUaeppTuqWuuIbBmIPPeR7LaUns/AJ20cfbmnL3mihlHbI5KEyrz254sj+96N0IdcDOZ4EWhiO1GI5D9pV3NMlW9BPPBqPsQ66Ab8D+FvLivVLxWE6vw6GqHaUYGOX6DH2xon3TQj7Fj1vEXUkoq9+T0x4ZtZLolo4VublmeYV+s+MDPQV1sozuaX9R+XEtk+sGq2py7RBCkEsJ4vnOo8pzT6s2OmNwY2qD7Uik9I3Eb29aHnPLyrmpTf1bCEEwnuGS85Kvnfk6nva5TR5qXtw8cu0LAPDmqmqZ8bxyomqFrS3SikuzSJ3R2/H6iyGrrdpyyd4le9OJOCtDBkOzpY4SF9sJOZglW4DS9EkAxqf6N1/R8Ti0HEApvT0v77KtpkwN16UQh6Sz/lbOsi0IgVRm42YsSrbAahhsWplTGbrZorsvTNikXFjyqlWAnK40GDXrVRVlUXexWV6h32zPM2ENmEWPggMxu33mEuoe+1Qu7BroAQopk2SucwvUvDbisEc3Xp2wlnjFtsxvf+OJeUHXjNc6eikHZyRff/RLhMvqhMxONQf6zMSUWuBaDlbNFxLFkFKy9U2kUn8vLS+sLhg7DYE+rW8G/holDLzhFPvnlGFJ2dm8jHO9xMZVX3dqWq3vjF7SeSG0X1TkAIKB/pYV14sK9CFWsUzhIn1ZfNvEi0Giw7rbWinHDMyGvCqvLQ+tdLOqZ5iIk/JgerE6+OlqAUVqJNFTurW0tNTe3rNf7PxA7/bgPKRrY+mcrNOeaIebtkkVQZba18UL09qqbX9/O0GSyazSLvHbt2TF3ZBSl4w3ffNLsULBypOPQE4F8OEDzQvYwjCYHY5hL5rIebVolC60dxxK6lbVcmGFUOvSxxpE45LxFP9yncC7eY2f1d5JHB8mZ6Gc2N71eYChQ0ofZuRCmUIMUoNbU6OvKESawxtju7jRlG2BWZbaTOYibTizA7gxgSE2LpSVYkbTBKurF1edFlpNIpVSmvTz1U49Vwv8WTWBPjumuov83Oa7TO34QG+7HSSKNUZGZZSGZFU2tBN+RmUH5fPta2nlefVolumwNrAROPEUvgkErQO9lJK4J/G7ZLz7XqxEnCbP+5hFn8AAe6B1KSU3PsDAgmDhzMNcWF4gUwCZaZ0xVQZggvwK+OrG2BjoDWGQ+fX38fIffFfHY2wkc0xN6lohBPH+djdtBJO6lXHvHH2VP+iGoaW5M/v6N7F9MfiWEsKLubJrgtKNucPDPHVoYxdw/JiJVabON7asO9sSLZRqzcwAVghzumQHSuIBwKqZCh/eo3SlwsLmu0zt+EAf87qfLLEa56mwl0CvM6GFh+9vv9NyjhDItqhzbyiGSWC2z+g9PyTZg1Z77NAhwpjBJecl2Tx4ifaDXvLgYUaX4Ikn7+WpE/dihSDamHJndbeDLBZXF4zjLcbRf+Lqn+Cy4RZ9+B0YuOll1WNKbmHk7JG9V6ihKSvkog3jL4YbXvgiTrzQ46YXvmLLjqETSh9J4ngXbybjveXVfPNdnVtI18qqrEeNb6yvjX/SLTrVHB1f8jNnqselg7mVqCY92YpJTOPU7Saw4wO9kijufLLER6qaGIHV/S2LCdWmOH3/3W33MXMuhQSMDPQ/APkmiDYZ/XyuQNKDMNk54xVCUNo3xpXnQgbync2fR668FgM4++T9zDyh1Bhjo63LECNaG0S6xdV1hHhqYzqRDl31HPIplVWJNhIX24n4yH6K+s/gpbZuTeHQ/kO8fnKOgb39kRq+WALbwC4rMxn/IuVD3nntO/n921ppK66fQBuEB2418w6Lutw52tzdk9DTvu581Z0tKCg5kFiNJWNM7ye8zXeZ2tGB3g9CEp7yhe3EwN4aKV67+wU4ctn1eBYsPdJswFEhlvcpJGGwy+/eCAIDRNBa3nRm+iyGBNFDP39w2TXsvQCjKxI/1X5h49h1ypGocP48K9qkO9NmTmFgYBzXBjxvNdCnOshAr4XBlENuSP29rIH+WNttNMv6ug76PEjXkaMvg5f/Z5i8ceuOoQNBzCRW0taSG2gms1FIxyFehsJKVYtRuqrRYLRFwpPVdpHlper+vh4edJLVpMdwHGXduAUuUzs60C+sFEi4ILuYc4+OTeHpyoa0ugf6511+K+eGITjbvkafKIS4CQPL7P9H6FvtA/3cORWIzUx39b7BF7wUMxQcvABmpn0w3nO5ckWSCwVK2olqz5GrW+4bs5O4MTBK5dUW0I3K6NVBqwA/NHyoy47bg0KmYhK6haUmJw23vKdtu+1WE9oW6UpSu0Z54c1AJlQSVJitmonIUolAwHCLafIhnQSFK9WW5IpSbkWWuYLyCmjfKt0vdnSgnz3zOKYE0cYDtsLekUPkdMLbS0Z/ycgRzg8L4vOta2lKnRC8TcjmQWX0RptAnzt3EgC7B4u+yeffsPq1Odh+wMRIpVhMG9hLIWhLvAOXtc8OSzYYJR8RBGpCt8Vg1XoR+9UaSGqs9dTvdqOcVZl8bJt2vGwHZI0wWKVRYjsh9ALqYo1BuPB85fnaYrAsoxVZRaEqbRzo8kwqU39jKMXA2u6iZtuNmTMnADCznU+WPaMHyelKhYx1D86mYZIbMskshwSNKnbAsrfMQAFKXZ4kNorQBCNo3dfvzqoFoHgPok7OoYP4empSjHbWdl8aTZBaNIgtLxIKiO9pLzxVGYARfqDWE6yNK1tcePU7eeLyCXj+azbsZ/YTZ1SdiwPbXJdnS6kz1+6r+dy6MHRdPVdjD2iWlF9sKyxdtxc1UsUVyZJkg1JuKSawy5vvMrWjA/2y1oyIt3icqsW0HAqVEnYPgR4gHM1iSDj/4KNNr83NnCDpQXmdhglrRWX0rQN9oKfsMmPdFQCFECxPqsdM0cX+0Ns3zvg8yGKZfEL117ejbINVClVGb7KhJYMXveB6vvqj/4UrDm3ciHs/iY2rG256T38H6XY0NcJgtY0S24WKVEFxsSpsaJRCSnbrTiojnSYQYBVrhhr1DE664cnZjxnYm1+i39mBPlZUf4hMD+JRns7oa7UnOpE+OAXAE9/4UtNrC6fUIq3MbI46YaeMPtRelSM9KgAaVz8XgMFDnWveiaNXkvIgPW+Q7+KUVNYG4SIIVc//BrInG+d33nwt8R5KbtuBK257I7N7JEdv+YGtPpRti5GoNg5kxrdfSc6piPCtVH1grXKzX2wFIQSeA5ZbU3svlwkFZAbqB6x8xyBWkptuPrKjA326pNXv9ndfqPO0cqJwehsLP3K90nxZeKi5xXJZO+MwtD4d7bUSGAIjbHNi5FUL2PBEb610V93xYqQQHOpiin1Iv//D58Ht0iro60Bv+KHK6J/F7HvxW3jRVx8hPfWcrT6UbYtRay05uf3MZOJav6qcqy6uWmU1MdsOLy6I1UgVi7JP2YJEg8CfdLbGfGRHB/qR597Bky8/yvgVL+q6b1kH+sp4eDeuvuLlzGVAnDvT9NrSWbUt1kFIbSPplNEbhTy+AZnx3o4lc9tLOfqlLxI70DmTmnqOWny1Qih3cUoKbIOYzuiDHX1GRWwGtdaSew9vjfBbJ9LaCKUyJEXuAlZJ4nd4qiw5AserXqPC9ymbzZLoYSJG0oULK5s7Hbv9BUQ6cPmL3sjlL3pjT/v6cQvwMXtUyhsZPsbMEAzMN/9B3FlVF0/uX7+O9loITYHptQ70VtFTzk3x3roXhBDEJrvXj2P7Jyhb2veyhSl43fHFTGJlHyOUz/qMPqI7tnYcc20Y7dD9tVVkR1VGH1YmWL/+e8TKgny8fXef71jE3WrxXZSV90UTqSQpd5GZ+dNMjW7ebMizJv8KE6o2byV7W0AVQpAfNhla9Fkq1q+e+AtKxyJ5aG0j/eslNEXbjN52yxQdYIM9PoVhsDCkFq7FUOfOCBXoVQtoFOgjuhHXCpCFOBgdFvm3imGtbR96HuRn4dsfIVaCUqJDoE9YJF3wAtWlZ/itlXLNTAZTwqyef9ksev6UhRCmEOI+IcRn9b8/IYR4VAjxoBDiz4QQtt4uhBC/J4R4XAhxvxDiuf06+LUwd3iIu64RyMk1tL2Npkl48ND36x1hjJUCrg3Dm3RHDg2B2aakZ7vB6kLzRpMfU5mXs7ezS1EYs4n5YPqScPtdtxHbjIqRd1fV2S0iU9HG8jz4xh+wUvBIeBB2mNcJE3HSLswXtA59m0Af0+89N725LlNruSzfAzxc8+9PAJcD1wAJ4Kf09lcBx/R/7wD+6OIP8+IRw8P84WtNEqneO2UGD6k69olvf7luu5lTRhzDmzTmLs32gT7uhnhOf6Jr5krlEXv4qps776j7oh03Kt1EdCelyzX9Om8vlmQ8Q8kC03PhW3/K/3rmCFYIR9/0wx2+KUnKhZm504BKelpdCxUTc3f+XD8OvS09fdJCiEngNcBHKtuklJ+XGuBbQKXweyfwcf3SN4FBIcTmtKd0IB1Tk4rJeHepgApT16gFyeKjX6/b7hQCigmxaYE+NA3MNjMWjidXF5o3mufcrNQjDx3rbBYtdF903A0Jze3vBBWxtWT1YmepT+ftxWIbNsUYxLwCfr7A/u/muf9Yipe84ofafo+hSzIXzp0EVKBvJYme3aOko0s1JiWbQa+f9IeB9wFN4UaXbH4M+Ge9aQI4XbPLGb1tS7lp6g5uy5W4eur5PX/PJc+5A8+C2PmTdduTBUkxYW2KmTLoxdg2GX3Cqyw0bzzZV7yCyT/8Q5xLO7diVvqiEx5R6SaiK4Na2rrcp/N2IyjZQFnwL6eOkXEliZ/6sbay3gCW7r1f1pr0ZiAJWiQ9I/umAAiXN9d8pOtlKYR4LTAjpby3zS5/CPyrlPLfKt/SYp+mlUQhxDuEEPcIIe65cKH/d7dbnn8n//Vdj7J/X+8tkak9VzI3BAOLS3haD/6+6e+QKYAf30TVPdNoGehLZZ+EW11o3miEbZO57aUdT3Coam4nXKKMPqIrA4PjlE0oJbdpkR7wYgK7KBh6oMD9R2xe8Zp3dtw/PqRKMoULSgjR8mVL74sBrd0k8pvbXtlL/nUL8HohxEngk8BtQoi/ABBCfBAYA95bs/8ZoLZJexJokoGUUv6JlPK4lPL42Fh/DbbXjWmTHxKMLpY5MZ1DSsmffe7XyRZAJjovUG4k0jSwWwT6+ekZDEBu8QVjp1WgN4gCfUR3bMvir3/oBuy3/uJWH0pb3JjF/tMmWTcg/9ZXE7c6X2OpMfWU4i2paX0zaG1yFN+j4oZRKDa91k+6PjtJKd8PvB9ACHEr8MtSyrcKIX4KuAO4XUpZW9L5DPBuIcQngecBS1LKzV152EDEWJKRE3m++9QzLPIA1/3jSaQhuevGt9FbB//FIy0TM1CqmbXZ9eyphzEBNklzpx1OjeRxFOgjeuE3P/gXW30IHSnGbKDM/VOCO173H7ruP7h/ChcIlrVXrN/a5EikUgQGmG6zWGI/uZiK6h8De4BvCCG+K4T4gN7+eeBJ4HHgT4Gfu7hD3FoGD+zDkHDigX/j7z/5QV7wsOTpqw5j7NtEjQ7TUNlyuVy3efGsMu+2shuo/74OEtlqJ5PcBH3+iIh+Y+hp8CffeAMT6e5LjAMTWpM+r6Zpbb/1tSCEoBBX8y+byZpWQ6SUdwF36a9bfq/uwlmbC/Q2Zt+lz6HM48yc+BSvufcc5VTIbx7+cV7dRRZgQ7HUR10o5MnUiLLlZs4wAjhdBpr6TWqwWnqTRpTRR+x8Zp47wRl7kVtf21uemtk3yTRg5FVJxvLbe194Dtje5koVR+lXFw5edxsAd377HJdMw/nrj+KM7uXmI5sYXLXZQVE7y1coLSi97MTw1navDoxUh9CijD5iNyBffSvf/rHref6+3rr0rGyGQIBZLCGlJOaDtFrn0V7cqBNA2wy2b3/TNiF26DqWU5KDFwSlcZ+X/84f8YqhzVuIBcBSUgTFlQWgqtTpa4/KbJfJ1X4zPD7JjP46CvQRu4F3Xfcufu7an+vacVahVqq4XHKxwvaBvhw3iBc2104wuiq7kRoh0EoHx954PWKzgzyqzRHAzdVn9KGWUR3dYqnXzOBeAn09yBYLUBERO5Feg3wFVZIJKKzodvE2Jkd+3CbhQcnfvKw+uip74DnPG2PPcxdJ/m+/tjUHoDMDt1gf6EW+gG/Anv2dB5r6TSwxhFtZOmjhqRkR8WzAixs4rmRlQT/f2q3nW6SWKl6osR7sN1HppgfSd/44zDwM+67dkt9fyehLFX1sjVlwySUgndw8udOWWDFKNqQ8wIoCfcSzk7Jj4Hg++YU5AESsTcNGKknSXeLc7Bn2ZDYnSYsCfS/c9NNb+usNWw1rlIoNgd4tUXTW/ojZD0qVp9Q2dcmIiN2OH7dJrPjkcnOkaB/ojUwaA5h95gQc3pxAH5VudgCGbqksF/J12203wN0mU+TlKNBHPMsJEjHSLiwsngfau9nZWTVguNKgodVPokCUoQ2gAAAMKUlEQVS/AzB1ZlAu1Qf6mNc/ieK1Ugn0Igr0Ec9SpJYqXlxQVqNGGze7hDY2Kc4225T2i+0RJSI6YsZU2h5UrM00jicpbZNA78dU+ciwW3caRETselJpTAm5aRXArTbWg5kxNXdS3kSp4u0RJSI6Ugn0fql+lT7uQjm+PRY/A1udSiIK9BHPUkxdkvFnlbCZ3ca2dHhiSu23vLApxwVRoN8RWHH1CBjUBHoZBCQ98OObY37SjcBWGb2wN1EaIiJiG+EMjgIglpUEsZNqrUE1vP+Y2q9h0r2fRIF+B2DrQB+Wqop3/rx67Au3iaZ3qE1YzDa9wxERu53EyH4AYivqOo2lWwf65F4lgCbyhZav94Mo0O8AYtp9PvSqGf386ccBkKn2hsWbiYypEpLRrnc4ImKXk9Va8/G8kjeIp1rPt5jpLCULrOLmSRVHgX4HYGsHJ1kurW6bf0YFepHJbskxNaENwq0o0Ec8SxmcUFIkybwy1EsNDLfdt+iA5W2eVHEU6HcAjl7UCWsC/dJ5ZctrDWytRHEFUQn0Tuve4YiI3U52QmX0g3quMZkdbbuvF1dzMJtFFOh3AE5CZ+1+NQMozqmhjPjQnq04pCasikF4snXvcETEbic9MkwgqoE+MzTedl/PETibKFUcBfodQCKjFnWkX5U2LS0qPY3U+NZKFFcYHFY3o6GhwS57RkTsTkzTwHXAVJUb4tn2GlTluEnck5t0ZFGg3xEkkirQixorQV97Uw7sv2RLjqmRsePX8ImXCsYuu2qrDyUiYsvwdBNcyYJ4rP2UuB+3iLsQhpsT7KN59R1AMp1lDqAmo5f5PCUTxvduj0B/zd4ruGrPMxjp7VFKiojYCjxHABLfBKODrWaYiJF0XZbdMoPJ/rck95zRCyFMIcR9QojP6n8fFkLcLYQ4IYT4lBAiprc7+t+P69en+nPozx7i8Qy+AQTVxRtRKJKPw97s9liM5cjtGC9+H4xfudVHEhGxZZQc1WZc7pJCy1ScZAnOz8903nGDWEvp5j3AwzX//i3gQ1LKY8AC8Ha9/e3AgpTyKPAhvV/ERWDZcXyTukBvumUKccjGt8niZ2IQbvs1MKOHxIhnL76WJPG7XAZmWnXSXTj9aL8PCegx0AshJoHXAB/R/xbAbcDf6F0+BrxBf32n/jf69dvFdhBM38kIQWCA8KuB3nJ9ittjKDYiIkLjx9UcSbdAb2ldnKXzT/T7kIDeM/oPA+8DKv1AI8CilLJSND4DTOivJ4DTAPr1Jb1/xEXgWyCCajuW7Ya4TnT/jIjYTsiEVprtojUYH1IhsTizOVLFXQO9EOK1wIyU8t7azS12lT28Vvtz3yGEuEcIcc+FC5sn17lTCQwwagK948lto0UfERGhqEiS+FbnJCwzpnRxvIXpvh8T9JbR3wK8XghxEvgkqmTzYWBQCFF5QJkEzuqvzwAHAPTrA8B84w+VUv6JlPK4lPL42NjYRb2JZwOBWZ/ROy6UtolEcUREhMLQQmah2TnQD+9V8y/BclNo7AtdA72U8v1Sykkp5RTww8CXpZQ/CnwF+EG929uAf9Bff0b/G/36l6WUmzcZsEupzei9B79LvASFbKQrExGxnahIkgRdMvqRSaWLI3MrfT8muLiBqf8DeK8Q4nFUDf6jevtHgRG9/b3Ar17cIUZAJaNX98sLv/0BXBvuuf7YFh9VRERELfFhNUcSWp1Da1Zr0hsNPtD9Yk29cFLKu4C79NdPAje12McF3rwBxxZRQ2CCEUrcRx9l5Vsn+KebBcWR7TEsFRERoUiNqZJMaHYO9GZqENcGs+h23G+jiFbzdgihKTADyexv/wZlW/KPNxn80JWv2urDioiIqGFg3xGge0aPEBTjYLmbI1UcTbfsEAIDxudCVk5/l8++wGD/8G286aoXbPVhRURE1JA9cJgVIGN2l+v2HIi5ftf9NoIo0O8QQlOQKUi8mOQLxx3++rUf2OpDioiIaCA7NsayCU7yQNd9vbgg5m6OVHFUutkhhPov9dnjBj903U8znmpvahAREbE1pB2bX3rRe/j2a97bdd+yY2yaVHGU0e8QyjFBwYEHj6f4xPN/ZqsPJyIiogWGIXjPu+/kqv2tjcFr8eMWiekAKSX9VomJAv0O4VsvTvKxFxT4v17yK5hGNCgVEbFdeeXV+3raL0jESHgexVJA0ulvKI5KNzuEN1x7Oz966AjXXfVDW30oERERG0EqTrwMM/Nzff9VUUa/Q7jl9v+XW7b6ICIiIjYMI5UCLjBz5jGm9vXXsCfK6CMiIiK2ACujfJYXz/ZfqjgK9BERERFbQHxIdc7lZ073/XdFgT4iIiJiC0iOqHKNN3++778rCvQRERERW8DQXjVU5S/1fzE2CvQRERERW8DYqlTxct9/VxToIyIiIraAof0q0FvFQt9/VxToIyIiIrYAO7OHM/skI0Pxvv+uqI8+IiIiYiswDF7+7hfCsVf0/VdFgT4iIiJiq3jTRzbl10Slm4iIiIhdThToIyIiInY5UaCPiIiI2OV0DfRCiLgQ4ltCiO8JIb4vhPg/9fbbhRDfEUJ8Vwjx70KIo3q7I4T4lBDicSHE3UKIqf6+hYiIiIiITvSS0XvAbVLKa4HrgFcKIZ4P/BHwo1LK64D/Cfy63v/twIKU8ijwIeC3Nv6wIyIiIiJ6pWugl4qc/qet/5P6v6zePgCc1V/fCXxMf/03wO2i3/YpERERERFt6am9UghhAvcCR4H/JqW8WwjxU8DnhRBFYBl4vt59AjgNIKX0hRBLwAgw2/Az3wG8A+DgwYMb8FYiIiIiIlrR02KslDLQJZpJ4CYhxNXALwKvllJOAn8O/K7evVX23uSAK6X8EynlcSnl8bGxsfUdfUREREREV9Y0MCWlXBRC3AW8CrhWSnm3fulTwD/rr88AB4AzQggLVdaZ7/Rz77333lkhxNNrOJRRGp4QngVE7/nZQfSenx1s1Hs+1MtOXQO9EGIMKOsgnwBehlpgHRBCXCqlfAx4OfCw/pbPAG8DvgH8IPBlKWVTRl+LlHJNKb0Q4h4p5fG1fM9OJ3rPzw6i9/zsYLPfcy8Z/T7gY7pObwB/JaX8rBDip4FPCyFCYAH4Sb3/R4H/IYR4HJXJ/3AfjjsiIiIioke6Bnop5f3A9S22/x3wdy22u8CbN+ToIiIiIiIump06GfsnW30AW0D0np8dRO/52cGmvmfRpXweEREREbHD2akZfUREREREj+yoQC+EeKUQ4lGto/OrW308m4EQ4s+EEDNCiAe3+lg2CyHEASHEV4QQD2t9pfds9TH1m3aaUs8GhBCmEOI+IcRnt/pYNgMhxEkhxANaJ+yeTfmdO6V0o7t+Kq2cZ4BvA2+RUj60pQfWZ4QQLwZywMellFdv9fFsBkKIfcA+KeV3hBAZ1FT2G3bz31rLhKSklDkhhA38O/AeKeU3t/jQ+o4Q4r3AcSArpXztVh9PvxFCnASOSyk3bXZgJ2X0NwGPSymflFKWgE+idHV2NVLKf6XLwNluQ0p5Tkr5Hf31CmpGY2Jrj6q/dNCU2tUIISaB1wCbY7X0LGUnBfpVDR3NGXb5xR8BWub6euDuznvufHQJ47vADPClmsnz3cyHgfcB4VYfyCYigS8KIe7Vml99ZycF+p40dCJ2D0KINPBp4BeklMtbfTz9po2m1K5FCPFaYEZKee9WH8smc4uU8rkoKZl36fJsX9lJgb6ioVNhkqo0csQuQ9epPw18Qkr5t1t9PJuJlHIRuAt45RYfSr+5BXi9rll/ErhNCPEXW3tI/UdKeVb/fwY1dHpTv3/nTgr03waOCSEOCyFiKGmFz2zxMUX0Ab0w+VHgYSnl73bbfzcghBgTQgzqryuaUo9s7VH1Fynl+6WUk1LKKdT1/GUp5Vu3+LD6ihAipRsMEEKkgFcAfe+o2zGBXkrpA+8GvoBanPsrKeX3t/ao+o8Q4i9RAnGXCSHOCCHevtXHtAncAvwYKsP7rv7v1Vt9UH1mH/AVIcT9qKTmS1LKZ0W74bOMPcC/CyG+B3wL+JyU8p+7fM9Fs2PaKyMiIiIi1seOyegjIiIiItZHFOgjIiIidjlRoI+IiIjY5USBPiIiImKXEwX6iIiIiF1OFOgjIiIidjlRoI+IiIjY5USBPiIiImKX8/8D840wEs2aNDEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7da4314a8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results['time'], results['rotor_speed1'], label='Rotor 1 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed2'], label='Rotor 2 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed3'], label='Rotor 3 revolutions / second')\n",
    "plt.plot(results['time'], results['rotor_speed4'], label='Rotor 4 revolutions / second')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When specifying a task, you will derive the environment state from the simulator.  Run the code cell below to print the values of the following variables at the end of the simulation:\n",
    "- `task.sim.pose` (the position of the quadcopter in ($x,y,z$) dimensions and the Euler angles),\n",
    "- `task.sim.v` (the velocity of the quadcopter in ($x,y,z$) dimensions), and\n",
    "- `task.sim.angular_v` (radians/second for each of the three Euler angles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.28530662  12.14725033  31.10221018   0.15385841   6.07120026   0.        ]\n",
      "[ 2.9760326   5.46322316  5.81428155]\n",
      "[ 0.01916427 -0.09019081  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# the pose, velocity, and angular velocity of the quadcopter at the end of the episode\n",
    "print(task.sim.pose)\n",
    "print(task.sim.v)\n",
    "print(task.sim.angular_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sample task in `task.py`, we use the 6-dimensional pose of the quadcopter to construct the state of the environment at each timestep.  However, when amending the task for your purposes, you are welcome to expand the size of the state vector by including the velocity information.  You can use any combination of the pose, velocity, and angular velocity - feel free to tinker here, and construct the state to suit your task.\n",
    "\n",
    "## The Task\n",
    "\n",
    "A sample task has been provided for you in `task.py`.  Open this file in a new window now. \n",
    "\n",
    "The `__init__()` method is used to initialize several variables that are needed to specify the task.  \n",
    "- The simulator is initialized as an instance of the `PhysicsSim` class (from `physics_sim.py`).  \n",
    "- Inspired by the methodology in the original DDPG paper, we make use of action repeats.  For each timestep of the agent, we step the simulation `action_repeats` timesteps.  If you are not familiar with action repeats, please read the **Results** section in [the DDPG paper](https://arxiv.org/abs/1509.02971).\n",
    "- We set the number of elements in the state vector.  For the sample task, we only work with the 6-dimensional pose information.  To set the size of the state (`state_size`), we must take action repeats into account.  \n",
    "- The environment will always have a 4-dimensional action space, with one entry for each rotor (`action_size=4`). You can set the minimum (`action_low`) and maximum (`action_high`) values of each entry here.\n",
    "- The sample task in this provided file is for the agent to reach a target position.  We specify that target position as a variable.\n",
    "\n",
    "The `reset()` method resets the simulator.  The agent should call this method every time the episode ends.  You can see an example of this in the code cell below.\n",
    "\n",
    "The `step()` method is perhaps the most important.  It accepts the agent's choice of action `rotor_speeds`, which is used to prepare the next state to pass on to the agent.  Then, the reward is computed from `get_reward()`.  The episode is considered done if the time limit has been exceeded, or the quadcopter has travelled outside of the bounds of the simulation.\n",
    "\n",
    "In the next section, you will learn how to test the performance of an agent on this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agent\n",
    "\n",
    "The sample agent given in `agents/policy_search.py` uses a very simplistic linear policy to directly compute the action vector as a dot product of the state vector and a matrix of weights. Then, it randomly perturbs the parameters by adding some Gaussian noise, to produce a different policy. Based on the average reward obtained in each episode (`score`), it keeps track of the best set of parameters found so far, how the score is changing, and accordingly tweaks a scaling factor to widen or tighten the noise.\n",
    "\n",
    "Run the code cell below to see how the agent performs on the sample task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode = 1000, score =  -0.610 (best =  -0.050), noise_scale = 3.25"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from agents.policy_search import PolicySearch_Agent\n",
    "from task import Task\n",
    "\n",
    "num_episodes = 1000\n",
    "target_pos = np.array([0., 0., 10.])\n",
    "task = Task(target_pos=target_pos)\n",
    "agent = PolicySearch_Agent(task) \n",
    "\n",
    "for i_episode in range(1, num_episodes+1):\n",
    "    state = agent.reset_episode() # start a new episode\n",
    "    while True:\n",
    "        action = agent.act(state) \n",
    "        next_state, reward, done = task.step(action)\n",
    "        agent.step(reward, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            print(\"\\rEpisode = {:4d}, score = {:7.3f} (best = {:7.3f}), noise_scale = {}\".format(\n",
    "                i_episode, agent.score, agent.best_score, agent.noise_scale), end=\"\")  # [debug]\n",
    "            break\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This agent should perform very poorly on this task.  And that's where you come in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Define the Task, Design the Agent, and Train Your Agent!\n",
    "\n",
    "Amend `task.py` to specify a task of your choosing.  If you're unsure what kind of task to specify, you may like to teach your quadcopter to takeoff, hover in place, land softly, or reach a target pose.  \n",
    "\n",
    "After specifying your task, use the sample agent in `agents/policy_search.py` as a template to define your own agent in `agents/agent.py`.  You can borrow whatever you need from the sample agent, including ideas on how you might modularize your code (using helper methods like `act()`, `learn()`, `reset_episode()`, etc.).\n",
    "\n",
    "Note that it is **highly unlikely** that the first agent and task that you specify will learn well.  You will likely have to tweak various hyperparameters and the reward function for your task until you arrive at reasonably good behavior.\n",
    "\n",
    "As you develop your agent, it's important to keep an eye on how it's performing. Use the code above as inspiration to build in a mechanism to log/save the total rewards obtained in each episode to file.  If the episode rewards are gradually increasing, this is an indication that your agent is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Episode =    1, total_reward =  -60.45, , z=   0.00, v_z= -13.82, \n",
      " \t score = 0.00 (best = -inf), total_steps =  26, \n",
      " \t task.sim.v=[  0.93528753   3.99643522 -13.8172312 ],\n",
      " \t action=[616.41980695155326, 313.43496205896355, 649.76317798326158, 511.68667758264559], \n",
      " \t task.sim.pose=[ 4.0305897   5.08777695  0.          2.84128249  0.15178838  0.        ]\n",
      "Episode =    2, total_reward =  -60.28, , z=   0.00, v_z= -13.76, \n",
      " \t score = 0.00 (best = -inf), total_steps =  26, \n",
      " \t task.sim.v=[  0.93907456   4.12369443 -13.7634732 ],\n",
      " \t action=[618.47125581040314, 313.77940011774984, 647.46424588495802, 514.37629979850715], \n",
      " \t task.sim.pose=[ 4.01682693  5.21481799  0.          2.79075923  0.14209154  0.        ]\n",
      "Episode =    3, total_reward =  -57.68, , z=   0.00, v_z= -14.68, \n",
      " \t score = -2.31 (best = -1.83), total_steps =  25, \n",
      " \t task.sim.v=[  3.9036846    4.18893983 -14.68415134],\n",
      " \t action=[888.5338274393938, 306.83859203259448, 118.94006832806922, 672.09617744983473], \n",
      " \t task.sim.pose=[ 3.82678889  4.42947737  0.          5.67136643  3.94181149  0.        ]\n",
      "Episode =    4, total_reward =  -44.94, , z=   0.00, v_z= -19.09, \n",
      " \t score = -2.25 (best = -0.01), total_steps =  20, \n",
      " \t task.sim.v=[  2.3517447    1.86306097 -19.09008283],\n",
      " \t action=[895.64475209220234, 164.3050727241127, 488.18433360503013, 894.51582047861802], \n",
      " \t task.sim.pose=[ 2.97344674  2.03044562  0.          2.61191152  0.80260378  0.        ]\n",
      "Episode =    5, total_reward =  -50.63, , z=   0.00, v_z= -16.69, \n",
      " \t score = -2.41 (best = 0.02), total_steps =  21, \n",
      " \t task.sim.v=[  0.18669359  -8.2553252  -16.68644999],\n",
      " \t action=[885.08479555568476, 741.80018657613607, 809.05143214546467, 891.52917711275211], \n",
      " \t task.sim.pose=[ 1.50944455 -4.72285048  0.          3.05604736  6.23684913  0.        ]\n",
      "Episode =    6, total_reward =  247.92, , z= 132.15, v_z=  21.04, \n",
      " \t score = 2.95 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[  0.85842928 -23.57822045  21.03685597],\n",
      " \t action=[899.31915958795912, 900.290938624913, 668.103819591611, 900.74351194746941], \n",
      " \t task.sim.pose=[  15.86973499  -31.75684242  132.14515955    3.0837561     0.38608649\n",
      "    0.        ]\n",
      "Episode =    7, total_reward =  175.88, , z= 158.68, v_z= 121.91, \n",
      " \t score = 2.93 (best = 2.95), total_steps =  60, \n",
      " \t task.sim.v=[  38.53381339  197.80014303  121.91370636],\n",
      " \t action=[899.61321640390372, 899.47187397657206, 900.76974991463248, -0.24725653486012686], \n",
      " \t task.sim.pose=[   3.61522624  150.          158.67552053    3.91193197    0.1948246     0.        ]\n",
      "Episode =    8, total_reward =  -52.73, , z=   0.00, v_z= -15.90, \n",
      " \t score = -1.82 (best = 2.95), total_steps =  29, \n",
      " \t task.sim.v=[  1.88409986   3.95961154 -15.89922952],\n",
      " \t action=[900.15792546058526, 900.03336077916549, 462.69294542551052, -0.64534957300797813], \n",
      " \t task.sim.pose=[ 0.95991514  6.84154706  0.          4.36614183  6.19361788  0.        ]\n",
      "Episode =    9, total_reward =  -55.67, , z=   0.00, v_z= -15.70, \n",
      " \t score = -1.86 (best = 2.95), total_steps =  30, \n",
      " \t task.sim.v=[  1.2621209    3.96904395 -15.69846858],\n",
      " \t action=[899.47362722496086, 900.33581965373969, 842.32231421948552, -0.22425257020146708], \n",
      " \t task.sim.pose=[ 0.53912501  6.91822303  0.          1.51978099  6.22117936  0.        ]\n",
      "Episode =   10, total_reward =  -58.72, , z=   0.00, v_z= -12.97, \n",
      " \t score = -1.37 (best = 2.95), total_steps =  43, \n",
      " \t task.sim.v=[ 21.19548243   0.09783995 -12.96600361],\n",
      " \t action=[899.72053214659718, 899.4941291218521, 0.030622031776432714, -0.23066963690571979], \n",
      " \t task.sim.pose=[ 26.55367571  -0.54709223   0.           2.96494211   4.71710977   0.        ]\n",
      "Episode =   11, total_reward =  -55.02, , z=   0.00, v_z= -11.83, \n",
      " \t score = -1.83 (best = 2.95), total_steps =  30, \n",
      " \t task.sim.v=[  6.63804176   3.63048997 -11.83251167],\n",
      " \t action=[900.28661800909094, 900.11306214219894, 234.06140483867327, 0.50198006272173457], \n",
      " \t task.sim.pose=[ 3.11969082  6.98951968  0.          6.14401242  5.90970197  0.        ]\n",
      "Episode =   12, total_reward =  -53.75, , z=   0.00, v_z= -15.37, \n",
      " \t score = -1.79 (best = 2.95), total_steps =  30, \n",
      " \t task.sim.v=[  0.76178548   4.21323886 -15.36576382],\n",
      " \t action=[900.72132069173892, 900.00374469328995, 869.47564214611828, 0.12630023082041053], \n",
      " \t task.sim.pose=[ 0.19698091  6.82321859  0.          1.27015183  6.22071647  0.        ]\n",
      "Episode =   13, total_reward =  -54.71, , z=   0.00, v_z= -15.56, \n",
      " \t score = -1.82 (best = 2.95), total_steps =  30, \n",
      " \t task.sim.v=[ -1.80133974   3.6086159  -15.56005878],\n",
      " \t action=[900.16730581719924, 900.41929325935746, 782.43333884349897, 0.12595745855133039], \n",
      " \t task.sim.pose=[-1.03916097  6.91117571  0.          1.93061668  0.08558932  0.        ]\n",
      "Episode =   14, total_reward =  -55.82, , z=   0.00, v_z= -15.69, \n",
      " \t score = -1.86 (best = 2.95), total_steps =  30, \n",
      " \t task.sim.v=[  0.42975049   4.19680018 -15.69395692],\n",
      " \t action=[899.96849992521913, 899.64652801456009, 874.07194446171138, -0.38511124876414216], \n",
      " \t task.sim.pose=[ 0.04686632  6.92202774  0.          1.32738176  6.23064621  0.        ]\n",
      "Episode =   15, total_reward =  -54.78, , z=   0.00, v_z= -13.25, \n",
      " \t score = -1.71 (best = 2.95), total_steps =  32, \n",
      " \t task.sim.v=[ -8.08285277   3.90838125 -13.24886625],\n",
      " \t action=[899.95686176155755, 898.493046981411, 869.76707191057517, 7.293262206004937], \n",
      " \t task.sim.pose=[-4.0148464   7.49530753  0.          4.31877579  0.32241871  0.        ]\n",
      "Episode =   16, total_reward =  -55.58, , z=   0.00, v_z= -10.87, \n",
      " \t score = -1.85 (best = 2.95), total_steps =  30, \n",
      " \t task.sim.v=[ -4.88275409   1.52251735 -10.87273704],\n",
      " \t action=[900.08215783254593, 900.42411927272701, 38.688714052091221, -0.036629913527041036], \n",
      " \t task.sim.pose=[-2.77601341  6.4793882   0.          5.92291169  0.20851855  0.        ]\n",
      "Episode =   17, total_reward =  -57.46, , z=   0.00, v_z= -10.16, \n",
      " \t score = -1.85 (best = 2.95), total_steps =  31, \n",
      " \t task.sim.v=[ -4.50770564  11.17449849 -10.15992695],\n",
      " \t action=[900.3847342682476, 899.77552677806329, -0.14120649343815511, 0.68316659902915788], \n",
      " \t task.sim.pose=[-2.2305633   8.82686515  0.          0.4341556   0.2328841   0.        ]\n",
      "Episode =   18, total_reward =  -51.99, , z=   0.00, v_z= -19.31, \n",
      " \t score = -1.79 (best = 2.95), total_steps =  29, \n",
      " \t task.sim.v=[ -0.43185839  -0.12736391 -19.31325791],\n",
      " \t action=[900.32528134796632, 898.81478101225764, 0.23462040759661001, 0.43063236802344501], \n",
      " \t task.sim.pose=[-0.67571775  5.77163905  0.          3.30571759  6.19434719  0.        ]\n",
      "Episode =   19, total_reward =  -41.44, , z=   0.00, v_z= -15.55, \n",
      " \t score = -1.26 (best = 2.95), total_steps =  33, \n",
      " \t task.sim.v=[ -1.42306173  -8.85924847 -15.55087134],\n",
      " \t action=[899.85799507528793, -0.25654035023662625, 0.0066812178726140051, -0.60568521992919355], \n",
      " \t task.sim.pose=[ -1.64793794 -13.23275086   0.           5.91617179   3.19227746   0.        ]\n",
      "Episode =   20, total_reward =  -56.43, , z=   0.00, v_z= -14.54, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.21556680e+00  -2.37644977e-06  -1.45360213e+01],\n",
      " \t action=[899.80518946122129, 0.27465815093488327, 0.093273007987263123, 0.19145272240701958], \n",
      " \t task.sim.pose=[ -2.03844529e+00  -3.85729840e-08   0.00000000e+00   2.24494970e-05\n",
      "   1.92721950e+00   0.00000000e+00]\n",
      "Episode =   21, total_reward =  -56.59, , z=   0.00, v_z= -14.57, \n",
      " \t score = -2.18 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.21832053e+00  -1.83761927e-06  -1.45681596e+01],\n",
      " \t action=[899.80584330332044, 0.35214782531282485, 0.29547556599666569, -0.33388203061466637], \n",
      " \t task.sim.pose=[ -2.04782976e+00  -2.84149586e-07   0.00000000e+00   1.67443596e-05\n",
      "   1.95206777e+00   0.00000000e+00]\n",
      "Episode =   22, total_reward =  -56.29, , z=   0.00, v_z= -14.51, \n",
      " \t score = -2.16 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.20740531e+00  -5.04994697e-06  -1.45095396e+01],\n",
      " \t action=[899.94955136111298, 1.4101437097695628, 0.082099088425325428, -0.17306303463002465], \n",
      " \t task.sim.pose=[ -2.02116568e+00  -6.32944444e-07   0.00000000e+00   4.31393521e-05\n",
      "   1.90407694e+00   0.00000000e+00]\n",
      "Episode =   23, total_reward =  -56.36, , z=   0.00, v_z= -14.52, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.21872268e+00   3.48344122e-06  -1.45248258e+01],\n",
      " \t action=[899.26355868011763, -0.39889136480974197, -0.32675514480164414, 0.36540270362191135], \n",
      " \t task.sim.pose=[ -2.03761726e+00   3.54222021e-08   0.00000000e+00   6.28314420e+00\n",
      "   1.90466161e+00   0.00000000e+00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =   24, total_reward =  -56.38, , z=   0.00, v_z= -14.53, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.20582790e+00  -1.21945572e-06  -1.45293772e+01],\n",
      " \t action=[899.77027480377262, 3.3110806204905217, -0.61585952970951663, -0.38408087649442491], \n",
      " \t task.sim.pose=[ -2.02083982e+00   6.46353305e-08   0.00000000e+00   1.65030764e-05\n",
      "   1.91737957e+00   0.00000000e+00]\n",
      "Episode =   25, total_reward =  -56.34, , z=   0.00, v_z= -14.52, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.20466822e+00   1.82070404e-06  -1.45175540e+01],\n",
      " \t action=[900.19773671722248, 3.2661162525736658, 0.20237264810473027, -0.25047808882787304], \n",
      " \t task.sim.pose=[ -2.01949235e+00   1.79278040e-07   0.00000000e+00   6.28316784e+00\n",
      "   1.91598788e+00   0.00000000e+00]\n",
      "Episode =   26, total_reward =  -56.28, , z=   0.00, v_z= -16.17, \n",
      " \t score = -2.16 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.73535320e+00   3.70024169e-05  -1.61690869e+01],\n",
      " \t action=[900.34751784054686, 899.10999191774886, -0.035999339843630046, -0.70240737517521779], \n",
      " \t task.sim.pose=[ -2.61629417e+00   1.92319381e-08   0.00000000e+00   6.28316903e+00\n",
      "   3.59576412e+00   0.00000000e+00]\n",
      "Episode =   27, total_reward =  -51.07, , z=   0.00, v_z= -19.08, \n",
      " \t score = -2.13 (best = 2.95), total_steps =  24, \n",
      " \t task.sim.v=[ -5.37737068e+00   6.73921005e-05  -1.90779095e+01],\n",
      " \t action=[900.31709513455007, 898.94311325880176, 0.12806585007268201, -0.50323809953158649], \n",
      " \t task.sim.pose=[ -1.77056553e+00   1.63781336e-05   0.00000000e+00   6.28317237e+00\n",
      "   1.18364162e+00   0.00000000e+00]\n",
      "Episode =   28, total_reward =  -54.36, , z=   0.00, v_z= -17.80, \n",
      " \t score = -2.09 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[  3.08769453e+00  -6.70042670e-05  -1.77994880e+01],\n",
      " \t action=[877.1870117741538, 813.4105767248916, 2.2008317906646391, 0.10842584728978943], \n",
      " \t task.sim.pose=[ -3.15426337e-01  -6.58321361e-06   0.00000000e+00   1.92305278e-05\n",
      "   1.84033558e+00   0.00000000e+00]\n",
      "Episode =   29, total_reward =  -59.23, , z=   0.00, v_z= -11.39, \n",
      " \t score = -2.19 (best = 2.95), total_steps =  27, \n",
      " \t task.sim.v=[  3.82483254e+00  -1.98419856e-05  -1.13938672e+01],\n",
      " \t action=[883.55851280393131, 899.73743418507934, -0.22580510360787343, 0.18435833277933103], \n",
      " \t task.sim.pose=[ -1.35258790e+00  -9.22551394e-06   0.00000000e+00   6.28316701e+00\n",
      "   4.04465429e+00   0.00000000e+00]\n",
      "Episode =   30, total_reward =  -55.68, , z=   0.00, v_z= -14.08, \n",
      " \t score = -2.14 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -2.05862517e+00   1.13357048e-06  -1.40816096e+01],\n",
      " \t action=[59.228664769149695, 899.66472588017518, -0.26836952838971007, 0.77604123216697163], \n",
      " \t task.sim.pose=[ -2.79759419e+00  -1.79737867e-06   0.00000000e+00   6.28314455e+00\n",
      "   6.19457614e+00   0.00000000e+00]\n",
      "Episode =   31, total_reward =  -56.26, , z=   0.00, v_z= -10.59, \n",
      " \t score = -2.16 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[  1.07671983e-03  -2.04033422e-05  -1.05907590e+01],\n",
      " \t action=[847.19407901410807, 885.38354656373792, -0.13751191920537109, -0.089112456440351262], \n",
      " \t task.sim.pose=[ -1.97438983e+00  -2.41226397e-06   0.00000000e+00   6.28317937e+00\n",
      "   1.64563276e-02   0.00000000e+00]\n",
      "Episode =   32, total_reward =  -56.36, , z=   0.00, v_z= -13.53, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -9.35880079e-01  -5.78742831e-05  -1.35317021e+01],\n",
      " \t action=[4.269250528444414, 899.22774787777473, -0.0072224911016254834, -0.28169192747617328], \n",
      " \t task.sim.pose=[ -2.06272011e+00  -1.82537962e-06   0.00000000e+00   6.28301462e+00\n",
      "   4.08515706e+00   0.00000000e+00]\n",
      "Episode =   33, total_reward =  -56.41, , z=   0.00, v_z= -14.47, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.87102111e+00   2.45528575e-06  -1.44730956e+01],\n",
      " \t action=[1.6532092666295533, 892.97593600058804, 0.4885000915065878, 0.11930998554759589], \n",
      " \t task.sim.pose=[ -2.14038870e+00   1.62451703e-06   0.00000000e+00   6.28297863e+00\n",
      "   1.82530406e+00   0.00000000e+00]\n",
      "Episode =   34, total_reward =  -54.59, , z=   0.00, v_z= -15.84, \n",
      " \t score = -2.18 (best = 2.95), total_steps =  25, \n",
      " \t task.sim.v=[ -1.01756141e+00   1.65802618e-05  -1.58380674e+01],\n",
      " \t action=[0.19603695170603935, 691.47707489428353, -0.6909219129608013, -0.65290763620854908], \n",
      " \t task.sim.pose=[ -5.56371396e-01   5.90789012e-06   0.00000000e+00   6.28317101e+00\n",
      "   1.21305703e+00   0.00000000e+00]\n",
      "Episode =   35, total_reward =  -56.52, , z=   0.00, v_z= -16.99, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[  4.88629416e-01   1.38709501e-05  -1.69911793e+01],\n",
      " \t action=[1.1419278828253874, 328.06531498219078, 0.50285058183589615, 0.25248100333791434], \n",
      " \t task.sim.pose=[ -3.59821498e-01   1.78913949e-06   0.00000000e+00   6.28318033e+00\n",
      "   4.67640184e-01   0.00000000e+00]\n",
      "Episode =   36, total_reward =  -59.08, , z=   0.00, v_z= -13.56, \n",
      " \t score = -2.11 (best = 2.95), total_steps =  28, \n",
      " \t task.sim.v=[ -1.34743512e+00  -4.68769087e-06  -1.35624471e+01],\n",
      " \t action=[0.78670005768310802, 810.54231272679067, 1.7948683572197588, 0.029585674510714477], \n",
      " \t task.sim.pose=[ -2.68310853e+00  -3.62433272e-06   0.00000000e+00   6.28315318e+00\n",
      "   1.31080009e+00   0.00000000e+00]\n",
      "Episode =   37, total_reward =  -59.61, , z=   0.00, v_z= -13.86, \n",
      " \t score = -2.13 (best = 2.95), total_steps =  28, \n",
      " \t task.sim.v=[ -3.63737265e+00   2.69486406e-06  -1.38593250e+01],\n",
      " \t action=[0.024348374571163733, 890.60189274781078, 2.6429264476328025, 0.56823403993159149], \n",
      " \t task.sim.pose=[ -4.36890996e+00  -2.35591218e-07   0.00000000e+00   6.28312873e+00\n",
      "   5.16243562e+00   0.00000000e+00]\n",
      "Episode =   38, total_reward =  -57.13, , z=   0.00, v_z= -14.38, \n",
      " \t score = -2.12 (best = 2.95), total_steps =  27, \n",
      " \t task.sim.v=[ -2.97481258e+00  -2.36369149e-06  -1.43846328e+01],\n",
      " \t action=[1.2927719521199648, 877.34006907474622, 1.9090687310879444, 0.098873784172986798], \n",
      " \t task.sim.pose=[ -3.86792118e+00  -3.60834544e-06   0.00000000e+00   6.28317423e+00\n",
      "   3.55073334e+00   0.00000000e+00]\n",
      "Episode =   39, total_reward =  -59.10, , z=   0.00, v_z= -12.88, \n",
      " \t score = -2.19 (best = 2.95), total_steps =  27, \n",
      " \t task.sim.v=[ -1.00913294e+00   6.98587280e-06  -1.28759380e+01],\n",
      " \t action=[1.121141189184411, 795.73716739103463, -0.072081122872369452, -0.098895032254490492], \n",
      " \t task.sim.pose=[ -1.61739505e+00   5.23448687e-07   0.00000000e+00   6.28308122e+00\n",
      "   1.22259252e+00   0.00000000e+00]\n",
      "Episode =   40, total_reward =  -56.56, , z=   0.00, v_z= -14.75, \n",
      " \t score = -2.18 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -2.24705149e+00   1.33220160e-06  -1.47528202e+01],\n",
      " \t action=[-0.16521844542027692, 897.51944532412392, 1.445541616927144, 0.28448879921467862], \n",
      " \t task.sim.pose=[ -2.68523932e+00   1.50187089e-06   0.00000000e+00   6.28314717e+00\n",
      "   1.63221591e+00   0.00000000e+00]\n",
      "Episode =   41, total_reward =  -54.80, , z=   0.00, v_z= -14.65, \n",
      " \t score = -2.19 (best = 2.95), total_steps =  25, \n",
      " \t task.sim.v=[ -1.89263823e+00   7.59432976e-06  -1.46509938e+01],\n",
      " \t action=[1.0021951985426276, 868.78522096358256, -0.2710966500408426, -0.34960289380339937], \n",
      " \t task.sim.pose=[ -1.73445344e+00   5.49433945e-07   0.00000000e+00   6.28316681e+00\n",
      "   6.22709373e+00   0.00000000e+00]\n",
      "Episode =   42, total_reward =  -56.39, , z=   0.00, v_z= -14.80, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -9.05110336e-01   1.48719040e-06  -1.48012333e+01],\n",
      " \t action=[1.6644707734090216, 863.22893131558419, 0.95168258800003436, -0.20977273357361434], \n",
      " \t task.sim.pose=[ -1.89816501e+00   4.49283010e-07   0.00000000e+00   6.28317830e+00\n",
      "   2.30829370e+00   0.00000000e+00]\n",
      "Episode =   43, total_reward =  -55.87, , z=   0.00, v_z= -14.18, \n",
      " \t score = -2.15 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.09038124e+00   1.09416153e-05  -1.41767920e+01],\n",
      " \t action=[0.62326593685000276, 861.48527899855503, 1.0028434708985778, -0.00097944359191623476], \n",
      " \t task.sim.pose=[ -1.78239580e+00   4.46145613e-06   0.00000000e+00   6.28303617e+00\n",
      "   2.30874538e+00   0.00000000e+00]\n",
      "Episode =   44, total_reward =  -57.65, , z=   0.00, v_z= -14.00, \n",
      " \t score = -2.06 (best = 2.95), total_steps =  28, \n",
      " \t task.sim.v=[  1.47673485e+00   2.46118259e-05  -1.40044204e+01],\n",
      " \t action=[598.84832238433432, 3.3051661054961801, -0.69536601690122235, -0.028226779298608472], \n",
      " \t task.sim.pose=[  1.59697457e+00   2.54419830e-06   0.00000000e+00   4.94847539e-05\n",
      "   4.67232120e-01   0.00000000e+00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =   45, total_reward =  -56.70, , z=   0.00, v_z= -14.40, \n",
      " \t score = -2.02 (best = 2.95), total_steps =  28, \n",
      " \t task.sim.v=[  2.44829662e+00  -5.46756449e-07  -1.44004440e+01],\n",
      " \t action=[900.02168775498671, -0.0024474064169439091, 0.43674260652412078, -0.81245225478794736], \n",
      " \t task.sim.pose=[  2.23433529e+00   1.66157144e-06   0.00000000e+00   1.08299230e-05\n",
      "   5.68588953e-01   0.00000000e+00]\n",
      "Episode =   46, total_reward =  -58.87, , z=   0.00, v_z= -13.77, \n",
      " \t score = -2.10 (best = 2.95), total_steps =  28, \n",
      " \t task.sim.v=[ -1.20568330e+00   2.26234904e-05  -1.37741503e+01],\n",
      " \t action=[0.73967587397892054, 892.61476277109978, -0.23120531956095658, -0.089108851558264077], \n",
      " \t task.sim.pose=[ -2.15604661e+00   2.01219894e-06   0.00000000e+00   6.28297866e+00\n",
      "   4.73794698e+00   0.00000000e+00]\n",
      "Episode =   47, total_reward =  -55.19, , z=   0.00, v_z= -12.92, \n",
      " \t score = -2.12 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -4.48369594e-01   2.62745329e-05  -1.29203745e+01],\n",
      " \t action=[27.675557994810013, 644.7016924747162, 18.743864807791823, 0.22840879688429194], \n",
      " \t task.sim.pose=[ -8.96977318e-01   3.10231892e-06   0.00000000e+00   6.28299998e+00\n",
      "   1.87753235e+00   0.00000000e+00]\n",
      "Episode =   48, total_reward =  -55.19, , z=   0.00, v_z= -14.42, \n",
      " \t score = -1.97 (best = 2.95), total_steps =  28, \n",
      " \t task.sim.v=[ -9.77775687e-01   3.98763302e-06  -1.44153698e+01],\n",
      " \t action=[0.52346494996410031, 897.07949844941004, 0.5155070876596084, 0.034338467761416469], \n",
      " \t task.sim.pose=[ -8.32479229e-01   5.17428638e-07   0.00000000e+00   6.28317102e+00\n",
      "   3.88281247e+00   0.00000000e+00]\n",
      "Episode =   49, total_reward =  -58.42, , z=   0.00, v_z= -14.20, \n",
      " \t score = -2.09 (best = 2.95), total_steps =  28, \n",
      " \t task.sim.v=[ -3.07926370e+00   5.23860430e-07  -1.42022324e+01],\n",
      " \t action=[0.24433448185111128, 872.16115932842524, 2.4161982636147661, 0.0033042358103735209], \n",
      " \t task.sim.pose=[ -3.46713788e+00  -6.31293586e-07   0.00000000e+00   6.28316710e+00\n",
      "   2.71007589e+00   0.00000000e+00]\n",
      "Episode =   50, total_reward =  -58.78, , z=   0.00, v_z= -13.55, \n",
      " \t score = -2.18 (best = 2.95), total_steps =  27, \n",
      " \t task.sim.v=[ -2.67197990e+00   6.50821436e-06  -1.35491741e+01],\n",
      " \t action=[-0.15041158206753569, 895.18779482601769, 0.3466552930444855, 0.38424757617171368], \n",
      " \t task.sim.pose=[ -3.16823225e+00   2.37337475e-06   0.00000000e+00   6.28311367e+00\n",
      "   2.59344251e+00   0.00000000e+00]\n",
      "Episode =   51, total_reward =  -56.16, , z=   0.00, v_z= -14.41, \n",
      " \t score = -2.25 (best = 2.95), total_steps =  25, \n",
      " \t task.sim.v=[ -1.66743493e+00   2.49126787e-07  -1.44145853e+01],\n",
      " \t action=[0.37535008904388978, 899.77210454054546, 0.16385609491161823, 0.11466925451092697], \n",
      " \t task.sim.pose=[ -1.36437308e+00   5.34652482e-07   0.00000000e+00   6.28317832e+00\n",
      "   1.33523402e+00   0.00000000e+00]\n",
      "Episode =   52, total_reward =  -54.16, , z=   0.00, v_z= -15.05, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  25, \n",
      " \t task.sim.v=[ -2.51539470e+00   1.17500693e-06  -1.50509250e+01],\n",
      " \t action=[0.89443594790751446, 889.74696808979434, 0.12147789702280209, 0.064921921876411867], \n",
      " \t task.sim.pose=[ -2.97655144e+00   1.03945161e-06   0.00000000e+00   6.28317367e+00\n",
      "   2.15587477e+00   0.00000000e+00]\n",
      "Episode =   53, total_reward =  -57.91, , z=   0.00, v_z= -14.13, \n",
      " \t score = -2.14 (best = 2.95), total_steps =  27, \n",
      " \t task.sim.v=[ -2.54960535e+00   2.19391532e-07  -1.41279476e+01],\n",
      " \t action=[-0.18528441637628557, 897.89737319144217, 0.96404396046796736, -0.085939653537377814], \n",
      " \t task.sim.pose=[ -2.66750590e+00   1.93267962e-07   0.00000000e+00   6.28318275e+00\n",
      "   3.14841923e+00   0.00000000e+00]\n",
      "Episode =   54, total_reward =  -56.84, , z=   0.00, v_z= -14.01, \n",
      " \t score = -2.11 (best = 2.95), total_steps =  27, \n",
      " \t task.sim.v=[ -1.31937943e+00  -3.21774454e-06  -1.40123866e+01],\n",
      " \t action=[0.63886445709032658, 886.71367593222328, 0.51785715779194708, 0.084204269187024894], \n",
      " \t task.sim.pose=[ -2.19112222e+00  -1.39208969e-06   0.00000000e+00   6.28317080e+00\n",
      "   1.91279017e+00   0.00000000e+00]\n",
      "Episode =   55, total_reward =  -59.78, , z=   0.00, v_z= -13.80, \n",
      " \t score = -2.06 (best = 2.95), total_steps =  29, \n",
      " \t task.sim.v=[  1.22918405e+00  -7.18782000e-06  -1.38005195e+01],\n",
      " \t action=[6.1309563849994477, 693.46969831962019, 0.0631269093845645, 0.26495441056645175], \n",
      " \t task.sim.pose=[  1.62934879e+00  -6.92788478e-06   0.00000000e+00   6.28317592e+00\n",
      "   2.46285280e+00   0.00000000e+00]\n",
      "Episode =   56, total_reward =  -56.83, , z=   0.00, v_z= -13.73, \n",
      " \t score = -2.10 (best = 2.95), total_steps =  27, \n",
      " \t task.sim.v=[ -1.15904421e+00  -3.34419982e-06  -1.37348797e+01],\n",
      " \t action=[-0.03269198511349064, 898.78889413957802, -0.57994030983687361, -0.10542950032956691], \n",
      " \t task.sim.pose=[ -2.23142807e+00   1.28445624e-06   0.00000000e+00   6.28315603e+00\n",
      "   1.65818003e+00   0.00000000e+00]\n",
      "Episode =   57, total_reward =  -57.02, , z=   0.00, v_z= -14.54, \n",
      " \t score = -2.19 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -7.02208642e-01  -2.14476524e-06  -1.45422693e+01],\n",
      " \t action=[0.56902277634986287, 900.56849111558881, -0.10775458780944303, 0.28687687805001238], \n",
      " \t task.sim.pose=[ -8.28436830e-01   7.16623252e-07   0.00000000e+00   6.28315693e+00\n",
      "   3.28072052e-01   0.00000000e+00]\n",
      "Episode =   58, total_reward =  -58.02, , z=   0.00, v_z= -13.95, \n",
      " \t score = -2.07 (best = 2.95), total_steps =  28, \n",
      " \t task.sim.v=[ -1.19295291e+00  -2.47092284e-07  -1.39507549e+01],\n",
      " \t action=[0.54861205150682513, 898.37675043238607, 0.23612364936897928, -0.10707026264083275], \n",
      " \t task.sim.pose=[ -1.93710243e+00  -1.96584038e-06   0.00000000e+00   6.28314925e+00\n",
      "   2.88202523e+00   0.00000000e+00]\n",
      "Episode =   59, total_reward =  -58.01, , z=   0.00, v_z= -14.30, \n",
      " \t score = -2.15 (best = 2.95), total_steps =  27, \n",
      " \t task.sim.v=[ -1.18284040e+00  -9.20924833e-06  -1.42964897e+01],\n",
      " \t action=[-0.19543880941614561, 899.9865882683863, 0.47179859169836869, 0.13168030666318381], \n",
      " \t task.sim.pose=[ -2.25898903e+00   7.14705951e-07   0.00000000e+00   6.28308783e+00\n",
      "   7.35463179e-01   0.00000000e+00]\n",
      "Episode =   60, total_reward =  -55.79, , z=   0.00, v_z= -15.55, \n",
      " \t score = -2.07 (best = 2.95), total_steps =  27, \n",
      " \t task.sim.v=[ -2.42682106e-01   4.20684060e-05  -1.55480167e+01],\n",
      " \t action=[0.3870928758207739, 899.27955419350724, -0.36723872387749651, -0.35274623428877228], \n",
      " \t task.sim.pose=[ -3.73714096e-01   1.63237260e-06   0.00000000e+00   6.28307693e+00\n",
      "   8.20424057e-01   0.00000000e+00]\n",
      "Episode =   61, total_reward =  -58.31, , z=   0.00, v_z= -14.12, \n",
      " \t score = -2.16 (best = 2.95), total_steps =  27, \n",
      " \t task.sim.v=[ -3.79006130e-01  -5.62847142e-06  -1.41163669e+01],\n",
      " \t action=[-0.13513732708980941, 899.87137575491568, -0.13786278021306275, -0.03312924654987677], \n",
      " \t task.sim.pose=[ -9.34145723e-01  -2.29687160e-06   0.00000000e+00   6.28314973e+00\n",
      "   8.49447035e-02   0.00000000e+00]\n",
      "Episode =   62, total_reward =  -56.09, , z=   0.00, v_z= -12.79, \n",
      " \t score = -2.16 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -2.04244338e-01   7.82694085e-05  -1.27898530e+01],\n",
      " \t action=[0.2839833755712789, 896.8936506514267, 0.4306042203743039, -0.061376380539981401], \n",
      " \t task.sim.pose=[ -5.32805406e-01   1.00601257e-05   0.00000000e+00   6.28287896e+00\n",
      "   4.61441252e+00   0.00000000e+00]\n",
      "Episode =   63, total_reward =  -54.34, , z=   0.00, v_z= -14.67, \n",
      " \t score = -1.94 (best = 2.95), total_steps =  28, \n",
      " \t task.sim.v=[ -7.88094717e-01   6.52599915e-06  -1.46740380e+01],\n",
      " \t action=[0.48023661737690759, 897.71205146205034, 0.45156808970022999, -0.19797108644179218], \n",
      " \t task.sim.pose=[ -1.36075614e-01   1.86859245e-06   0.00000000e+00   6.28317877e+00\n",
      "   3.61433606e+00   0.00000000e+00]\n",
      "Episode =   64, total_reward =  -57.41, , z=   0.00, v_z= -14.19, \n",
      " \t score = -2.13 (best = 2.95), total_steps =  27, \n",
      " \t task.sim.v=[ -8.33187671e-01   6.03482574e-07  -1.41863224e+01],\n",
      " \t action=[-0.4088382689015625, 898.30333357890345, -0.047250226679532131, 0.41087252366222737], \n",
      " \t task.sim.pose=[ -1.33244253e+00  -3.71289363e-07   0.00000000e+00   6.28316985e+00\n",
      "   3.58693366e+00   0.00000000e+00]\n",
      "Episode =   65, total_reward =  -54.47, , z=   0.00, v_z= -14.72, \n",
      " \t score = -2.18 (best = 2.95), total_steps =  25, \n",
      " \t task.sim.v=[ -2.91865403e-02   1.43577793e-06  -1.47155870e+01],\n",
      " \t action=[-0.15341187426264324, 900.40567343997986, 0.39904584371763852, -0.2008936921171452], \n",
      " \t task.sim.pose=[  1.19931566e-02   1.16817802e-06   0.00000000e+00   6.28317804e+00\n",
      "   5.21682484e-01   0.00000000e+00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =   66, total_reward =  -58.28, , z=   0.00, v_z= -13.99, \n",
      " \t score = -2.16 (best = 2.95), total_steps =  27, \n",
      " \t task.sim.v=[ -1.23313875e+00   1.18997791e-05  -1.39945461e+01],\n",
      " \t action=[0.33588737898302767, 899.53557454181373, 0.94845386275381904, -0.66500932635939902], \n",
      " \t task.sim.pose=[ -2.10600713e+00  -1.45664762e-04   0.00000000e+00   6.27884622e+00\n",
      "   5.38277236e+00   0.00000000e+00]\n",
      "Episode =   67, total_reward =  -55.44, , z=   0.00, v_z= -13.81, \n",
      " \t score = -2.13 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.71993489  -0.09351868 -13.80754727],\n",
      " \t action=[26.267989214780108, 0.28569012074885608, 141.05201259228545, -0.12710853603988187], \n",
      " \t task.sim.pose=[-1.26643364 -0.00227427  0.          0.80347053  0.76201955  0.        ]\n",
      "Episode =   68, total_reward =  -56.32, , z=   0.00, v_z= -13.92, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -2.39374682   0.62950131 -13.91666916],\n",
      " \t action=[41.594480593253031, 8.6873194202767099, 412.4927283131139, -0.16252846267704266], \n",
      " \t task.sim.pose=[-2.24747872  0.10529774  0.          1.67121397  4.19844557  0.        ]\n",
      "Episode =   69, total_reward =  -56.50, , z=   0.00, v_z= -14.63, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.68261072e+00  -3.74522829e-05  -1.46281143e+01],\n",
      " \t action=[-0.16153800320808395, 891.13290016553083, -0.17947459051561016, 0.57087090567984422], \n",
      " \t task.sim.pose=[ -2.21933248e+00   2.41675587e-06   0.00000000e+00   6.28280838e+00\n",
      "   5.78631361e+00   0.00000000e+00]\n",
      "Episode =   70, total_reward =  -56.33, , z=   0.00, v_z= -14.45, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -2.17637771  -0.2802316  -14.44511121],\n",
      " \t action=[0.75412840255645797, 821.75322318439123, 10.50558921747213, 0.38710771584321363], \n",
      " \t task.sim.pose=[ -2.18838378e+00   1.99190123e-03   0.00000000e+00   4.59291296e+00\n",
      "   4.11235819e+00   0.00000000e+00]\n",
      "Episode =   71, total_reward =  -58.47, , z=   0.00, v_z= -14.04, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  27, \n",
      " \t task.sim.v=[  2.71885918   1.1518485  -14.03880285],\n",
      " \t action=[0.85273946767670394, 613.17211504025431, 895.87537573128111, -0.14588463060707355], \n",
      " \t task.sim.pose=[ 0.18681198  0.34518868  0.          1.71115053  0.74320075  0.        ]\n",
      "Episode =   72, total_reward =  -56.36, , z=   0.00, v_z= -14.02, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[  1.61618076   2.08945093 -14.01715821],\n",
      " \t action=[1.6220813130461145, 879.88821428646395, 539.64482759067357, 0.45255265305366188], \n",
      " \t task.sim.pose=[ 0.30855162  2.00556216  0.          2.53661623  0.47209892  0.        ]\n",
      "Episode =   73, total_reward =  -56.05, , z=   0.00, v_z= -13.41, \n",
      " \t score = -2.16 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[  0.09635735   2.4846641  -13.40635685],\n",
      " \t action=[899.9261323330536, 1.6591487329636736, 0.13964801518041384, 0.13903069130315551], \n",
      " \t task.sim.pose=[ 0.09121405  2.44109605  0.          3.5300791   3.82489235  0.        ]\n",
      "Episode =   74, total_reward =  -58.65, , z=   0.00, v_z= -13.28, \n",
      " \t score = -1.83 (best = 2.95), total_steps =  32, \n",
      " \t task.sim.v=[ -0.47469888   6.05044314 -13.27529845],\n",
      " \t action=[899.53811543118991, 0.26722127205801394, -0.27406784745072055, 0.59941741068040155], \n",
      " \t task.sim.pose=[ -1.4563255   10.02697792   0.           6.26108324   3.16557249   0.        ]\n",
      "Episode =   75, total_reward =  -56.41, , z=   0.00, v_z= -15.39, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.47202068   0.6985202  -15.38765635],\n",
      " \t action=[39.018862821950023, 893.01543643009325, 60.131542120835327, 0.5635731970805582], \n",
      " \t task.sim.pose=[-2.04008029  0.18883861  0.          4.64382696  4.19025649  0.        ]\n",
      "Episode =   76, total_reward =  -56.69, , z=   0.00, v_z= -14.75, \n",
      " \t score = -2.18 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.02211691e+00   6.74463018e-06  -1.47483958e+01],\n",
      " \t action=[899.83155194212566, 94.52164547088617, -0.15286558355014637, 0.22464146600944976], \n",
      " \t task.sim.pose=[ -2.03720687e+00   1.34823090e-06   0.00000000e+00   6.28315784e+00\n",
      "   1.67035671e-01   0.00000000e+00]\n",
      "Episode =   77, total_reward =  -56.25, , z=   0.00, v_z= -14.50, \n",
      " \t score = -2.16 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.20575859e+00   1.61366547e-07  -1.45035032e+01],\n",
      " \t action=[900.60389621689035, -0.15028517339655278, 0.12931646421177292, 0.30634982537580202], \n",
      " \t task.sim.pose=[ -2.01586128e+00  -1.04515770e-08   0.00000000e+00   6.28318428e+00\n",
      "   1.88965880e+00   0.00000000e+00]\n",
      "Episode =   78, total_reward =  -56.43, , z=   0.00, v_z= -14.53, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.21000857e+00   1.54459188e-06  -1.45335074e+01],\n",
      " \t action=[899.94624352918618, -0.18338440025067443, -0.13861003253862869, -0.6492751660134084], \n",
      " \t task.sim.pose=[ -2.03091153e+00   4.02518327e-07   0.00000000e+00   6.28317568e+00\n",
      "   1.93708802e+00   0.00000000e+00]\n",
      "Episode =   79, total_reward =  -56.20, , z=   0.00, v_z= -14.48, \n",
      " \t score = -2.16 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.20379816e+00   9.27668828e-07  -1.44847336e+01],\n",
      " \t action=[899.03978038745663, -0.87152349034256682, -0.092105269473336443, 0.58081379664089483], \n",
      " \t task.sim.pose=[ -2.01566440e+00  -1.97116646e-07   0.00000000e+00   6.28317927e+00\n",
      "   1.90427300e+00   0.00000000e+00]\n",
      "Episode =   80, total_reward =  -56.45, , z=   0.00, v_z= -14.54, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -1.21261712e+00   1.03790966e-05  -1.45379526e+01],\n",
      " \t action=[900.1149353312843, -0.21060303427043081, 0.25187161842031686, -0.021839934232348451], \n",
      " \t task.sim.pose=[ -2.03415869e+00  -1.88140766e-07   0.00000000e+00   6.28310604e+00\n",
      "   1.93244362e+00   0.00000000e+00]\n",
      "Episode =   81, total_reward =  -56.48, , z=   0.00, v_z= -14.50, \n",
      " \t score = -2.17 (best = 2.95), total_steps =  26, \n",
      " \t task.sim.v=[ -0.7400753   -0.30242949 -14.50153447],\n",
      " \t action=[900.06983550319694, 0.19403279719474459, 687.33130833806638, 0.44246209312898221], \n",
      " \t task.sim.pose=[-1.88132548  0.0112514   0.          2.76764596  1.94031479  0.        ]\n",
      "Episode =   82, total_reward =  -49.18, , z=   0.00, v_z= -14.59, \n",
      " \t score = -2.14 (best = 2.95), total_steps =  23, \n",
      " \t task.sim.v=[ -1.95700809  -1.52431955 -14.5891648 ],\n",
      " \t action=[899.69581363664713, 0.24420554083216539, 899.2935284567161, 900.221463777243], \n",
      " \t task.sim.pose=[-1.4967775  -1.22921048  0.          2.3876759   0.80282146  0.        ]\n",
      "Episode =   83, total_reward =  -53.66, , z=   0.00, v_z= -14.51, \n",
      " \t score = -1.85 (best = 2.95), total_steps =  29, \n",
      " \t task.sim.v=[ -3.46294752  -0.01607903 -14.51006313],\n",
      " \t action=[899.47233767402929, -0.11928638569689717, 899.55403886431588, 899.8299528225109], \n",
      " \t task.sim.pose=[ -7.00489430e+00  -4.21133458e-03   0.00000000e+00   6.16657600e+00\n",
      "   3.02278860e+00   0.00000000e+00]\n",
      "Episode =   84, total_reward =  -60.67, , z=   0.00, v_z= -13.32, \n",
      " \t score = -1.38 (best = 2.95), total_steps =  44, \n",
      " \t task.sim.v=[-13.38381473  -7.61223561 -13.32152781],\n",
      " \t action=[899.14975879854433, 0.41372622304250528, 899.6694252406794, -0.12172838190904928], \n",
      " \t task.sim.pose=[-25.11918664  -2.28638401   0.           3.11401387   4.4321692    0.        ]\n",
      "Episode =   85, total_reward =  171.51, , z=  35.53, v_z=   9.26, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76473883  1.41948047  9.25999794],\n",
      " \t action=[900.22411886391217, 0.12612769888826661, 900.06034213436124, -0.0056064485155288696], \n",
      " \t task.sim.pose=[-13.42942557   2.3334131   35.52963416   2.13872903   2.09436391   0.        ]\n",
      "Episode =   86, total_reward =  171.10, , z=  35.51, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80626718 -2.02613325  9.28539131],\n",
      " \t action=[899.74324232068591, 0.11185312707736261, 900.25350013691855, 0.41310478900154074], \n",
      " \t task.sim.pose=[-13.53653947  -4.42433622  35.51057915   2.07520806   2.13436397   0.        ]\n",
      "Episode =   87, total_reward =  171.23, , z=  35.60, v_z=   9.37, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88551532 -1.59817725  9.36626254],\n",
      " \t action=[900.09909562906626, -0.73082779322634583, 900.06072597610728, 0.57966648738057613], \n",
      " \t task.sim.pose=[-13.70474562  -6.50417858  35.5957992    2.09458835   2.08949089   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =   88, total_reward =  171.32, , z=  35.54, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77395412  0.95583862  9.29048883],\n",
      " \t action=[899.77904472761475, -0.070434131423095681, 900.13047888091285, -0.098466432884433672], \n",
      " \t task.sim.pose=[-13.37469541   1.57144877  35.53822072   2.10949126   2.07248157   0.        ]\n",
      "Episode =   89, total_reward =  171.84, , z=  35.67, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78857421  0.47946566  9.32631085],\n",
      " \t action=[900.64255419004974, -0.18577823613008776, 899.63295307032809, 0.37802412221328169], \n",
      " \t task.sim.pose=[-13.43705466  -0.78209679  35.66923951   2.14862548   2.09574242   0.        ]\n",
      "Episode =   90, total_reward =  171.36, , z=  35.53, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73587827  0.16885087  9.29737127],\n",
      " \t action=[899.91875233532164, 0.42976912344341917, 900.09338408865278, 0.17274693372044675], \n",
      " \t task.sim.pose=[-13.35430862   0.49307773  35.53254044   2.13830401   2.14468292   0.        ]\n",
      "Episode =   91, total_reward =  172.56, , z=  35.83, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83822959 -2.00622866  9.37305775],\n",
      " \t action=[900.13389216073699, 0.23943360260123339, 899.75671319945548, 0.013456495555859344], \n",
      " \t task.sim.pose=[-13.63465562  -6.01059243  35.82761173   2.1252608    2.13497212   0.        ]\n",
      "Episode =   92, total_reward =  171.62, , z=  35.62, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77343797  0.20744611  9.32634244],\n",
      " \t action=[899.91621582587391, -0.2677647899691738, 899.65786323180237, -0.53362290648478072], \n",
      " \t task.sim.pose=[-13.35276758   0.06430311  35.62450493   2.10951536   2.08508597   0.        ]\n",
      "Episode =   93, total_reward =  171.66, , z=  35.64, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78243658 -1.33141205  9.32049175],\n",
      " \t action=[899.21904312650906, -0.34080621109340997, 899.83844685997758, -0.095900706365925237], \n",
      " \t task.sim.pose=[-13.44557937  -2.80244809  35.63754357   2.09019373   2.1314522    0.        ]\n",
      "Episode =   94, total_reward =  169.30, , z=  35.20, v_z=   9.31, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86592374 -1.95645854  9.30918907],\n",
      " \t action=[900.326104102513, -0.59411319693515607, 900.20455862005917, -0.43147969251913526], \n",
      " \t task.sim.pose=[-13.45443433  -6.47831733  35.19789849   2.0494487    2.05087818   0.        ]\n",
      "Episode =   95, total_reward =  171.96, , z=  35.69, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76902159  0.02732773  9.33890236],\n",
      " \t action=[899.94655628074315, -0.56232440192219657, 900.02896712945085, -0.35312521265817176], \n",
      " \t task.sim.pose=[-13.3999066   -0.6684813   35.69028365   2.13479583   2.11349191   0.        ]\n",
      "Episode =   96, total_reward =  170.64, , z=  35.40, v_z=   9.26, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77238336  0.96583122  9.26173925],\n",
      " \t action=[899.41569395028034, 0.01985495770057627, 899.160797561241, 0.68432741293107902], \n",
      " \t task.sim.pose=[-13.32063649   1.41624092  35.39796449   2.11601772   2.06299857   0.        ]\n",
      "Episode =   97, total_reward =  172.47, , z=  35.80, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80483588 -1.71279177  9.35368623],\n",
      " \t action=[899.76506438890772, -0.3524681146507388, 900.23836960261076, -0.34846785559739613], \n",
      " \t task.sim.pose=[-13.50157799  -4.07986346  35.79995819   2.10198531   2.12658693   0.        ]\n",
      "Episode =   98, total_reward =  170.56, , z=  35.32, v_z=   9.20, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88130642 -4.16291862  9.2023463 ],\n",
      " \t action=[900.42665390815694, 0.35146182176775065, 900.01301780009305, -0.34101077254908979], \n",
      " \t task.sim.pose=[-13.70340939 -11.04813318  35.31871845   2.07921689   2.14930879   0.        ]\n",
      "Episode =   99, total_reward =  172.30, , z=  35.73, v_z=   9.32, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76381287  0.7380675   9.31991045],\n",
      " \t action=[899.6627046276343, -0.032435615642617183, 899.96787755699359, 0.052172746943962289], \n",
      " \t task.sim.pose=[-13.44209552   1.35052853  35.72751352   2.12577213   2.10776195   0.        ]\n",
      "Episode =  100, total_reward =  170.75, , z=  35.42, v_z=   9.28, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87951724 -3.3816181   9.27954949],\n",
      " \t action=[899.91460935639077, -0.17936520558370439, 899.78085176576485, 0.47374351810919924], \n",
      " \t task.sim.pose=[-13.60728249  -9.06675702  35.4210352    2.04621101   2.0944421    0.        ]\n",
      "Episode =  101, total_reward =  170.70, , z=  35.41, v_z=   9.27, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82638421 -2.71412095  9.26576289],\n",
      " \t action=[900.0295657799436, 0.51399356521023931, 899.89148735238598, -0.23523109506440892], \n",
      " \t task.sim.pose=[-13.54162288  -6.55600893  35.41487465   2.07524288   2.13278584   0.        ]\n",
      "Episode =  102, total_reward =  171.58, , z=  35.62, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79724824 -0.3609145   9.33825973],\n",
      " \t action=[899.24970867834486, 0.054891310785967096, 899.81607049755473, 0.43612783339542616], \n",
      " \t task.sim.pose=[-13.47675388  -2.33636403  35.62404504   2.12821506   2.11634747   0.        ]\n",
      "Episode =  103, total_reward =  171.55, , z=  35.58, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85628542 -3.10324853  9.29787028],\n",
      " \t action=[899.44134425038612, 0.21557900580993522, 899.85106027523943, -0.24032213067423558], \n",
      " \t task.sim.pose=[-13.61725533  -8.34235227  35.57876587   2.08651875   2.13147712   0.        ]\n",
      "Episode =  104, total_reward =  170.52, , z=  35.45, v_z=   9.34, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82441044 -0.72554168  9.3383339 ],\n",
      " \t action=[899.9037345920043, -0.48269981682220264, 900.18351978470935, -0.62615670271791768], \n",
      " \t task.sim.pose=[-13.4183527   -3.11674458  35.44681032   2.07221756   2.06361365   0.        ]\n",
      "Episode =  105, total_reward =  172.17, , z=  35.72, v_z=   9.31, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86468624 -3.16237863  9.3094395 ],\n",
      " \t action=[899.9043094351988, -0.1672017983897362, 899.31757386484594, -0.74043005355149716], \n",
      " \t task.sim.pose=[-13.67979401  -8.08923462  35.71624692   2.07579732   2.12587913   0.        ]\n",
      "Episode =  106, total_reward =  170.86, , z=  35.37, v_z=   9.23, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74501338  1.72101354  9.22903131],\n",
      " \t action=[900.42373279999163, -0.47031023779693676, 900.04484622668781, 0.021735263191004855], \n",
      " \t task.sim.pose=[-13.3027284    3.79466386  35.37450335   2.12923039   2.07303961   0.        ]\n",
      "Episode =  107, total_reward =  171.62, , z=  35.65, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81855194 -1.53793237  9.34122414],\n",
      " \t action=[899.96292795289548, 0.31608051291626404, 899.84280978935033, 0.028005257197928915], \n",
      " \t task.sim.pose=[-13.54051983  -4.37663173  35.64621266   2.10934996   2.12107545   0.        ]\n",
      "Episode =  108, total_reward =  171.13, , z=  35.52, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85302358 -2.77066061  9.30394115],\n",
      " \t action=[899.56214318498451, -0.15240430252286383, 900.26511195810497, 0.14968966404812872], \n",
      " \t task.sim.pose=[-13.59626745  -7.694525    35.51676055   2.08591228   2.1225509    0.        ]\n",
      "Episode =  109, total_reward =  172.17, , z=  35.73, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79975135 -2.0182156   9.32841111],\n",
      " \t action=[899.97959800987121, 0.049312811396921785, 899.9767254545676, 0.0040147621939097544], \n",
      " \t task.sim.pose=[-13.53858048  -4.60823746  35.73462293   2.10448251   2.15047734   0.        ]\n",
      "Episode =  110, total_reward =  172.10, , z=  35.72, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81429624 -2.12056532  9.34143964],\n",
      " \t action=[900.06861469906312, -0.5700437734101701, 899.86682065003799, -0.12308306937074331], \n",
      " \t task.sim.pose=[-13.55253216  -5.7648029   35.72129611   2.11658633   2.14709097   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  111, total_reward =  170.04, , z=  34.97, v_z=   8.99, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.91311581 -6.17790049  8.99295388],\n",
      " \t action=[900.10427874282937, -0.054685117999350448, 899.61955776577963, -0.23844482877997097], \n",
      " \t task.sim.pose=[-13.75172781 -15.93504678  34.97373921   2.07814775   2.18073896   0.        ]\n",
      "Episode =  112, total_reward =  172.07, , z=  35.72, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84135212 -2.2246316   9.35676076],\n",
      " \t action=[900.43457373213926, -0.27819185005451313, 900.50215659803609, 0.094681664386042433], \n",
      " \t task.sim.pose=[-13.62676226  -6.59736831  35.71747607   2.11292985   2.13901388   0.        ]\n",
      "Episode =  113, total_reward =  171.48, , z=  35.39, v_z=   9.15, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.71897127  2.67018283  9.1477812 ],\n",
      " \t action=[900.1692539473687, -0.040478727162413741, 900.37062357242257, -0.21721303335879655], \n",
      " \t task.sim.pose=[-13.34552163   5.71426879  35.38964305   2.15350157   2.09951891   0.        ]\n",
      "Episode =  114, total_reward =  171.67, , z=  35.55, v_z=   9.26, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75136906  1.23509294  9.26184466],\n",
      " \t action=[899.83019711803502, 0.41922065780127671, 899.94140838002613, -0.018092146644968291], \n",
      " \t task.sim.pose=[-13.4259745    2.65055406  35.55492719   2.14686021   2.1103821    0.        ]\n",
      "Episode =  115, total_reward =  171.62, , z=  35.60, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82272406 -2.90377685  9.27619491],\n",
      " \t action=[900.00133936196153, -1.0221538552531813, 899.86044069638365, -0.32648433724845938], \n",
      " \t task.sim.pose=[-13.59240356  -6.7665485   35.5965566    2.0792667    2.15135549   0.        ]\n",
      "Episode =  116, total_reward =  171.78, , z=  35.67, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80634875  0.22011852  9.34229394],\n",
      " \t action=[900.39057132697678, -0.52289435419219576, 899.71967197490733, -0.20807111904789388], \n",
      " \t task.sim.pose=[-13.50990409  -0.99142696  35.6661212    2.13088201   2.09162815   0.        ]\n",
      "Episode =  117, total_reward =  170.19, , z=  35.04, v_z=   8.96, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8815171  -5.9076725   8.95553379],\n",
      " \t action=[899.64698116273814, 0.5729318592508994, 899.71177730314866, -0.24860923366267396], \n",
      " \t task.sim.pose=[-13.71990297 -13.49846437  35.04054856   2.05205719   2.18233989   0.        ]\n",
      "Episode =  118, total_reward =  171.22, , z=  35.55, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81763885 -1.96075108  9.31208995],\n",
      " \t action=[899.5427891741565, 0.23259120857173737, 899.98887376907339, 0.23269914998355534], \n",
      " \t task.sim.pose=[-13.55182935  -5.04235399  35.55417613   2.08621141   2.13077068   0.        ]\n",
      "Episode =  119, total_reward =  170.93, , z=  35.51, v_z=   9.33, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83927326 -1.68305965  9.33186146],\n",
      " \t action=[900.15027064193862, -0.047554061992213903, 899.9253265505713, -0.25736449462483957], \n",
      " \t task.sim.pose=[-13.59399619  -5.151419    35.50601802   2.09599652   2.11080319   0.        ]\n",
      "Episode =  120, total_reward =  171.58, , z=  35.56, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.90490367 -3.80525746  9.27830199],\n",
      " \t action=[898.88402365475588, 0.16622708745088283, 899.68605974686841, -0.1036020822385485], \n",
      " \t task.sim.pose=[-13.81132024 -10.91752768  35.56499586   2.08752076   2.14319079   0.        ]\n",
      "Episode =  121, total_reward =  171.74, , z=  35.68, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81582343 -1.64579035  9.35530824],\n",
      " \t action=[900.12669695481736, -0.16898948617490311, 899.8614249874862, 0.12648875037794574], \n",
      " \t task.sim.pose=[-13.47248733  -4.53102825  35.68288566   2.08480947   2.10247766   0.        ]\n",
      "Episode =  122, total_reward =  171.59, , z=  35.58, v_z=   9.25, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82354564 -3.11300544  9.24683347],\n",
      " \t action=[900.21166015145468, -0.43448254194543362, 900.51058624378902, 0.809471657908863], \n",
      " \t task.sim.pose=[-13.64287122  -7.18705367  35.57896371   2.08081296   2.16987735   0.        ]\n",
      "Episode =  123, total_reward =  170.77, , z=  35.44, v_z=   9.28, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84545546 -2.95751629  9.28200256],\n",
      " \t action=[899.486066578178, -0.30192924723169712, 900.03278232229434, -0.3454956223407557], \n",
      " \t task.sim.pose=[-13.53073665  -7.91914032  35.43680688   2.06486833   2.11986565   0.        ]\n",
      "Episode =  124, total_reward =  171.82, , z=  35.66, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84451083 -2.51581015  9.34007558],\n",
      " \t action=[899.78775761634859, -0.32211922709047158, 899.64295631589289, 0.03343567030394333], \n",
      " \t task.sim.pose=[-13.58905669  -6.81258975  35.66299414   2.09092268   2.119124     0.        ]\n",
      "Episode =  125, total_reward =  170.65, , z=  35.46, v_z=   9.34, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82397705 -0.5945754   9.33514835],\n",
      " \t action=[899.71586273567323, -0.60859163649338333, 900.19160780860739, 0.40776717250868566], \n",
      " \t task.sim.pose=[-13.42303648  -2.37390105  35.46493264   2.07540778   2.05514103   0.        ]\n",
      "Episode =  126, total_reward =  171.37, , z=  35.59, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79199583 -0.26143016  9.32909348],\n",
      " \t action=[899.97194161210223, -0.61001734980539402, 899.705346659204, -0.073680969920104922], \n",
      " \t task.sim.pose=[-13.44795939  -1.27672242  35.58720873   2.09084133   2.09311842   0.        ]\n",
      "Episode =  127, total_reward =  171.46, , z=  35.58, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78687775 -2.06691097  9.29700705],\n",
      " \t action=[900.67631898760976, -0.20551057926607391, 899.60638359917027, -0.013036292546647121], \n",
      " \t task.sim.pose=[-13.39378961  -4.23266228  35.57812545   2.0838654    2.12511001   0.        ]\n",
      "Episode =  128, total_reward =  172.30, , z=  35.75, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76119202 -0.34988821  9.33099965],\n",
      " \t action=[899.64398817066842, -0.22826042548323108, 899.91753297139508, -0.054066151793860873], \n",
      " \t task.sim.pose=[-13.43807287  -0.73789021  35.74725783   2.1397417    2.14016048   0.        ]\n",
      "Episode =  129, total_reward =  170.76, , z=  35.37, v_z=   9.23, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73022678  1.56543702  9.23169343],\n",
      " \t action=[900.18353563612845, -0.51588177670343549, 900.08038355694373, -0.38679238882205325], \n",
      " \t task.sim.pose=[-13.1572506    4.28726606  35.36533907   2.06849969   2.0437155    0.        ]\n",
      "Episode =  130, total_reward =  171.09, , z=  35.51, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78882841  0.662098    9.29904457],\n",
      " \t action=[900.37994080324245, -0.37089197597818968, 899.56638731539067, -0.25394672300273013], \n",
      " \t task.sim.pose=[-13.40545768   0.14293785  35.50959811   2.11120726   2.07941627   0.        ]\n",
      "Episode =  131, total_reward =  171.68, , z=  35.63, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77852045  0.50620654  9.32158979],\n",
      " \t action=[900.16726426443029, -0.138477672383128, 899.84294908177549, -0.31857797639714003], \n",
      " \t task.sim.pose=[-13.37928904  -0.31664049  35.62670495   2.13724256   2.09282222   0.        ]\n",
      "Episode =  132, total_reward =  171.35, , z=  35.58, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78416329 -0.55749151  9.33169119],\n",
      " \t action=[899.92477687209521, 0.11021211541434897, 899.7183026330249, 0.054836010511081612], \n",
      " \t task.sim.pose=[-13.4085974   -1.99505309  35.58450363   2.1000954    2.10874301   0.        ]\n",
      "Episode =  133, total_reward =  173.11, , z=  35.93, v_z=   9.36, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79043197 -0.6270048   9.36451091],\n",
      " \t action=[900.00748625202402, 0.13329937105020562, 899.85555725680854, 0.060228421732236082], \n",
      " \t task.sim.pose=[-13.60291338  -2.47607839  35.92737946   2.1669166    2.16193825   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  134, total_reward =  170.98, , z=  35.46, v_z=   9.27, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88951143 -3.45204773  9.27393337],\n",
      " \t action=[900.0115173572226, 0.2313769094910996, 899.84117560169796, -0.017790721685997782], \n",
      " \t task.sim.pose=[-13.75710236 -10.1496893   35.45591987   2.10566803   2.14666216   0.        ]\n",
      "Episode =  135, total_reward =  171.43, , z=  35.60, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86538428 -2.09643053  9.35826987],\n",
      " \t action=[900.18929704587185, 0.038244160510897705, 900.76870426161327, 0.44950956141130582], \n",
      " \t task.sim.pose=[-13.68637541  -6.9852799   35.60106549   2.11847431   2.12580744   0.        ]\n",
      "Episode =  136, total_reward =  171.94, , z=  35.71, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8170501  -1.89171189  9.35480755],\n",
      " \t action=[900.0625988017805, 0.13643083238409254, 899.92804789152126, -0.30794513117931471], \n",
      " \t task.sim.pose=[-13.52023685  -5.76485833  35.70807013   2.10547922   2.13487469   0.        ]\n",
      "Episode =  137, total_reward =  171.43, , z=  35.61, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88146863 -2.45460714  9.3349376 ],\n",
      " \t action=[899.76465829690551, -0.65245683019740008, 899.94442199554646, -0.11298740780372743], \n",
      " \t task.sim.pose=[-13.77619563  -7.68345498  35.60854269   2.09540609   2.12724943   0.        ]\n",
      "Episode =  138, total_reward =  171.21, , z=  35.55, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80051283  0.29938848  9.31858831],\n",
      " \t action=[900.61647221047247, 0.14506730826567976, 900.14160082849594, -0.015411658959748803], \n",
      " \t task.sim.pose=[-13.45531724  -0.37985635  35.54752083   2.09299283   2.07469525   0.        ]\n",
      "Episode =  139, total_reward =  171.33, , z=  35.38, v_z=   9.12, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75453279  3.06829767  9.11842316],\n",
      " \t action=[900.10790449630508, -0.045705667138888517, 899.98023051892665, 0.19749335562540174], \n",
      " \t task.sim.pose=[-13.33658667   5.58067824  35.37998568   2.15029387   2.04098132   0.        ]\n",
      "Episode =  140, total_reward =  171.88, , z=  35.68, v_z=   9.32, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82276865 -2.00653951  9.31606351],\n",
      " \t action=[899.48731001303145, 0.49896983798737787, 899.43951526213357, -0.0098737785307151417], \n",
      " \t task.sim.pose=[-13.63621164  -5.04554329  35.68383327   2.09846957   2.15140116   0.        ]\n",
      "Episode =  141, total_reward =  171.83, , z=  35.68, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79328644 -1.11740434  9.33517637],\n",
      " \t action=[899.76334702121289, -0.022626520746607787, 900.1747408255917, 0.10050368709733666], \n",
      " \t task.sim.pose=[-13.48002683  -2.95580173  35.68335779   2.10042417   2.12431391   0.        ]\n",
      "Episode =  142, total_reward =  170.98, , z=  35.44, v_z=   9.24, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84192932 -3.36516581  9.2379272 ],\n",
      " \t action=[899.69096428788703, -0.034531456864597229, 900.24158759600232, 0.01151503556824697], \n",
      " \t task.sim.pose=[-13.61382361  -7.80605169  35.43522287   2.06695405   2.14177384   0.        ]\n",
      "Episode =  143, total_reward =  171.77, , z=  35.65, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77515098 -0.11922675  9.33913134],\n",
      " \t action=[900.25226310509106, -0.33197600387445059, 900.51931592826111, -0.34609982634718911], \n",
      " \t task.sim.pose=[-13.42194672  -0.2868056   35.64929485   2.09961949   2.10312324   0.        ]\n",
      "Episode =  144, total_reward =  170.37, , z=  35.21, v_z=   9.14, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73946991  2.56680765  9.14303421],\n",
      " \t action=[900.20688180752791, 0.6695865846140624, 900.05189538473121, 0.16973713381654171], \n",
      " \t task.sim.pose=[-13.2543509    5.15841191  35.20643195   2.12591589   2.05088055   0.        ]\n",
      "Episode =  145, total_reward =  170.78, , z=  35.39, v_z=   9.25, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74029317  1.08436952  9.2541168 ],\n",
      " \t action=[899.8932528738319, -0.077891298525583602, 899.66422439968744, 0.85024159924931864], \n",
      " \t task.sim.pose=[-13.25843389   1.80112132  35.39143147   2.14728322   2.09919105   0.        ]\n",
      "Episode =  146, total_reward =  171.57, , z=  35.44, v_z=   9.15, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7493343   2.59705268  9.15029697],\n",
      " \t action=[899.33235308699375, -0.012374018090236191, 900.18700748803337, -0.50420952001807429], \n",
      " \t task.sim.pose=[-13.44985311   4.2094772   35.44175892   2.17695864   2.10273777   0.        ]\n",
      "Episode =  147, total_reward =  171.58, , z=  35.65, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85316373 -1.05863189  9.36274895],\n",
      " \t action=[899.77622961891882, -0.012656683814768643, 899.86484747050122, 0.49983266802460702], \n",
      " \t task.sim.pose=[-13.65781909  -4.52901884  35.64915711   2.1294826    2.10335598   0.        ]\n",
      "Episode =  148, total_reward =  171.71, , z=  35.61, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76942109  0.99512352  9.3024749 ],\n",
      " \t action=[900.60413973565358, -0.37108859589996135, 899.56388427386469, -0.28703559395653538], \n",
      " \t task.sim.pose=[-13.36443392   1.226741    35.61279682   2.13488809   2.08007244   0.        ]\n",
      "Episode =  149, total_reward =  170.47, , z=  35.17, v_z=   9.07, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73568158  3.32635249  9.06585896],\n",
      " \t action=[899.88996670005463, -0.13558118567878241, 900.04526703997544, 0.19168874750234149], \n",
      " \t task.sim.pose=[-13.24711381   6.44333051  35.16598839   2.1417902    2.04102686   0.        ]\n",
      "Episode =  150, total_reward =  171.02, , z=  35.53, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80984747 -0.1148702   9.33080107],\n",
      " \t action=[899.04313718102821, 0.145458876850663, 900.1733693124919, 0.16680774177636487], \n",
      " \t task.sim.pose=[-13.44951678  -1.8935539   35.52991591   2.10319893   2.08331953   0.        ]\n",
      "Episode =  151, total_reward =  171.10, , z=  35.58, v_z=   9.38, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.89540147 -1.77068457  9.37574293],\n",
      " \t action=[900.44947851436325, -0.33873265008231357, 899.5809584511594, -0.99298393555064279], \n",
      " \t task.sim.pose=[-13.66814329  -6.88611917  35.58004172   2.07225229   2.06230175   0.        ]\n",
      "Episode =  152, total_reward =  170.23, , z=  35.28, v_z=   9.22, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86522606 -3.85484921  9.22356088],\n",
      " \t action=[899.2664249412876, -0.56768741265983969, 899.97393837316656, -0.20542609904027742], \n",
      " \t task.sim.pose=[-13.61173083 -10.37742829  35.27512602   2.07100091   2.14140949   0.        ]\n",
      "Episode =  153, total_reward =  171.11, , z=  35.50, v_z=   9.27, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86286038 -3.40857096  9.27000371],\n",
      " \t action=[899.92277285530224, 0.4412304383117609, 900.64608779145726, -0.016560595399911587], \n",
      " \t task.sim.pose=[-13.6379307   -8.57030311  35.50023258   2.04421213   2.12008106   0.        ]\n",
      "Episode =  154, total_reward =  172.02, , z=  35.72, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83130019 -1.70086744  9.36249603],\n",
      " \t action=[899.62238981570738, 0.38637951899397843, 899.94621709707189, -0.41388072305191953], \n",
      " \t task.sim.pose=[-13.59611944  -5.09985287  35.72391632   2.11242347   2.12596818   0.        ]\n",
      "Episode =  155, total_reward =  172.73, , z=  35.83, v_z=   9.30, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81584957 -2.9216632   9.29725464],\n",
      " \t action=[899.92175751215768, 0.12037773111046146, 900.42385596989834, -0.22670370062974107], \n",
      " \t task.sim.pose=[-13.58283687  -6.42132303  35.82891751   2.06908234   2.15246186   0.        ]\n",
      "Episode =  156, total_reward =  172.38, , z=  35.84, v_z=   9.39, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85983512 -0.41443631  9.39414896],\n",
      " \t action=[899.9130121674699, -0.62800300372609663, 899.57656864680894, -0.30397441870272163], \n",
      " \t task.sim.pose=[-13.64507053  -3.27821177  35.84498771   2.10265108   2.06927511   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  157, total_reward =  171.23, , z=  35.57, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79296636 -0.95816049  9.34218879],\n",
      " \t action=[899.88175870133375, -0.17999321885192276, 900.37268078439024, -0.23266115329088066], \n",
      " \t task.sim.pose=[-13.42868593  -2.83240025  35.56805315   2.08926749   2.11308583   0.        ]\n",
      "Episode =  158, total_reward =  171.18, , z=  35.54, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85807785 -2.57949472  9.32921684],\n",
      " \t action=[899.91112195727533, 0.12139100805359687, 900.09787658398864, 0.38088009345462553], \n",
      " \t task.sim.pose=[-13.59880112  -7.75380626  35.5446958    2.08191652   2.11744318   0.        ]\n",
      "Episode =  159, total_reward =  171.54, , z=  35.62, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7943489   0.09948056  9.33888922],\n",
      " \t action=[900.14493876628285, -0.17426230134733067, 900.20430668646941, 0.73433393405080138], \n",
      " \t task.sim.pose=[-13.47362286  -0.93737795  35.61642236   2.11926713   2.09882516   0.        ]\n",
      "Episode =  160, total_reward =  171.84, , z=  35.65, v_z=   9.31, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86649725 -3.04263138  9.30994825],\n",
      " \t action=[899.60002106838192, -0.47573462159098601, 899.68094486449831, 0.76348708980078528], \n",
      " \t task.sim.pose=[-13.74562748  -8.66148067  35.65498957   2.10463009   2.15652402   0.        ]\n",
      "Episode =  161, total_reward =  171.43, , z=  35.57, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75260569  0.15138664  9.30372179],\n",
      " \t action=[900.01072672891644, 0.25869106324236402, 899.59975769502125, -0.5612761843192513], \n",
      " \t task.sim.pose=[-13.34925033   0.08816325  35.56533681   2.12122365   2.11792183   0.        ]\n",
      "Episode =  162, total_reward =  171.15, , z=  35.52, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82713456 -2.78087046  9.28393347],\n",
      " \t action=[900.0894889662452, 0.28352002091582629, 900.22148186908987, -0.056470497704451283], \n",
      " \t task.sim.pose=[-13.47153932  -5.92413191  35.52040366   2.02822847   2.09683832   0.        ]\n",
      "Episode =  163, total_reward =  170.33, , z=  35.36, v_z=   9.29, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76689033 -0.53807134  9.29458447],\n",
      " \t action=[900.10692210434183, -0.77203816630908451, 899.55699124407226, 0.25794886292622071], \n",
      " \t task.sim.pose=[-13.23631155  -0.24504831  35.35935238   2.0538442    2.06308904   0.        ]\n",
      "Episode =  164, total_reward =  171.74, , z=  35.64, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75722978 -0.62534007  9.32478792],\n",
      " \t action=[899.64933941166123, 0.55243286943344183, 900.4698328750967, -0.17314030389886828], \n",
      " \t task.sim.pose=[-13.38160674  -0.97615088  35.63888316   2.09490004   2.13228161   0.        ]\n",
      "Episode =  165, total_reward =  171.52, , z=  35.61, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81769643 -2.26852183  9.308493  ],\n",
      " \t action=[899.54890268266354, -1.1324129659689093, 899.98163196535472, 0.56044964655124141], \n",
      " \t task.sim.pose=[-13.56275893  -5.91291924  35.60574289   2.09873604   2.15001726   0.        ]\n",
      "Episode =  166, total_reward =  171.89, , z=  35.69, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83666806 -2.3348837   9.33128952],\n",
      " \t action=[899.86111615286745, 0.072414636773285301, 900.2607199632414, -0.31743344441164678], \n",
      " \t task.sim.pose=[-13.55893489  -5.94534128  35.69361435   2.07096015   2.109983     0.        ]\n",
      "Episode =  167, total_reward =  172.67, , z=  35.88, v_z=   9.38, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81563908 -0.50509875  9.38285263],\n",
      " \t action=[899.92985005676485, -0.23343603748437286, 900.6093970909069, -0.064362274135139508], \n",
      " \t task.sim.pose=[-13.5882335   -2.32854771  35.87507367   2.09968728   2.10917553   0.        ]\n",
      "Episode =  168, total_reward =  171.55, , z=  35.46, v_z=   9.19, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72723213  2.35511294  9.18707651],\n",
      " \t action=[899.89166863272112, -0.55204593389762857, 900.1108177772486, 0.41498842875509034], \n",
      " \t task.sim.pose=[-13.29973628   4.55028079  35.46256059   2.1693752    2.09293918   0.        ]\n",
      "Episode =  169, total_reward =  170.85, , z=  35.38, v_z=   9.22, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87417419 -4.00165202  9.22130818],\n",
      " \t action=[900.25095281163999, -0.27873355996599669, 899.54005837614829, 0.50086412961169791], \n",
      " \t task.sim.pose=[-13.64726926 -10.12863138  35.3813439    2.06621489   2.13194907   0.        ]\n",
      "Episode =  170, total_reward =  172.33, , z=  35.78, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79617941  0.6260704   9.34981078],\n",
      " \t action=[899.75752998346309, -0.05087771679530665, 900.16339908366058, -0.68327042560219864], \n",
      " \t task.sim.pose=[ -1.34409214e+01   2.56839951e-03   3.57831164e+01   2.12055041e+00\n",
      "   2.06623559e+00   0.00000000e+00]\n",
      "Episode =  171, total_reward =  171.14, , z=  35.55, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80921686  0.28415066  9.33122369],\n",
      " \t action=[901.13830853583522, 0.22533558042673524, 900.60265969056934, -0.096536507134207333], \n",
      " \t task.sim.pose=[-13.43252703  -0.99875511  35.55166467   2.09358587   2.05983693   0.        ]\n",
      "Episode =  172, total_reward =  170.36, , z=  35.37, v_z=   9.30, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87761404 -3.08674408  9.30368869],\n",
      " \t action=[900.02244887008749, -0.16674432533584077, 899.48186833020623, 0.64174712706195691], \n",
      " \t task.sim.pose=[-13.58142012  -9.25546016  35.3706464    2.06372053   2.09656565   0.        ]\n",
      "Episode =  173, total_reward =  168.87, , z=  34.75, v_z=   8.96, \n",
      " \t score = 2.01 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.69734343  3.87244736  8.96235415],\n",
      " \t action=[899.55544237736797, -0.43736472993384662, 900.22327625744026, 0.86271825711941119], \n",
      " \t task.sim.pose=[-13.05558572   9.44508083  34.7493332    2.11156312   2.01872711   0.        ]\n",
      "Episode =  174, total_reward =  171.40, , z=  35.61, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85427334 -2.20761898  9.35391874],\n",
      " \t action=[900.18802190235783, -0.22081387730223864, 900.62034733232338, -0.0063156085618403801], \n",
      " \t task.sim.pose=[-13.54505343  -6.57392192  35.61323924   2.06555575   2.08184465   0.        ]\n",
      "Episode =  175, total_reward =  170.77, , z=  35.41, v_z=   9.25, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87516719 -3.69166284  9.25412774],\n",
      " \t action=[899.71169032257262, -0.60130137378764814, 900.05694541499099, 0.40811135293927031], \n",
      " \t task.sim.pose=[-13.6108858   -9.94222469  35.40663796   2.05206475   2.11230011   0.        ]\n",
      "Episode =  176, total_reward =  171.61, , z=  35.58, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74087748  0.07172878  9.29178664],\n",
      " \t action=[900.2436798658623, 0.0048100889197629088, 899.56433937935651, -0.050581971961825845], \n",
      " \t task.sim.pose=[-13.37724572   0.87621655  35.57552415   2.13882577   2.138932     0.        ]\n",
      "Episode =  177, total_reward =  170.99, , z=  35.37, v_z=   9.20, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.89149416 -4.44969911  9.2004703 ],\n",
      " \t action=[900.10378100697039, -0.58868106714148238, 899.74078183950087, 0.25384446708821917], \n",
      " \t task.sim.pose=[-13.68975903 -11.58297301  35.36899702   2.0720833    2.13177901   0.        ]\n",
      "Episode =  178, total_reward =  171.90, , z=  35.70, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83558527 -2.57701554  9.33950406],\n",
      " \t action=[899.84715389238534, 0.19470004402463287, 899.6243906678003, 0.072713831013443336], \n",
      " \t task.sim.pose=[-13.48766499  -6.73345092  35.70320035   2.05775411   2.0985269    0.        ]\n",
      "Episode =  179, total_reward =  171.58, , z=  35.64, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80738455 -1.10288244  9.34336982],\n",
      " \t action=[900.69104839187435, -0.11798879931007886, 899.56176063619046, -0.76678545178660029], \n",
      " \t task.sim.pose=[-13.47993736  -3.45154862  35.63586719   2.10733193   2.10904982   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  180, total_reward =  171.00, , z=  35.54, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.89607433 -2.64217994  9.34702372],\n",
      " \t action=[900.57679302324095, -0.22796704427725703, 899.53156909371899, 0.29190889879348314], \n",
      " \t task.sim.pose=[-13.61000326  -7.68993256  35.53544973   2.02857894   2.04949546   0.        ]\n",
      "Episode =  181, total_reward =  170.77, , z=  35.50, v_z=   9.34, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86294276 -1.69513119  9.33663308],\n",
      " \t action=[900.07901525434727, -0.56707200847691652, 899.34542389823787, -0.072382551233031639], \n",
      " \t task.sim.pose=[-13.5615947   -5.08302999  35.4974779    2.05511614   2.05995594   0.        ]\n",
      "Episode =  182, total_reward =  171.25, , z=  35.51, v_z=   9.27, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8204647  -2.92896405  9.2677494 ],\n",
      " \t action=[899.9207783500791, 0.30273543420977, 899.96101739333801, 0.20116262081401068], \n",
      " \t task.sim.pose=[-13.53660693  -6.69709165  35.51265431   2.0816567    2.14447383   0.        ]\n",
      "Episode =  183, total_reward =  169.90, , z=  35.22, v_z=   9.27, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.94298914 -3.88573779  9.27473779],\n",
      " \t action=[899.77947892749444, -0.147937940435308, 899.58063514950311, -0.14135786279696055], \n",
      " \t task.sim.pose=[-13.73519024 -12.70340694  35.22087182   2.06982156   2.08793067   0.        ]\n",
      "Episode =  184, total_reward =  170.21, , z=  35.03, v_z=   9.00, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.92489534 -6.15631757  9.00058047],\n",
      " \t action=[899.9299823831916, 0.012551931665281263, 899.93418904561202, 0.26579469668038824], \n",
      " \t task.sim.pose=[-13.7936718  -15.69232731  35.02826665   2.05891378   2.16317366   0.        ]\n",
      "Episode =  185, total_reward =  171.54, , z=  35.64, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86534674 -1.98126744  9.35862865],\n",
      " \t action=[900.04159455362276, 0.0094877158980037346, 900.20791411447067, -0.05689437963340177], \n",
      " \t task.sim.pose=[-13.67153841  -6.76465332  35.64247561   2.10245143   2.11190924   0.        ]\n",
      "Episode =  186, total_reward =  168.95, , z=  34.72, v_z=   8.93, \n",
      " \t score = 2.01 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.98563681 -6.90048701  8.92849944],\n",
      " \t action=[899.49127510364235, 0.4299759589715369, 899.74370791174795, -0.64439179444212347], \n",
      " \t task.sim.pose=[-13.90921633 -18.97835702  34.72425271   2.04040769   2.14211866   0.        ]\n",
      "Episode =  187, total_reward =  171.10, , z=  35.55, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83477692 -0.64451216  9.34352454],\n",
      " \t action=[899.83804527355278, 0.2671307780888596, 899.78812068845434, 0.012378182164876503], \n",
      " \t task.sim.pose=[-13.5436029   -3.25193872  35.55082452   2.10738336   2.08718356   0.        ]\n",
      "Episode =  188, total_reward =  170.84, , z=  35.50, v_z=   9.33, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85249916 -2.15997905  9.32993331],\n",
      " \t action=[899.82943351135577, -0.16191753152928842, 899.94002768072869, -0.33341342882414488], \n",
      " \t task.sim.pose=[-13.55111045  -6.5512967   35.49647239   2.06820141   2.09408327   0.        ]\n",
      "Episode =  189, total_reward =  171.45, , z=  35.59, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82139765 -1.73473786  9.32412   ],\n",
      " \t action=[900.04615118330287, 0.31608361759648324, 899.33243603933886, -0.050015416764898679], \n",
      " \t task.sim.pose=[-13.59123478  -5.01542784  35.5851148    2.1342508    2.14874579   0.        ]\n",
      "Episode =  190, total_reward =  171.36, , z=  35.59, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80587098  0.75281301  9.31978398],\n",
      " \t action=[899.35932551746737, -0.12015932948691847, 899.96208548605352, 0.0056071629988486138], \n",
      " \t task.sim.pose=[-13.41276468   0.15588606  35.59076855   2.08987746   2.04787461   0.        ]\n",
      "Episode =  191, total_reward =  171.28, , z=  35.57, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79700809 -0.18881459  9.33246773],\n",
      " \t action=[899.8475132361749, 0.033996803479451575, 899.73388897307098, 0.28634293182533405], \n",
      " \t task.sim.pose=[-13.4535382   -1.16091294  35.56902695   2.09288249   2.08892933   0.        ]\n",
      "Episode =  192, total_reward =  171.83, , z=  35.67, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75778321 -0.51375832  9.33529958],\n",
      " \t action=[899.88295648278495, -0.43759247543608659, 900.43014245748043, -0.08200495412130776], \n",
      " \t task.sim.pose=[-13.37221667  -1.51243805  35.66634692   2.12114199   2.13442917   0.        ]\n",
      "Episode =  193, total_reward =  171.67, , z=  35.66, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78398832 -1.19214793  9.34705124],\n",
      " \t action=[899.77702580448306, 0.40775291623027099, 899.97468581951989, 0.13458589004364035], \n",
      " \t task.sim.pose=[-13.42549063  -3.3437462   35.65781001   2.09536577   2.12747347   0.        ]\n",
      "Episode =  194, total_reward =  170.34, , z=  35.32, v_z=   9.25, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76688347  1.40734816  9.25044161],\n",
      " \t action=[900.23590997458598, -0.55481534379119657, 900.48061112747087, -0.59655625468489637], \n",
      " \t task.sim.pose=[-13.2671788    1.89114332  35.31993322   2.11413928   2.05433585   0.        ]\n",
      "Episode =  195, total_reward =  172.01, , z=  35.70, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8059856   0.70873084  9.32819305],\n",
      " \t action=[900.3709125696422, -0.095994633870994495, 900.33156408736704, -0.39402843077799965], \n",
      " \t task.sim.pose=[-13.54069691  -0.36620672  35.70036464   2.14052833   2.08942305   0.        ]\n",
      "Episode =  196, total_reward =  172.16, , z=  35.68, v_z=   9.30, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87580184 -3.62763066  9.29598802],\n",
      " \t action=[900.40928890134842, 0.13988470235226877, 899.97319572339791, -0.067928741082796007], \n",
      " \t task.sim.pose=[-13.74942946  -9.98266411  35.68480773   2.10227607   2.15459047   0.        ]\n",
      "Episode =  197, total_reward =  170.80, , z=  35.43, v_z=   9.27, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8514063  -3.30132922  9.26924521],\n",
      " \t action=[900.37389774904375, 0.19246040596880992, 899.66154883266245, 0.26997960583557018], \n",
      " \t task.sim.pose=[-13.53784498  -8.2868511   35.42685986   2.05264329   2.10498493   0.        ]\n",
      "Episode =  198, total_reward =  170.54, , z=  35.34, v_z=   9.26, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.89443794 -3.86558445  9.25591966],\n",
      " \t action=[899.68148254760808, 0.26806556303717854, 900.00280854514244, -0.57040490206840477], \n",
      " \t task.sim.pose=[-13.6698933  -11.1024544   35.33919528   2.08204395   2.12157555   0.        ]\n",
      "Episode =  199, total_reward =  171.11, , z=  35.57, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83182461 -0.6166573   9.35415425],\n",
      " \t action=[900.09910052225246, -0.004424757446965355, 900.16263090277016, -0.12180974576919623], \n",
      " \t task.sim.pose=[-13.46465853  -3.67295717  35.56634385   2.10168616   2.07084834   0.        ]\n",
      "Episode =  200, total_reward =  169.41, , z=  35.02, v_z=   9.10, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8783326  -5.03560181  9.09685867],\n",
      " \t action=[899.88584704507696, -0.35032903334950716, 899.38664846091854, 0.97751136832689089], \n",
      " \t task.sim.pose=[-13.5238736  -12.1318086   35.02423775   2.00378823   2.10364884   0.        ]\n",
      "Episode =  201, total_reward =  170.02, , z=  34.95, v_z=   8.95, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.69146659  4.07563166  8.94834651],\n",
      " \t action=[900.15320834602778, 0.073280374372154261, 900.32530783369509, 0.20944659323386103], \n",
      " \t task.sim.pose=[-13.19943668   8.8196488   34.94926582   2.17795032   2.06939345   0.        ]\n",
      "Episode =  202, total_reward =  170.23, , z=  35.24, v_z=   9.21, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72921017  1.54116398  9.21217427],\n",
      " \t action=[899.69764545783153, -0.35739997961964648, 900.27680080462835, -0.26696839160750963], \n",
      " \t task.sim.pose=[-13.23064487   3.58655999  35.24320416   2.12236963   2.08225028   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  203, total_reward =  171.32, , z=  35.48, v_z=   9.24, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73928512  1.65564855  9.24039655],\n",
      " \t action=[900.07883506369149, 0.20843650397375893, 899.78293962339569, -0.010764595330256699], \n",
      " \t task.sim.pose=[-13.3111203    3.56168201  35.47822335   2.14495825   2.0902877    0.        ]\n",
      "Episode =  204, total_reward =  172.51, , z=  35.81, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84768572 -2.36076724  9.34946888],\n",
      " \t action=[899.9041035565424, -0.52660226380419817, 899.84249306231027, 0.11581930740625626], \n",
      " \t task.sim.pose=[-13.70241056  -7.19158089  35.81114969   2.12582931   2.15671791   0.        ]\n",
      "Episode =  205, total_reward =  172.22, , z=  35.78, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81306409 -1.53371139  9.36653919],\n",
      " \t action=[900.05104125995626, 0.053533185491926871, 899.76782342968636, -0.013240532986985715], \n",
      " \t task.sim.pose=[-13.53831796  -4.41347136  35.77540094   2.09623674   2.12464433   0.        ]\n",
      "Episode =  206, total_reward =  171.11, , z=  35.49, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73572524 -0.2055426   9.29875251],\n",
      " \t action=[899.76349808929319, -0.053387198689024307, 901.02296339751194, 0.14305028980949633], \n",
      " \t task.sim.pose=[-13.29469132   0.21640003  35.49001274   2.11374912   2.13399414   0.        ]\n",
      "Episode =  207, total_reward =  171.70, , z=  35.68, v_z=   9.37, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84879327 -1.25104971  9.36866182],\n",
      " \t action=[900.2352796669586, -0.89208410965288731, 899.2438030055705, 0.09425138661214176], \n",
      " \t task.sim.pose=[-13.59361899  -4.74550323  35.68329354   2.10165362   2.0876643    0.        ]\n",
      "Episode =  208, total_reward =  171.26, , z=  35.58, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82783405 -0.14608095  9.3370023 ],\n",
      " \t action=[899.86440634326868, -0.22578231623877448, 899.778709126889, -0.22347997665282293], \n",
      " \t task.sim.pose=[-13.50886325  -2.80871027  35.58269838   2.12009411   2.08273197   0.        ]\n",
      "Episode =  209, total_reward =  171.41, , z=  35.57, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77291188  0.32538528  9.31730601],\n",
      " \t action=[900.16788684243522, -0.39483720286245133, 900.37676072726254, 0.11798675784477609], \n",
      " \t task.sim.pose=[-13.41025939   0.16379709  35.56568835   2.11637314   2.10214459   0.        ]\n",
      "Episode =  210, total_reward =  171.27, , z=  35.57, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86177004 -2.34259953  9.33867755],\n",
      " \t action=[899.40603833579803, 0.49378541263483972, 900.40033663109023, -0.13276785252289311], \n",
      " \t task.sim.pose=[-13.65105641  -7.57089126  35.57237608   2.09466416   2.12456797   0.        ]\n",
      "Episode =  211, total_reward =  171.86, , z=  35.70, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85024292 -1.53050911  9.36706333],\n",
      " \t action=[900.61204687212614, -0.25110081665671574, 900.06278151926233, 0.53083630058569287], \n",
      " \t task.sim.pose=[-13.65297814  -5.37821793  35.7040976    2.11398081   2.1121931    0.        ]\n",
      "Episode =  212, total_reward =  172.44, , z=  35.78, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83302721 -2.58772761  9.34320731],\n",
      " \t action=[900.17859954747757, 0.095505257682946321, 900.0093832047462, -0.33469291193831008], \n",
      " \t task.sim.pose=[-13.61601193  -7.18950014  35.78322201   2.11505568   2.14967357   0.        ]\n",
      "Episode =  213, total_reward =  172.51, , z=  35.78, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7667743  -1.11650605  9.34040442],\n",
      " \t action=[899.75174613320814, -0.65389662227607315, 899.6579089301722, -0.2164705969668031], \n",
      " \t task.sim.pose=[-13.47894454  -2.67700875  35.78465498   2.15070018   2.16906036   0.        ]\n",
      "Episode =  214, total_reward =  170.96, , z=  35.32, v_z=   9.16, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72735952  2.58686917  9.15597399],\n",
      " \t action=[898.9682107426936, -0.3252352931005254, 900.4609589913141, -0.30731605839962389], \n",
      " \t task.sim.pose=[-13.24536337   6.02678225  35.32423376   2.11432695   2.05574735   0.        ]\n",
      "Episode =  215, total_reward =  172.20, , z=  35.70, v_z=   9.31, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76672432  1.07759664  9.30560583],\n",
      " \t action=[900.08317631965554, 0.099592275123770474, 899.89915268330606, 0.046463165617717045], \n",
      " \t task.sim.pose=[-13.43700282   1.34181589  35.69841595   2.15271979   2.10383717   0.        ]\n",
      "Episode =  216, total_reward =  171.31, , z=  35.60, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79969674 -0.66308061  9.34326677],\n",
      " \t action=[899.64633432117068, -0.37614353985973858, 900.07832066711001, -0.22434276611048795], \n",
      " \t task.sim.pose=[-13.37922903  -1.18906726  35.60158203   2.03735531   2.05567716   0.        ]\n",
      "Episode =  217, total_reward =  171.11, , z=  35.45, v_z=   9.27, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73080608  0.88295017  9.27269967],\n",
      " \t action=[899.9311757585217, -0.47971770733261326, 900.29825694923875, 0.18523812047075489], \n",
      " \t task.sim.pose=[-13.28412424   2.76721902  35.45226508   2.12402166   2.10339487   0.        ]\n",
      "Episode =  218, total_reward =  171.52, , z=  35.64, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79517536 -0.99828677  9.34683516],\n",
      " \t action=[899.93607067419998, -0.79492568847755507, 900.2746254448839, -0.56742268877010127], \n",
      " \t task.sim.pose=[-13.3724623   -2.70803844  35.63804562   2.06216183   2.08161972   0.        ]\n",
      "Episode =  219, total_reward =  172.41, , z=  35.78, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80325274 -1.76238426  9.342362  ],\n",
      " \t action=[900.62745040994855, 0.53775541366439583, 900.12436168684496, -0.22505721351605412], \n",
      " \t task.sim.pose=[-13.57387167  -4.02029142  35.78485249   2.10463225   2.14404151   0.        ]\n",
      "Episode =  220, total_reward =  171.39, , z=  35.59, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79569221 -1.66919966  9.31671701],\n",
      " \t action=[899.23553919486994, -0.20853753670760991, 900.88085564734024, 0.25587401294987905], \n",
      " \t task.sim.pose=[-13.46712848  -3.94644756  35.58520367   2.07875316   2.13004074   0.        ]\n",
      "Episode =  221, total_reward =  171.58, , z=  35.64, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79038981 -0.54594312  9.34623284],\n",
      " \t action=[899.91282569109683, 0.63940431948626775, 900.41348537532451, 0.023904404908043908], \n",
      " \t task.sim.pose=[-13.44042387  -2.29802005  35.63507318   2.12542072   2.11187965   0.        ]\n",
      "Episode =  222, total_reward =  171.82, , z=  35.69, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88353413 -2.21591202  9.36740602],\n",
      " \t action=[901.16284813633547, 0.087913742601445688, 900.3205035409062, 0.40867390858873009], \n",
      " \t task.sim.pose=[-13.73067974  -7.26961192  35.69419278   2.10138722   2.10518126   0.        ]\n",
      "Episode =  223, total_reward =  172.46, , z=  35.83, v_z=   9.40, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87160862 -1.81834739  9.39608521],\n",
      " \t action=[900.19705279057621, 0.72604387881727583, 900.43390082880137, 0.49724507301375431], \n",
      " \t task.sim.pose=[-13.74207527  -7.19779985  35.82554639   2.14316612   2.13651558   0.        ]\n",
      "Episode =  224, total_reward =  172.36, , z=  35.80, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80868203 -1.05915487  9.36470988],\n",
      " \t action=[900.51635424510698, -0.26574055412333036, 899.47680247392327, -0.49369113607441095], \n",
      " \t task.sim.pose=[-13.55144284  -3.33069311  35.79859519   2.11471252   2.12548191   0.        ]\n",
      "Episode =  225, total_reward =  171.84, , z=  35.73, v_z=   9.38, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85110716 -1.3345525   9.37918546],\n",
      " \t action=[900.11666158292758, 0.0026344088075148792, 900.3293970749902, -0.57907321774531972], \n",
      " \t task.sim.pose=[-13.56886693  -5.32964165  35.72684831   2.09158408   2.08687584   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  226, total_reward =  171.08, , z=  35.51, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78427084  0.75374881  9.29998991],\n",
      " \t action=[900.09097688878217, -0.14061407983005814, 899.82089154291702, -0.032641357607322105], \n",
      " \t task.sim.pose=[-13.3337193    0.51943075  35.50813944   2.10574362   2.05815005   0.        ]\n",
      "Episode =  227, total_reward =  170.25, , z=  35.11, v_z=   9.10, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.68131744  2.89057175  9.09621148],\n",
      " \t action=[901.01784134396894, -0.0095235948652813273, 900.61285065479535, 0.552028625264957], \n",
      " \t task.sim.pose=[-13.12061478   7.60646795  35.10649225   2.15187671   2.07946017   0.        ]\n",
      "Episode =  228, total_reward =  172.11, , z=  35.74, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81155414 -0.68878816  9.35957258],\n",
      " \t action=[900.03780699811352, -0.59437182379098585, 900.05468039910465, -0.47607429279613478], \n",
      " \t task.sim.pose=[-13.59910287  -2.92426794  35.73965858   2.1296457    2.13160793   0.        ]\n",
      "Episode =  229, total_reward =  172.60, , z=  35.82, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77077328 -0.57938069  9.35934701],\n",
      " \t action=[899.7229233836872, 0.38573403776702586, 900.29322272948627, -0.46089958426016647], \n",
      " \t task.sim.pose=[-13.45851992  -1.59434848  35.82219614   2.12760763   2.13792915   0.        ]\n",
      "Episode =  230, total_reward =  170.73, , z=  35.42, v_z=   9.27, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75608548  0.96733313  9.26994533],\n",
      " \t action=[899.01636231104033, -0.24550576061022555, 899.92080506434002, 0.53992534058427932], \n",
      " \t task.sim.pose=[-13.27553462   1.8388467   35.41567405   2.08737555   2.0713327    0.        ]\n",
      "Episode =  231, total_reward =  172.25, , z=  35.68, v_z=   9.28, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76836377  1.34550408  9.275744  ],\n",
      " \t action=[899.8637396512654, -0.18555332374197725, 899.76623199278583, -0.19629991530414748], \n",
      " \t task.sim.pose=[-13.53986631   1.94085895  35.68234564   2.15374536   2.12302446   0.        ]\n",
      "Episode =  232, total_reward =  171.52, , z=  35.55, v_z=   9.27, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75695602  1.33335983  9.27443235],\n",
      " \t action=[899.9136295346425, 0.056928300396588527, 900.34436319887357, -0.20070719401052389], \n",
      " \t task.sim.pose=[-13.32010563   2.34783399  35.55496132   2.12547935   2.07329526   0.        ]\n",
      "Episode =  233, total_reward =  170.02, , z=  35.21, v_z=   9.21, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73725941  1.76134209  9.21262508],\n",
      " \t action=[900.16648179726326, -0.40660909011750723, 900.18334573546349, 0.13018828018366146], \n",
      " \t task.sim.pose=[-13.1262242    4.10158159  35.21437625   2.08392286   2.03682676   0.        ]\n",
      "Episode =  234, total_reward =  170.55, , z=  35.41, v_z=   9.30, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77969817  0.56552072  9.29865383],\n",
      " \t action=[900.36378566917767, -0.45305637426770912, 899.51525612680041, -0.25628042532652223], \n",
      " \t task.sim.pose=[-13.28547552   0.95636077  35.40727655   2.08637117   2.04677883   0.        ]\n",
      "Episode =  235, total_reward =  168.29, , z=  34.60, v_z=   8.94, \n",
      " \t score = 2.00 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.95514764 -6.53152334  8.94467919],\n",
      " \t action=[900.27300932695744, 0.29119944671083403, 900.01038776693701, -0.17248435137040946], \n",
      " \t task.sim.pose=[-13.69868739 -17.28364216  34.60475598   2.02408982   2.10862291   0.        ]\n",
      "Episode =  236, total_reward =  171.29, , z=  35.53, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78153602  0.8372872   9.29502774],\n",
      " \t action=[899.68893536207372, 0.35672704139184519, 900.30145467837485, 0.40005146594148416], \n",
      " \t task.sim.pose=[-13.39922976  -0.26184932  35.53165004   2.15146871   2.09461213   0.        ]\n",
      "Episode =  237, total_reward =  171.67, , z=  35.63, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77629985 -0.26398567  9.32409332],\n",
      " \t action=[900.12778124339707, 0.63263176358970485, 899.80099005103989, 0.41219606152179111], \n",
      " \t task.sim.pose=[-13.43730341  -1.04995952  35.63166925   2.12065089   2.11872126   0.        ]\n",
      "Episode =  238, total_reward =  170.45, , z=  35.25, v_z=   9.15, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74089264  2.4654202   9.14899718],\n",
      " \t action=[899.56575565606659, 0.62386656041993527, 899.4256196071193, 0.43033937895679475], \n",
      " \t task.sim.pose=[-13.25082482   4.72085178  35.25059188   2.14020717   2.05616551   0.        ]\n",
      "Episode =  239, total_reward =  171.04, , z=  35.49, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78943728  0.47983439  9.29977725],\n",
      " \t action=[900.7895312685115, 0.034815538088788206, 900.0188500256703, -0.68423882385958434], \n",
      " \t task.sim.pose=[-13.40315315  -0.30779607  35.49069194   2.1270964    2.08256177   0.        ]\n",
      "Episode =  240, total_reward =  172.49, , z=  35.82, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80042926 -0.51645183  9.36854046],\n",
      " \t action=[899.72747031349377, 0.043173539951013723, 900.23483113083535, 0.33660280639064416], \n",
      " \t task.sim.pose=[-13.52607921  -1.60687229  35.82291122   2.10456279   2.10704975   0.        ]\n",
      "Episode =  241, total_reward =  171.10, , z=  35.37, v_z=   9.20, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72243232  1.98059333  9.1960286 ],\n",
      " \t action=[900.28670853775213, 0.36066300572089738, 900.47590477590427, 0.086201104006959364], \n",
      " \t task.sim.pose=[-13.3012767    4.85189816  35.37106923   2.13075259   2.09590124   0.        ]\n",
      "Episode =  242, total_reward =  172.10, , z=  35.70, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[ -1.76128632e+00   3.03312720e-03   9.33421763e+00],\n",
      " \t action=[900.75744813957749, 0.4285023292061263, 899.49519204978208, 0.13675578695041454], \n",
      " \t task.sim.pose=[-13.3408185    0.58219465  35.70488766   2.10697315   2.09235909   0.        ]\n",
      "Episode =  243, total_reward =  169.80, , z=  35.16, v_z=   9.21, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7086434   1.32473543  9.2060679 ],\n",
      " \t action=[899.89742022639359, -0.03023088874592722, 899.27205232515007, -1.1065583868641953], \n",
      " \t task.sim.pose=[-13.05831764   4.51372918  35.15586866   2.09187776   2.05630335   0.        ]\n",
      "Episode =  244, total_reward =  170.81, , z=  35.43, v_z=   9.26, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81461955 -2.74194689  9.25770129],\n",
      " \t action=[899.77585463404114, -0.48663656151691687, 900.14612750334697, -0.19742873216863244], \n",
      " \t task.sim.pose=[-13.49041054  -5.60090278  35.42537156   2.05396729   2.12059578   0.        ]\n",
      "Episode =  245, total_reward =  171.08, , z=  35.46, v_z=   9.25, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80754299 -3.07943452  9.25495589],\n",
      " \t action=[900.32798263230654, 0.19078766209145143, 900.06643831433576, 0.0063902285973977957], \n",
      " \t task.sim.pose=[-13.46511109  -7.13884852  35.4642092    2.07437956   2.1462491    0.        ]\n",
      "Episode =  246, total_reward =  171.41, , z=  35.59, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86571819 -2.52821847  9.33760771],\n",
      " \t action=[901.35396846242907, -0.32889600468079616, 900.06563247497775, -0.73440225832953121], \n",
      " \t task.sim.pose=[-13.67876052  -7.58990746  35.59483236   2.08498496   2.12342832   0.        ]\n",
      "Episode =  247, total_reward =  170.99, , z=  35.50, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82545203 -2.01098319  9.3217546 ],\n",
      " \t action=[899.74294993188448, -0.25079059219471778, 899.72714831420512, 0.064308509398097097], \n",
      " \t task.sim.pose=[-13.49671895  -5.66197214  35.4956117    2.09839524   2.11718438   0.        ]\n",
      "Episode =  248, total_reward =  171.34, , z=  35.59, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81518141 -0.74747163  9.33990402],\n",
      " \t action=[900.66376369499983, -0.26247673745451483, 899.55652096389031, 0.27450658612849249], \n",
      " \t task.sim.pose=[-13.507592    -2.35219553  35.58574584   2.10854893   2.09502858   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  249, total_reward =  171.82, , z=  35.68, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8174178  -1.82992379  9.34282867],\n",
      " \t action=[899.92352799809066, -0.084506987042355014, 900.32322853260189, -0.62328804604692456], \n",
      " \t task.sim.pose=[-13.56177707  -4.92392388  35.67706569   2.1012166    2.13655498   0.        ]\n",
      "Episode =  250, total_reward =  171.41, , z=  35.60, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8096734   0.56475601  9.32966633],\n",
      " \t action=[900.17010220228872, 0.34522596959687085, 899.59971538769116, -0.21191739564324089], \n",
      " \t task.sim.pose=[-13.39123907  -1.21552121  35.60255026   2.12305331   2.05430131   0.        ]\n",
      "Episode =  251, total_reward =  170.84, , z=  35.25, v_z=   9.12, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.69907395  2.8175061   9.12229716],\n",
      " \t action=[900.14716053369636, -0.1165783932559788, 899.84419987670367, 0.55986492642152774], \n",
      " \t task.sim.pose=[-13.15888253   6.72632376  35.24743251   2.14061644   2.06759692   0.        ]\n",
      "Episode =  252, total_reward =  171.55, , z=  35.65, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79833433 -0.75333709  9.35092531],\n",
      " \t action=[899.20159542540625, -0.15349448421659539, 900.27242061557047, -0.1897836888015475], \n",
      " \t task.sim.pose=[-13.41842668  -2.33746608  35.64678859   2.07928729   2.09060104   0.        ]\n",
      "Episode =  253, total_reward =  172.10, , z=  35.78, v_z=   9.38, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82778704 -1.10985786  9.37962977],\n",
      " \t action=[900.12487239081349, -0.35871869630528341, 900.11091732496504, -0.36043593745905378], \n",
      " \t task.sim.pose=[-13.55890452  -3.69115095  35.77637306   2.07266215   2.09425472   0.        ]\n",
      "Episode =  254, total_reward =  170.99, , z=  35.40, v_z=   9.21, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75087044  2.02435629  9.20932314],\n",
      " \t action=[900.0825397371176, 0.27386842540492079, 900.16944385291663, 0.34237039949524661], \n",
      " \t task.sim.pose=[-13.29635206   3.71914392  35.39689564   2.13120825   2.06180101   0.        ]\n",
      "Episode =  255, total_reward =  171.07, , z=  35.45, v_z=   9.26, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88873374 -3.7576116   9.26488491],\n",
      " \t action=[900.04631035927082, 0.0023478455070017612, 899.78311885353912, -0.39469590483135719], \n",
      " \t task.sim.pose=[-13.7082149  -10.54468714  35.45339786   2.08609731   2.13085403   0.        ]\n",
      "Episode =  256, total_reward =  170.62, , z=  35.39, v_z=   9.28, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74613978  0.58198804  9.27907527],\n",
      " \t action=[899.49897076441073, -0.14885408041895243, 899.14890168236343, -0.19544452021550451], \n",
      " \t task.sim.pose=[-13.21972473   1.95770735  35.39423537   2.0982386    2.06792031   0.        ]\n",
      "Episode =  257, total_reward =  170.87, , z=  35.44, v_z=   9.28, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76102512  0.4782994   9.28476641],\n",
      " \t action=[899.4751700187752, -0.53707214079185328, 900.10010972941404, 0.19999356781114172], \n",
      " \t task.sim.pose=[-13.31929982   1.60631206  35.43890228   2.07072416   2.07704733   0.        ]\n",
      "Episode =  258, total_reward =  171.10, , z=  35.29, v_z=   9.10, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.70827721  3.09874733  9.10205513],\n",
      " \t action=[899.51204160079874, -0.17382364989753243, 899.87412378649117, -0.25339040453558209], \n",
      " \t task.sim.pose=[-13.24171871   6.89207747  35.29220796   2.14859604   2.07326629   0.        ]\n",
      "Episode =  259, total_reward =  172.01, , z=  35.74, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85736144 -2.066411    9.3625107 ],\n",
      " \t action=[899.01813865870895, 0.045207473974495149, 899.68443921663538, -0.28276628081323163], \n",
      " \t task.sim.pose=[-13.62103782  -6.91462997  35.73564477   2.10153573   2.11104945   0.        ]\n",
      "Episode =  260, total_reward =  171.77, , z=  35.62, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73512981  0.41606823  9.2993577 ],\n",
      " \t action=[899.63146149393754, 0.11243856989298254, 899.6795286131229, 0.25087342795239698], \n",
      " \t task.sim.pose=[-13.30755488   1.3722866   35.61611182   2.11529086   2.11678719   0.        ]\n",
      "Episode =  261, total_reward =  169.56, , z=  34.86, v_z=   8.93, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.69239757  4.26532699  8.93305154],\n",
      " \t action=[900.45487437513543, 0.2300655348411621, 900.59506803503075, -0.28043353542864208], \n",
      " \t task.sim.pose=[-13.03052413   9.46109285  34.86437296   2.13558147   2.0147804    0.        ]\n",
      "Episode =  262, total_reward =  170.71, , z=  35.49, v_z=   9.35, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84542626 -1.44092353  9.34863357],\n",
      " \t action=[899.90714950118775, 0.36583460099692211, 900.11522337510269, 0.12587656824388163], \n",
      " \t task.sim.pose=[-13.51553752  -5.22025169  35.49103345   2.08063907   2.07855288   0.        ]\n",
      "Episode =  263, total_reward =  171.40, , z=  35.58, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77653157 -0.14236093  9.3202931 ],\n",
      " \t action=[899.95250503724162, 0.11602861773459766, 899.70131097021579, -0.072095593719267659], \n",
      " \t task.sim.pose=[-13.36529942  -0.17176589  35.58289212   2.08638848   2.08367143   0.        ]\n",
      "Episode =  264, total_reward =  170.77, , z=  35.47, v_z=   9.31, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76954445 -0.35675978  9.31093719],\n",
      " \t action=[899.16946439067601, -0.27445759421408811, 899.45990423071623, -0.32197769676883958], \n",
      " \t task.sim.pose=[-13.25442208  -1.13591636  35.47163047   2.07860429   2.07883474   0.        ]\n",
      "Episode =  265, total_reward =  171.78, , z=  35.66, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84041026 -2.56497192  9.32609166],\n",
      " \t action=[900.00683139434818, 0.2255876339313484, 900.20807922647066, -0.53295289563264447], \n",
      " \t task.sim.pose=[-13.60889564  -6.50653664  35.66050744   2.07113721   2.12452512   0.        ]\n",
      "Episode =  266, total_reward =  171.08, , z=  35.56, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86497733 -1.43662477  9.36035396],\n",
      " \t action=[900.39596983763295, 0.32616364897332684, 899.61657157047466, 0.82204542300400463], \n",
      " \t task.sim.pose=[-13.59149442  -5.82281706  35.56303004   2.10327115   2.08198092   0.        ]\n",
      "Episode =  267, total_reward =  172.28, , z=  35.80, v_z=   9.38, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82279804 -0.68412572  9.37619219],\n",
      " \t action=[900.23204499596727, 0.52766738035577576, 900.16396652697313, -0.20191054501603417], \n",
      " \t task.sim.pose=[-13.58100054  -2.96623011  35.79600067   2.10041992   2.10481412   0.        ]\n",
      "Episode =  268, total_reward =  170.75, , z=  35.49, v_z=   9.35, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8546377  -1.65951551  9.34575834],\n",
      " \t action=[899.90270568160031, -0.08141614188908089, 900.12983838521393, 0.16102944857355339], \n",
      " \t task.sim.pose=[-13.53662262  -5.39488773  35.49130309   2.07396189   2.07285204   0.        ]\n",
      "Episode =  269, total_reward =  172.10, , z=  35.75, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83183047 -1.37740229  9.36280104],\n",
      " \t action=[899.50619943929325, 0.15634501726877795, 900.80836941257814, -0.11212597736316816], \n",
      " \t task.sim.pose=[-13.65249937  -5.21896306  35.74804609   2.12824802   2.14772241   0.        ]\n",
      "Episode =  270, total_reward =  171.33, , z=  35.54, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8545203  -3.02393361  9.28892576],\n",
      " \t action=[900.21781016382306, 0.70117601196823198, 900.04523701551159, -0.031616893203839008], \n",
      " \t task.sim.pose=[-13.61497446  -7.35332245  35.53727976   2.06067893   2.11648943   0.        ]\n",
      "Episode =  271, total_reward =  171.79, , z=  35.65, v_z=   9.31, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78511025  0.87560038  9.31348886],\n",
      " \t action=[900.15464206940965, 0.109702960914426, 900.4545397912816, 1.1073231352918433], \n",
      " \t task.sim.pose=[-13.43049325   1.19093533  35.64590053   2.10423221   2.07050937   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  272, total_reward =  171.67, , z=  35.61, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75173472  0.30837671  9.31902362],\n",
      " \t action=[899.84230288493507, 0.7842813484049721, 900.40050733514875, 0.031429151614115358], \n",
      " \t task.sim.pose=[-13.3152336    1.27450664  35.61486838   2.08880279   2.09036026   0.        ]\n",
      "Episode =  273, total_reward =  170.00, , z=  35.28, v_z=   9.27, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8550742  -2.89287274  9.26881676],\n",
      " \t action=[899.28184991292119, -0.38396703341085869, 900.17983012218724, 0.01629314975400889], \n",
      " \t task.sim.pose=[-13.5383226   -8.17834774  35.28404281   2.0705032    2.11191639   0.        ]\n",
      "Episode =  274, total_reward =  170.96, , z=  35.40, v_z=   9.20, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77780401  2.28384663  9.19770582],\n",
      " \t action=[900.03680313813425, -0.1653275412040639, 900.21696753577203, -0.45526910986113089], \n",
      " \t task.sim.pose=[-13.34255612   3.67250039  35.40215966   2.12377016   2.0361725    0.        ]\n",
      "Episode =  275, total_reward =  172.64, , z=  35.75, v_z=   9.28, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73044084  1.53536283  9.2815718 ],\n",
      " \t action=[899.85090013536058, 0.2326628358924801, 900.20370638721488, 0.13465407435812254], \n",
      " \t task.sim.pose=[-13.34989194   3.25037009  35.75325475   2.16514208   2.11250842   0.        ]\n",
      "Episode =  276, total_reward =  171.79, , z=  35.58, v_z=   9.25, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8561415  -3.82771473  9.24563332],\n",
      " \t action=[899.95536296558748, -0.038713565351528284, 899.30563378445856, 0.083150462393656283], \n",
      " \t task.sim.pose=[-13.62251155  -9.62277036  35.57940102   2.08982477   2.14848613   0.        ]\n",
      "Episode =  277, total_reward =  171.67, , z=  35.67, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84077006 -1.73959997  9.35957585],\n",
      " \t action=[900.30451706632334, 0.35069059640531403, 899.86280283939573, 0.61242121670956484], \n",
      " \t task.sim.pose=[-13.5289089   -4.72666148  35.67188489   2.05773415   2.07706077   0.        ]\n",
      "Episode =  278, total_reward =  170.94, , z=  35.53, v_z=   9.35, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83245351 -1.20294834  9.34603877],\n",
      " \t action=[899.91930195044472, 0.40828473309592073, 899.47725221002952, -0.35756507896981404], \n",
      " \t task.sim.pose=[-13.45694054  -4.20755723  35.52979037   2.08672598   2.07158906   0.        ]\n",
      "Episode =  279, total_reward =  170.29, , z=  35.31, v_z=   9.25, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74279411  1.11704992  9.25062056],\n",
      " \t action=[899.39697117734477, 0.70859588779557892, 900.35939517054669, 0.33069108971628375], \n",
      " \t task.sim.pose=[-13.16969058   2.26895171  35.31279674   2.08323771   2.06025738   0.        ]\n",
      "Episode =  280, total_reward =  171.78, , z=  35.70, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8127751  -1.11518651  9.35907145],\n",
      " \t action=[899.68638956992152, -0.44530107958197412, 899.95769252066088, 0.53231801556051472], \n",
      " \t task.sim.pose=[-13.48233583  -2.96104807  35.69797825   2.06771851   2.08475721   0.        ]\n",
      "Episode =  281, total_reward =  170.43, , z=  35.36, v_z=   9.26, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78039762 -2.22638922  9.25854768],\n",
      " \t action=[899.55852983375803, 0.7731080516210902, 900.42636220079112, -0.6471201324836634], \n",
      " \t task.sim.pose=[-13.36167215  -4.35832069  35.36108468   2.06511725   2.13039281   0.        ]\n",
      "Episode =  282, total_reward =  171.62, , z=  35.64, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77955679 -0.29072822  9.33539673],\n",
      " \t action=[900.19638100184807, 0.184394058487095, 900.1452331256769, -0.42672604860846797], \n",
      " \t task.sim.pose=[-13.42042346  -1.01177366  35.63571365   2.08763779   2.10230315   0.        ]\n",
      "Episode =  283, total_reward =  170.79, , z=  35.37, v_z=   9.25, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.92234224 -4.21377067  9.25250209],\n",
      " \t action=[899.63234964601975, -0.093137434489566129, 900.80170142218708, -0.49362895881506896], \n",
      " \t task.sim.pose=[-13.79123835 -12.16786544  35.37281044   2.06026891   2.12269315   0.        ]\n",
      "Episode =  284, total_reward =  170.98, , z=  35.41, v_z=   9.24, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72553047  1.49520435  9.23708129],\n",
      " \t action=[899.59206615290248, -0.86981556813012539, 900.41006446579627, -0.24050840173023313], \n",
      " \t task.sim.pose=[-13.22565239   3.77539185  35.40802506   2.11320488   2.08398694   0.        ]\n",
      "Episode =  285, total_reward =  171.42, , z=  35.55, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87199276 -3.25837983  9.29345683],\n",
      " \t action=[899.75003020738973, -0.15915322595430342, 900.20448945647195, -0.87079872532187441], \n",
      " \t task.sim.pose=[-13.7235744   -8.8091189   35.54981377   2.08556577   2.14230394   0.        ]\n",
      "Episode =  286, total_reward =  171.49, , z=  35.53, v_z=   9.24, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77533817  1.63852768  9.24468083],\n",
      " \t action=[899.80224169081851, 0.069742250491897154, 899.7316512660185, 0.2897911843679698], \n",
      " \t task.sim.pose=[-13.42381702   2.34929996  35.52699233   2.15098463   2.07830828   0.        ]\n",
      "Episode =  287, total_reward =  171.70, , z=  35.61, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82000368 -2.844575    9.28102435],\n",
      " \t action=[899.73597134163356, -0.020411119185532678, 900.13599699630424, -0.015960068768006819], \n",
      " \t task.sim.pose=[-13.58086959  -6.73740122  35.60619703   2.09581307   2.16017655   0.        ]\n",
      "Episode =  288, total_reward =  172.84, , z=  35.88, v_z=   9.35, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79118013  0.4564223   9.35035018],\n",
      " \t action=[899.82716645817641, -0.84277134997513137, 899.31507490518686, -0.36990978884425185], \n",
      " \t task.sim.pose=[-13.49678758  -0.74163377  35.88084402   2.15939659   2.10487409   0.        ]\n",
      "Episode =  289, total_reward =  171.98, , z=  35.72, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8010369  -0.98219558  9.35756261],\n",
      " \t action=[899.66803837264013, 0.41913239080584563, 899.86498055243339, -0.42505981929688719], \n",
      " \t task.sim.pose=[-13.46518205  -3.064482    35.7220131    2.10904016   2.10972887   0.        ]\n",
      "Episode =  290, total_reward =  171.62, , z=  35.59, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74799425  0.83024675  9.2990262 ],\n",
      " \t action=[900.47295977913689, -0.20888412871720621, 900.61204390772184, -0.84710661860576209], \n",
      " \t task.sim.pose=[-13.31364418   1.6452947   35.59005435   2.0978696    2.09170842   0.        ]\n",
      "Episode =  291, total_reward =  170.18, , z=  35.23, v_z=   9.20, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86855036 -4.19047864  9.19981838],\n",
      " \t action=[900.34126111800879, -0.14333948226772897, 900.06314057433462, 0.30732435742504055], \n",
      " \t task.sim.pose=[-13.60113128 -11.16745966  35.22772154   2.08392482   2.14363082   0.        ]\n",
      "Episode =  292, total_reward =  170.54, , z=  35.15, v_z=   9.08, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.69535151  3.11592901  9.07518353],\n",
      " \t action=[899.67611639034851, -0.11830531836397859, 900.29920763583414, -0.18736221896515826], \n",
      " \t task.sim.pose=[-13.19403548   7.29479448  35.14846165   2.14220884   2.07824929   0.        ]\n",
      "Episode =  293, total_reward =  172.22, , z=  35.78, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81413903 -0.9579434   9.37261024],\n",
      " \t action=[900.26699799076994, 0.02119073704104571, 899.77566498735348, -0.20380940273326431], \n",
      " \t task.sim.pose=[-13.52741961  -3.06165223  35.78024063   2.08943807   2.10108722   0.        ]\n",
      "Episode =  294, total_reward =  172.11, , z=  35.75, v_z=   9.38, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8508743  -1.32441049  9.38000441],\n",
      " \t action=[900.07586107660927, -0.29800998314425298, 900.20799388150851, -0.57611217469594056], \n",
      " \t task.sim.pose=[-13.68351337  -5.46560706  35.74996733   2.14089993   2.13243255   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  295, total_reward =  171.69, , z=  35.64, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80430249 -1.41655196  9.34179624],\n",
      " \t action=[900.85548252014519, 0.45737829861906759, 899.71182865095864, 0.0042996589659632101], \n",
      " \t task.sim.pose=[-13.51627375  -3.87609661  35.64449217   2.11217359   2.12750854   0.        ]\n",
      "Episode =  296, total_reward =  170.99, , z=  35.53, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8845545 -2.2389111  9.3536002],\n",
      " \t action=[899.71145006150675, 0.51980212266280856, 900.13244342676774, 0.59742196518675195], \n",
      " \t task.sim.pose=[-13.6252353   -7.66862593  35.53153931   2.07179346   2.08203652   0.        ]\n",
      "Episode =  297, total_reward =  172.52, , z=  35.82, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79003605  0.35613465  9.35303586],\n",
      " \t action=[899.89934101745541, -0.16656810398266164, 899.7375222426657, 0.10592959993192232], \n",
      " \t task.sim.pose=[-13.46519128  -0.17121049  35.81714748   2.11758586   2.09201959   0.        ]\n",
      "Episode =  298, total_reward =  171.36, , z=  35.52, v_z=   9.26, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76553865  1.42280238  9.26354774],\n",
      " \t action=[900.07522184188053, -0.37402869160896579, 899.77073948060263, -0.68368345567879363], \n",
      " \t task.sim.pose=[-13.36106432   2.64806213  35.51521291   2.11523376   2.06618628   0.        ]\n",
      "Episode =  299, total_reward =  172.12, , z=  35.71, v_z=   9.32, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79214608 -1.68725422  9.32256767],\n",
      " \t action=[899.65037797704792, 0.31579314669839076, 899.83793136350755, -0.18973656462975522], \n",
      " \t task.sim.pose=[-13.57152705  -4.07422188  35.71258738   2.13197485   2.17274423   0.        ]\n",
      "Episode =  300, total_reward =  169.91, , z=  35.13, v_z=   9.15, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73333535  2.27756222  9.15444254],\n",
      " \t action=[900.41540857481482, 0.10363761593422142, 900.03721362857675, -0.15456531084178177], \n",
      " \t task.sim.pose=[-13.24722522   5.70321939  35.1292389    2.11026664   2.05306316   0.        ]\n",
      "Episode =  301, total_reward =  172.11, , z=  35.73, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78195856 -0.79536666  9.33216772],\n",
      " \t action=[899.70243720483245, 0.18502162634986896, 899.69522785984827, -0.48789791708728103], \n",
      " \t task.sim.pose=[-13.48415495  -1.7655704   35.7283069    2.10999999   2.13055862   0.        ]\n",
      "Episode =  302, total_reward =  170.30, , z=  35.31, v_z=   9.23, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85531115 -3.65836996  9.23196562],\n",
      " \t action=[899.76179476292407, -0.94206378569400062, 899.90521224554152, 0.53642662774336136], \n",
      " \t task.sim.pose=[-13.5413707   -9.22567761  35.30761832   2.04172955   2.1129784    0.        ]\n",
      "Episode =  303, total_reward =  171.68, , z=  35.65, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79610791  0.1682997   9.33891334],\n",
      " \t action=[900.41050343551171, -0.093110795032100832, 900.01673858915626, -0.37427450396772499], \n",
      " \t task.sim.pose=[-13.44178602  -1.26612787  35.64946451   2.13198832   2.09214234   0.        ]\n",
      "Episode =  304, total_reward =  170.42, , z=  35.32, v_z=   9.25, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.90363981 -4.10624922  9.25108884],\n",
      " \t action=[900.0490390709972, 0.76725701336215735, 899.40749102103916, 0.75198014893974718], \n",
      " \t task.sim.pose=[-13.62973097 -11.54789752  35.31895051   2.04727555   2.09493381   0.        ]\n",
      "Episode =  305, total_reward =  170.90, , z=  35.42, v_z=   9.27, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76475525  1.20036574  9.26590744],\n",
      " \t action=[900.15006871411583, 0.38020053126893094, 900.51898571179333, -0.13146915109812005], \n",
      " \t task.sim.pose=[-13.34719323   1.84460475  35.42121682   2.12778131   2.08088297   0.        ]\n",
      "Episode =  306, total_reward =  171.37, , z=  35.61, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80685373 -0.22321037  9.35288539],\n",
      " \t action=[900.01982248830473, -0.37164519370369059, 900.33153850674285, 0.018873703273928039], \n",
      " \t task.sim.pose=[-13.39967538  -2.12677179  35.61434202   2.08181575   2.07156104   0.        ]\n",
      "Episode =  307, total_reward =  171.56, , z=  35.64, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81978197 -0.90199834  9.36422546],\n",
      " \t action=[900.04340217008769, -0.49656879650600061, 900.21551598478118, -0.22879350384909294], \n",
      " \t task.sim.pose=[-13.42943017  -3.44365865  35.64418157   2.10138233   2.07616269   0.        ]\n",
      "Episode =  308, total_reward =  171.28, , z=  35.56, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81307051  0.48620253  9.32062404],\n",
      " \t action=[900.63584365152872, -0.16818950623720896, 899.62012987927551, 0.42093067068069179], \n",
      " \t task.sim.pose=[-13.48495308  -0.57531769  35.56404516   2.10713634   2.0634098    0.        ]\n",
      "Episode =  309, total_reward =  170.95, , z=  35.49, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77068737  0.17368394  9.30097886],\n",
      " \t action=[899.42970389303048, 0.5414623875893757, 899.81838568603484, 0.16758958822814696], \n",
      " \t task.sim.pose=[-13.36034332  -0.53289685  35.48582079   2.11319045   2.10030108   0.        ]\n",
      "Episode =  310, total_reward =  171.16, , z=  35.57, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82725855 -1.17446108  9.35652604],\n",
      " \t action=[899.74135107158247, -0.120487513513927, 899.91589517726163, 0.7820023602415993], \n",
      " \t task.sim.pose=[-13.48031519  -3.98060027  35.56651829   2.07932075   2.08282187   0.        ]\n",
      "Episode =  311, total_reward =  171.06, , z=  35.51, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78565673  0.29867469  9.31735129],\n",
      " \t action=[899.71015758252554, -0.31268085053763173, 899.75450434136121, -0.36566670965169851], \n",
      " \t task.sim.pose=[-13.39544136   0.15116688  35.50577525   2.11196925   2.07534367   0.        ]\n",
      "Episode =  312, total_reward =  170.89, , z=  35.41, v_z=   9.26, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72795987  0.77889737  9.25785433],\n",
      " \t action=[900.0723553451495, -0.099037824326518864, 900.13794778235786, 0.90346231723555892], \n",
      " \t task.sim.pose=[-13.27102582   2.36778875  35.40912775   2.1211782    2.10814366   0.        ]\n",
      "Episode =  313, total_reward =  172.02, , z=  35.74, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81672446  0.50688741  9.3460466 ],\n",
      " \t action=[899.51650028798031, -0.11096086926139809, 900.30327967288099, 0.38135554909450259], \n",
      " \t task.sim.pose=[-13.46280595  -1.13163019  35.73717932   2.10930538   2.0602013    0.        ]\n",
      "Episode =  314, total_reward =  170.51, , z=  35.40, v_z=   9.30, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77039342 -0.26658676  9.2956228 ],\n",
      " \t action=[900.32689157463255, 0.074498823203675957, 900.46870087805314, -0.23984680017936866], \n",
      " \t task.sim.pose=[-13.37812535  -0.70899441  35.39536754   2.09935547   2.10519302   0.        ]\n",
      "Episode =  315, total_reward =  171.44, , z=  35.61, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86571497 -2.5362419   9.34430826],\n",
      " \t action=[899.35510167708128, 0.18596486184182517, 900.35952715198289, -0.28873763722288892], \n",
      " \t task.sim.pose=[-13.61679296  -7.66613642  35.61381112   2.07278606   2.10318181   0.        ]\n",
      "Episode =  316, total_reward =  170.55, , z=  35.41, v_z=   9.31, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84666895 -2.41772147  9.31070545],\n",
      " \t action=[899.69353051630208, -0.24920109346916347, 899.89912069922639, -0.16102346574451259], \n",
      " \t task.sim.pose=[-13.51430506  -6.85027226  35.41336433   2.07650422   2.09852288   0.        ]\n",
      "Episode =  317, total_reward =  171.25, , z=  35.58, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82475145 -0.99895576  9.34074567],\n",
      " \t action=[899.52970582049943, 0.20467435905905651, 899.66996182025082, -0.042076552867354566], \n",
      " \t task.sim.pose=[-13.51805437  -3.74924285  35.57533267   2.11236777   2.10242033   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  318, total_reward =  172.02, , z=  35.71, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82362774 -2.17610815  9.33832694],\n",
      " \t action=[899.9302380328628, 0.59058012260199089, 900.02566260731157, 0.17977363053100248], \n",
      " \t task.sim.pose=[-13.57693994  -5.35178409  35.70609504   2.09117945   2.13427743   0.        ]\n",
      "Episode =  319, total_reward =  171.70, , z=  35.50, v_z=   9.20, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74659211  2.3705131   9.19590248],\n",
      " \t action=[900.07871290161154, 0.021866855899844689, 900.68753891545737, -0.02947500203882903], \n",
      " \t task.sim.pose=[-13.3745763    4.24145425  35.49815536   2.13920966   2.08032828   0.        ]\n",
      "Episode =  320, total_reward =  171.92, , z=  35.69, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81100467 -1.95536113  9.34868838],\n",
      " \t action=[900.07391036560068, 0.3170960697132395, 899.61905082521037, 0.45440218091095746], \n",
      " \t task.sim.pose=[-13.48803052  -5.43459721  35.69335034   2.10462897   2.12926705   0.        ]\n",
      "Episode =  321, total_reward =  171.48, , z=  35.62, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79114258 -0.04952764  9.33974656],\n",
      " \t action=[900.25671073815806, -0.29489541250131657, 899.82315804862367, 0.51215582759862599], \n",
      " \t task.sim.pose=[-13.40598024  -1.13437804  35.62346208   2.09005684   2.08593571   0.        ]\n",
      "Episode =  322, total_reward =  170.54, , z=  35.41, v_z=   9.31, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7955961  -1.38978835  9.31424612],\n",
      " \t action=[899.97847575261676, -0.14333604831405883, 900.7905868072238, -0.078021498588117355], \n",
      " \t task.sim.pose=[-13.37707664  -3.32329613  35.41006202   2.07706862   2.09871345   0.        ]\n",
      "Episode =  323, total_reward =  172.23, , z=  35.74, v_z=   9.32, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78562014 -1.44858386  9.32162202],\n",
      " \t action=[899.96606884506616, 0.23129807314934572, 900.7963626052624, -0.78583949682036724], \n",
      " \t task.sim.pose=[-13.5727071   -2.80316536  35.73945577   2.10271075   2.16063628   0.        ]\n",
      "Episode =  324, total_reward =  171.70, , z=  35.63, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8140223  -2.19156444  9.31732982],\n",
      " \t action=[899.9672179864358, -0.92862724649552597, 899.63106667040768, 0.31022718064126337], \n",
      " \t task.sim.pose=[-13.54112358  -5.22810751  35.63136536   2.09909458   2.13729034   0.        ]\n",
      "Episode =  325, total_reward =  170.96, , z=  35.47, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76402775  0.78875547  9.29355646],\n",
      " \t action=[900.67821182986711, -0.24851823725035116, 899.75635842732333, 0.28555432933135116], \n",
      " \t task.sim.pose=[-13.27807076   1.79245322  35.47094027   2.09121768   2.05715433   0.        ]\n",
      "Episode =  326, total_reward =  172.26, , z=  35.72, v_z=   9.32, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85064208 -3.10756519  9.31981062],\n",
      " \t action=[899.54893060874019, -0.47305016474374206, 900.03758509463864, -0.29172097271384378], \n",
      " \t task.sim.pose=[-13.64488672  -8.77360004  35.72056008   2.12384243   2.1563894    0.        ]\n",
      "Episode =  327, total_reward =  171.38, , z=  35.54, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8894467  -3.33298281  9.30507498],\n",
      " \t action=[899.59854120624061, 0.79892071947790155, 900.1449578209324, 0.21783295290385027], \n",
      " \t task.sim.pose=[-13.71530102  -9.70524234  35.54386804   2.09337049   2.1244259    0.        ]\n",
      "Episode =  328, total_reward =  170.48, , z=  35.24, v_z=   9.13, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86363297 -4.76976869  9.128446  ],\n",
      " \t action=[899.93819627770915, -1.0327926774709875, 900.00979311289007, 0.0033780445750506705], \n",
      " \t task.sim.pose=[-13.59895609 -11.44723703  35.2434842    2.04904953   2.14616663   0.        ]\n",
      "Episode =  329, total_reward =  172.68, , z=  35.85, v_z=   9.36, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82185797 -1.71414861  9.3575557 ],\n",
      " \t action=[900.25731370015023, 0.13363538914113726, 899.11655615829068, -0.068192957813443089], \n",
      " \t task.sim.pose=[-13.64703884  -5.12605145  35.84642239   2.15390646   2.16103615   0.        ]\n",
      "Episode =  330, total_reward =  171.27, , z=  35.48, v_z=   9.25, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88035369 -3.91031079  9.24810931],\n",
      " \t action=[899.43083480535097, 0.1882024821381747, 899.64078953815101, 0.42913718336418427], \n",
      " \t task.sim.pose=[-13.66214215 -10.22739647  35.48373907   2.0714011    2.12449699   0.        ]\n",
      "Episode =  331, total_reward =  172.67, , z=  35.81, v_z=   9.32, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75759863 -0.70489538  9.3214089 ],\n",
      " \t action=[899.84410457924207, 0.072874120840171697, 899.90681350296154, 0.16655292814147538], \n",
      " \t task.sim.pose=[-13.52527399  -0.62808822  35.81386242   2.11165946   2.16045594   0.        ]\n",
      "Episode =  332, total_reward =  171.10, , z=  35.41, v_z=   9.21, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88457404 -4.19749545  9.20711389],\n",
      " \t action=[899.16030235438336, -0.60891767976204736, 900.17629720104696, 0.17719370908712334], \n",
      " \t task.sim.pose=[-13.70936071 -10.62739749  35.41289465   2.06431005   2.13964535   0.        ]\n",
      "Episode =  333, total_reward =  170.15, , z=  35.09, v_z=   9.11, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.6865754   2.70875202  9.10559451],\n",
      " \t action=[900.34059143126899, -0.34937084100303473, 899.69782321696835, -0.012806039469721087], \n",
      " \t task.sim.pose=[-13.15484261   7.50535284  35.09160381   2.13781738   2.08358827   0.        ]\n",
      "Episode =  334, total_reward =  172.16, , z=  35.79, v_z=   9.39, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84631227 -0.90062872  9.38834068],\n",
      " \t action=[899.85849301058124, -0.7027243870262323, 899.99070361404688, -0.15508827046358242], \n",
      " \t task.sim.pose=[-13.61746057  -4.34871333  35.78871262   2.11308262   2.09718483   0.        ]\n",
      "Episode =  335, total_reward =  171.98, , z=  35.70, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79229142 -1.92827229  9.33093712],\n",
      " \t action=[899.74154380359289, -0.1480606723893455, 899.98524312150596, -0.052945049923260754], \n",
      " \t task.sim.pose=[-13.43554653  -4.33316104  35.7035642    2.07938256   2.12405893   0.        ]\n",
      "Episode =  336, total_reward =  170.35, , z=  35.23, v_z=   9.15, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73974598  2.38196762  9.15196106],\n",
      " \t action=[900.07222610664405, -0.34622222449621509, 899.94917455224709, -0.48189751550278082], \n",
      " \t task.sim.pose=[-13.28789055   4.48028519  35.22507083   2.14608202   2.06840907   0.        ]\n",
      "Episode =  337, total_reward =  171.60, , z=  35.62, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81971481 -2.25311309  9.32355887],\n",
      " \t action=[900.03808108320618, -0.49410316466139348, 900.04428239396725, -0.43954702766600795], \n",
      " \t task.sim.pose=[-13.51531775  -5.21617951  35.61529633   2.07383582   2.11624011   0.        ]\n",
      "Episode =  338, total_reward =  170.69, , z=  35.23, v_z=   9.09, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7345236   3.04054493  9.09321503],\n",
      " \t action=[900.18927766356694, 0.39797462823936824, 899.53349809460644, -0.54709535571785228], \n",
      " \t task.sim.pose=[-13.32838665   6.10880012  35.23060653   2.17049371   2.07246399   0.        ]\n",
      "Episode =  339, total_reward =  170.87, , z=  35.41, v_z=   9.24, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85826438 -3.58591771  9.24376909],\n",
      " \t action=[900.17983483083049, -0.2319101994276816, 899.38840858139713, 0.32521400798234301], \n",
      " \t task.sim.pose=[-13.60541646  -8.94018622  35.40606889   2.07351363   2.12963407   0.        ]\n",
      "Episode =  340, total_reward =  171.06, , z=  35.49, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81857723 -2.61322191  9.28371621],\n",
      " \t action=[899.71619457637223, 0.031303062485970007, 899.92269550421224, -0.38676120468788777], \n",
      " \t task.sim.pose=[-13.49758013  -6.03349869  35.49331091   2.07089408   2.12375264   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  341, total_reward =  171.58, , z=  35.58, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84570838 -3.25853447  9.30274151],\n",
      " \t action=[900.23551272801421, -0.073786287524087918, 900.60253145617139, -0.12595934638649942], \n",
      " \t task.sim.pose=[-13.56287488  -9.00917463  35.58463244   2.08428809   2.13594861   0.        ]\n",
      "Episode =  342, total_reward =  170.39, , z=  35.16, v_z=   9.08, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73278071  3.21544207  9.0815698 ],\n",
      " \t action=[900.11148987535489, 0.25630874862470843, 900.21360515593869, -0.029563866485754348], \n",
      " \t task.sim.pose=[-13.21572578   6.43447408  35.15967474   2.13652368   2.03574921   0.        ]\n",
      "Episode =  343, total_reward =  170.91, , z=  35.51, v_z=   9.32, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82719849 -1.68829058  9.32301217],\n",
      " \t action=[900.22696855072218, 0.4203439321452207, 899.96190286947331, 0.16883165858005902], \n",
      " \t task.sim.pose=[-13.51544236  -4.56800599  35.51387245   2.05954331   2.09202947   0.        ]\n",
      "Episode =  344, total_reward =  170.86, , z=  35.41, v_z=   9.26, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7505322   1.2456458   9.26259606],\n",
      " \t action=[899.85555484847725, -0.14004595464893463, 900.12943056373081, -0.15758475140419451], \n",
      " \t task.sim.pose=[-13.21943201   3.1230891   35.41110355   2.08410254   2.04589124   0.        ]\n",
      "Episode =  345, total_reward =  171.71, , z=  35.62, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82872108 -3.1689162   9.29236878],\n",
      " \t action=[900.11076762837149, -0.081462493698607891, 899.97758354242126, 0.59324458645030276], \n",
      " \t task.sim.pose=[-13.51528707  -7.90582484  35.61556479   2.07257453   2.13471627   0.        ]\n",
      "Episode =  346, total_reward =  170.20, , z=  35.40, v_z=   9.34, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84207258 -0.88644213  9.3391275 ],\n",
      " \t action=[899.87856244265549, -0.13721940098507412, 900.4308066985393, -0.294735472434559], \n",
      " \t task.sim.pose=[-13.42936625  -3.44320354  35.4043786    2.03483635   2.03463778   0.        ]\n",
      "Episode =  347, total_reward =  170.41, , z=  35.43, v_z=   9.34, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82819993 -0.98969426  9.34040084],\n",
      " \t action=[900.17707494261185, -0.26074639166826641, 899.47205564968522, -0.28323355406491413], \n",
      " \t task.sim.pose=[-13.33244358  -3.57263096  35.43188234   2.06360308   2.03547673   0.        ]\n",
      "Episode =  348, total_reward =  171.23, , z=  35.52, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76176067  0.10556139  9.29470791],\n",
      " \t action=[899.76570781787711, 0.06225050846537955, 900.2976574538277, -0.47847826685119998], \n",
      " \t task.sim.pose=[-13.40532699   0.4840141   35.51587588   2.0941006    2.1118529    0.        ]\n",
      "Episode =  349, total_reward =  171.62, , z=  35.64, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84487916 -2.1937497   9.34719753],\n",
      " \t action=[900.55640144133963, -0.62612130143265732, 900.25306352024552, 0.68676678654698731], \n",
      " \t task.sim.pose=[-13.58152059  -6.30470289  35.64284695   2.08088912   2.11021597   0.        ]\n",
      "Episode =  350, total_reward =  171.34, , z=  35.58, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81563309 -0.92230847  9.34477984],\n",
      " \t action=[900.52622413949189, -0.53091850003550567, 900.12809385816399, -0.40954266331871492], \n",
      " \t task.sim.pose=[-13.52280735  -3.54280983  35.58231728   2.12058718   2.11196351   0.        ]\n",
      "Episode =  351, total_reward =  170.64, , z=  35.34, v_z=   9.25, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74234213  1.16030514  9.24848963],\n",
      " \t action=[900.37075913997762, 0.37885969066319392, 900.19310157568248, -0.35084585444418542], \n",
      " \t task.sim.pose=[-13.30360575   3.37307749  35.34476635   2.10776158   2.08104031   0.        ]\n",
      "Episode =  352, total_reward =  170.11, , z=  35.37, v_z=   9.33, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82971047 -1.1148993   9.33279975],\n",
      " \t action=[899.87502339372509, 0.26653101449865424, 900.70438504673245, -0.70511255361791747], \n",
      " \t task.sim.pose=[-13.36621282  -4.10563342  35.36602929   2.06190168   2.04706112   0.        ]\n",
      "Episode =  353, total_reward =  171.36, , z=  35.57, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83666679 -2.41741078  9.31092678],\n",
      " \t action=[900.03969877939835, 0.10370570125058715, 899.999922845784, -0.22895282599660685], \n",
      " \t task.sim.pose=[-13.60707843  -5.97746445  35.565664     2.07892599   2.12855838   0.        ]\n",
      "Episode =  354, total_reward =  171.64, , z=  35.61, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76007587  0.03885683  9.30638097],\n",
      " \t action=[899.8000945018025, -0.43782551595570252, 900.82723468654422, -0.25018395760066692], \n",
      " \t task.sim.pose=[-13.46685751   0.15763206  35.60812716   2.11609756   2.13896087   0.        ]\n",
      "Episode =  355, total_reward =  172.13, , z=  35.69, v_z=   9.30, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85400828 -3.3977241   9.30430272],\n",
      " \t action=[899.92829289109886, -0.1712110611505015, 899.75962740343482, -0.049289900937637902], \n",
      " \t task.sim.pose=[-13.65923106  -9.72100003  35.68558907   2.12463027   2.16778285   0.        ]\n",
      "Episode =  356, total_reward =  171.49, , z=  35.60, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85508128 -2.60135721  9.32474468],\n",
      " \t action=[900.01532740516006, 0.32373244104988497, 900.00432745552791, 0.024231114517757113], \n",
      " \t task.sim.pose=[-13.58929915  -7.47613327  35.60257081   2.09335208   2.11393731   0.        ]\n",
      "Episode =  357, total_reward =  171.68, , z=  35.63, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80660639 -2.0980194   9.30994887],\n",
      " \t action=[899.3480815758677, 0.89850173196868088, 900.5456599665024, 0.078143361289863086], \n",
      " \t task.sim.pose=[-13.53151466  -4.43288772  35.63124616   2.06674154   2.13022984   0.        ]\n",
      "Episode =  358, total_reward =  171.46, , z=  35.53, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.71537912  0.84258882  9.27962112],\n",
      " \t action=[900.10434344701059, -0.31754231408081557, 899.96251427709831, -0.30735021728733014], \n",
      " \t task.sim.pose=[-13.21090449   2.50550805  35.5297316    2.11172207   2.10734418   0.        ]\n",
      "Episode =  359, total_reward =  171.24, , z=  35.57, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84377759 -2.27080242  9.3336277 ],\n",
      " \t action=[900.09743956078376, 0.61237056115584165, 899.4647687719613, -0.55976398688293827], \n",
      " \t task.sim.pose=[-13.50621732  -6.09657528  35.56867572   2.06427529   2.08584649   0.        ]\n",
      "Episode =  360, total_reward =  170.70, , z=  35.46, v_z=   9.32, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80202911 -0.15673227  9.32285202],\n",
      " \t action=[900.54253813866421, -0.86648516011611132, 900.25325882582365, 0.6435535677557136], \n",
      " \t task.sim.pose=[-13.40205592  -0.64528116  35.45685436   2.06124312   2.05976421   0.        ]\n",
      "Episode =  361, total_reward =  171.21, , z=  35.50, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.89233355 -3.39105112  9.30096539],\n",
      " \t action=[900.40691913665762, -0.7785335628873099, 899.44901481868192, -0.51792114551854773], \n",
      " \t task.sim.pose=[-13.70676756  -9.95979735  35.49792924   2.09948617   2.12344622   0.        ]\n",
      "Episode =  362, total_reward =  171.79, , z=  35.69, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79956482 -1.29285561  9.34827746],\n",
      " \t action=[899.9318792176266, 0.12917249105361117, 900.71847945696493, 0.54506710299768368], \n",
      " \t task.sim.pose=[-13.44806271  -3.04204927  35.69372363   2.0669398    2.09875866   0.        ]\n",
      "Episode =  363, total_reward =  171.71, , z=  35.64, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8287399  -2.60909025  9.32236787],\n",
      " \t action=[899.5775378386619, 0.56868340991640653, 899.49558546592527, 0.008967288239508292], \n",
      " \t task.sim.pose=[-13.58141771  -7.77311498  35.63516504   2.12494855   2.16296039   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  364, total_reward =  170.60, , z=  35.39, v_z=   9.26, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.761701    1.12590593  9.26066764],\n",
      " \t action=[899.35824215491766, -0.31578250858600904, 900.26579219576411, -0.16251864843703495], \n",
      " \t task.sim.pose=[-13.26417133   2.06759548  35.38933093   2.0860688    2.05448009   0.        ]\n",
      "Episode =  365, total_reward =  171.02, , z=  35.46, v_z=   9.27, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74341228  0.93189392  9.27279212],\n",
      " \t action=[899.73019737150548, -0.55243749154142996, 899.79965869155842, 0.19124907461175789], \n",
      " \t task.sim.pose=[-13.21773031   2.69047962  35.45995723   2.08102943   2.06268563   0.        ]\n",
      "Episode =  366, total_reward =  170.73, , z=  35.38, v_z=   9.26, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72584046  0.47929099  9.2599812 ],\n",
      " \t action=[899.8937021905291, 0.34757501642925526, 900.54648853582387, 0.42795537986926735], \n",
      " \t task.sim.pose=[-13.29840354   2.48220696  35.37779799   2.10679986   2.11554816   0.        ]\n",
      "Episode =  367, total_reward =  173.15, , z=  35.89, v_z=   9.31, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7679144   1.18483631  9.31485931],\n",
      " \t action=[899.26808269999935, -0.52362998985609854, 899.8032965685727, -0.91407619889787362], \n",
      " \t task.sim.pose=[-13.51732305   1.00129491  35.88826804   2.17618608   2.13008486   0.        ]\n",
      "Episode =  368, total_reward =  171.03, , z=  35.51, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76997988  0.11463205  9.315315  ],\n",
      " \t action=[899.66900714652934, -0.49616315831897329, 900.23707806287075, -0.10714665366437259], \n",
      " \t task.sim.pose=[-13.34253991  -0.81043782  35.50893329   2.12210573   2.10161363   0.        ]\n",
      "Episode =  369, total_reward =  171.93, , z=  35.70, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78450521 -0.1111006   9.35006054],\n",
      " \t action=[900.24406004085574, -0.27471779367236804, 900.47657964758616, -0.088373876935448792], \n",
      " \t task.sim.pose=[-13.40384327  -1.35958861  35.69990222   2.12602033   2.1005519    0.        ]\n",
      "Episode =  370, total_reward =  170.86, , z=  35.47, v_z=   9.32, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.89784573 -2.93579486  9.32076014],\n",
      " \t action=[900.16174936062214, -0.17133397155182459, 899.97841980867418, -0.79653515265480523], \n",
      " \t task.sim.pose=[-13.72935602  -9.35656805  35.46743316   2.09580525   2.11319226   0.        ]\n",
      "Episode =  371, total_reward =  170.57, , z=  35.36, v_z=   9.26, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.90136112 -3.64057638  9.2616491 ],\n",
      " \t action=[900.05379632224424, 0.24188650918479773, 900.14797378214519, 0.15811071739854046], \n",
      " \t task.sim.pose=[-13.78911763 -10.6445957   35.35877375   2.09253434   2.14308274   0.        ]\n",
      "Episode =  372, total_reward =  170.62, , z=  35.40, v_z=   9.29, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75439478  0.46998016  9.28695114],\n",
      " \t action=[899.17940914961218, 0.054494692373053988, 899.75752463183323, 0.13810041019476846], \n",
      " \t task.sim.pose=[-13.26883885   1.28123944  35.39563357   2.09322672   2.07966392   0.        ]\n",
      "Episode =  373, total_reward =  171.65, , z=  35.63, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79365676  0.48882077  9.32160456],\n",
      " \t action=[899.96688567764465, -0.51844317176921018, 899.72228758779795, 0.13502519863924606], \n",
      " \t task.sim.pose=[-13.45647697   0.10907317  35.63136476   2.10234274   2.07787473   0.        ]\n",
      "Episode =  374, total_reward =  171.12, , z=  35.51, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77964383  1.06806329  9.28659493],\n",
      " \t action=[900.03837990069212, 0.77598736410374114, 900.48140311687655, 0.24392087986505645], \n",
      " \t task.sim.pose=[-13.31824551   0.81333635  35.50572283   2.1209207    2.05821445   0.        ]\n",
      "Episode =  375, total_reward =  172.01, , z=  35.67, v_z=   9.32, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7361344   0.47813123  9.31570217],\n",
      " \t action=[900.74365478896948, 0.11294125435518954, 899.7847022333093, 0.37817602543200529], \n",
      " \t task.sim.pose=[-13.33480761   1.03427474  35.67059969   2.13462906   2.12922295   0.        ]\n",
      "Episode =  376, total_reward =  172.01, , z=  35.73, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81186405 -0.49890567  9.3630734 ],\n",
      " \t action=[900.16772851496535, 0.37410747303067254, 900.18953723193567, 0.32285164675977779], \n",
      " \t task.sim.pose=[-13.53519942  -2.25674278  35.73251696   2.10319021   2.09771387   0.        ]\n",
      "Episode =  377, total_reward =  171.33, , z=  35.62, v_z=   9.38, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8887613  -1.59774318  9.37925493],\n",
      " \t action=[900.11538107758804, 0.093128620337936119, 899.51977621546973, -0.46811648831524794], \n",
      " \t task.sim.pose=[-13.66856254  -7.46400226  35.61666216   2.1206978    2.08915446   0.        ]\n",
      "Episode =  378, total_reward =  170.52, , z=  35.38, v_z=   9.29, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.879951   -3.22030864  9.28925108],\n",
      " \t action=[899.85977090625738, -0.39377820277070519, 899.76075033802124, 0.63934722169613145], \n",
      " \t task.sim.pose=[-13.60135468  -9.05805412  35.38327392   2.05981206   2.09325578   0.        ]\n",
      "Episode =  379, total_reward =  171.44, , z=  35.57, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85070163 -2.6368138   9.32209377],\n",
      " \t action=[900.10628936347837, 0.35785562673532523, 899.97467690357894, 0.45125495298166174], \n",
      " \t task.sim.pose=[-13.62764133  -7.78211906  35.56982298   2.11784277   2.1410476    0.        ]\n",
      "Episode =  380, total_reward =  171.42, , z=  35.56, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85406362 -3.44604482  9.27708728],\n",
      " \t action=[899.33545205023677, 0.55396825426629259, 900.35888157384795, 0.21809424694940749], \n",
      " \t task.sim.pose=[-13.61757042  -8.94379556  35.55617679   2.05222224   2.13284003   0.        ]\n",
      "Episode =  381, total_reward =  171.11, , z=  35.52, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79233062 -0.26989484  9.31793723],\n",
      " \t action=[899.6040830853608, -0.43487899949869097, 900.47260337679927, -0.03108418504075211], \n",
      " \t task.sim.pose=[-13.47237231  -0.86893696  35.52013949   2.09614566   2.10232966   0.        ]\n",
      "Episode =  382, total_reward =  171.10, , z=  35.52, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81492823 -2.02720446  9.31676213],\n",
      " \t action=[900.27884040675247, -0.39624111152314112, 900.21601920602291, 0.83037132754809995], \n",
      " \t task.sim.pose=[-13.44839371  -4.99560801  35.52117398   2.08457504   2.10890922   0.        ]\n",
      "Episode =  383, total_reward =  171.52, , z=  35.55, v_z=   9.27, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.733881    0.86687408  9.27448178],\n",
      " \t action=[900.48303640250413, 0.070067003020959834, 900.64698841601387, -0.54004925532778947], \n",
      " \t task.sim.pose=[-13.34544337   1.41819222  35.54660824   2.15720785   2.13375598   0.        ]\n",
      "Episode =  384, total_reward =  172.89, , z=  35.91, v_z=   9.38, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7892715  -0.0599714   9.37731348],\n",
      " \t action=[899.93974499899014, -0.5931139902818201, 899.54014662324118, -0.47059969652225508], \n",
      " \t task.sim.pose=[-13.48733044  -0.56684807  35.91178177   2.10655745   2.09634765   0.        ]\n",
      "Episode =  385, total_reward =  170.74, , z=  35.33, v_z=   9.19, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88403345 -4.49252382  9.1867326 ],\n",
      " \t action=[899.2457773071169, 0.16490432177492709, 899.92058913665312, -0.15356575009076437], \n",
      " \t task.sim.pose=[-13.69630276 -11.59626839  35.33220685   2.05400624   2.14705882   0.        ]\n",
      "Episode =  386, total_reward =  170.86, , z=  35.44, v_z=   9.29, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86575441 -3.23705977  9.28612171],\n",
      " \t action=[899.9145413368019, -0.49714246703819825, 899.66881674893443, -0.46350941813753277], \n",
      " \t task.sim.pose=[-13.62438625  -9.03374668  35.44337599   2.07518427   2.12414336   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  387, total_reward =  171.32, , z=  35.61, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80086666 -0.70776451  9.34168586],\n",
      " \t action=[899.94144111980563, -0.41650068859928563, 899.53094736449327, 0.18139929379922862], \n",
      " \t task.sim.pose=[-13.38033596  -2.38515934  35.60789705   2.08083306   2.07564204   0.        ]\n",
      "Episode =  388, total_reward =  172.39, , z=  35.80, v_z=   9.38, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81587835 -0.83752777  9.37713526],\n",
      " \t action=[899.85372798719277, 0.095369203419716359, 899.90288374604165, 0.12717695785330227], \n",
      " \t task.sim.pose=[-13.52404194  -3.56625501  35.79610786   2.14557346   2.11712049   0.        ]\n",
      "Episode =  389, total_reward =  171.77, , z=  35.65, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76738213 -0.3664684   9.33355853],\n",
      " \t action=[899.80055023079797, 0.076852773738128016, 900.26222999286347, -0.20448280880189024], \n",
      " \t task.sim.pose=[-13.40108381  -0.66075536  35.64525764   2.10612962   2.1149174    0.        ]\n",
      "Episode =  390, total_reward =  172.28, , z=  35.69, v_z=   9.29, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.89650558 -3.92684567  9.28883232],\n",
      " \t action=[899.9249673172817, 0.054956369842966618, 900.03100472734229, -0.65099551635698327], \n",
      " \t task.sim.pose=[-13.82738077 -11.58307846  35.68573631   2.12249025   2.17545542   0.        ]\n",
      "Episode =  391, total_reward =  170.83, , z=  35.27, v_z=   9.13, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74423513  2.86057942  9.12642323],\n",
      " \t action=[900.43474986517344, 0.10358101451167739, 900.27941924114612, -0.19682976831543647], \n",
      " \t task.sim.pose=[-13.26584192   5.85154236  35.27494759   2.10773459   2.0351311    0.        ]\n",
      "Episode =  392, total_reward =  172.22, , z=  35.77, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82519991 -2.13863083  9.35406157],\n",
      " \t action=[900.55216525001538, -0.24977193918568613, 899.99619618244458, 0.11545518727076495], \n",
      " \t task.sim.pose=[-13.51314772  -5.47981814  35.76926507   2.07417092   2.10316597   0.        ]\n",
      "Episode =  393, total_reward =  170.57, , z=  35.30, v_z=   9.20, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87770507 -4.20498667  9.20378333],\n",
      " \t action=[899.87631155391614, -0.21178975044093759, 899.87164286841153, 0.19376625536471179], \n",
      " \t task.sim.pose=[-13.66564636 -11.31134553  35.30251268   2.08486748   2.15289617   0.        ]\n",
      "Episode =  394, total_reward =  172.32, , z=  35.70, v_z=   9.30, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74944508  1.05480834  9.30262976],\n",
      " \t action=[900.91005919937106, 0.24654959043948052, 900.546013664003, 0.24538366779142412], \n",
      " \t task.sim.pose=[-13.41832513   2.61407831  35.7002097    2.13031102   2.10332094   0.        ]\n",
      "Episode =  395, total_reward =  169.45, , z=  35.08, v_z=   9.20, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.70619309  1.45382831  9.1969165 ],\n",
      " \t action=[900.33360030762606, 0.43686036634075753, 899.8932487900671, 0.15439602452479761], \n",
      " \t task.sim.pose=[-13.03582464   4.87269766  35.07856952   2.06415611   2.04563611   0.        ]\n",
      "Episode =  396, total_reward =  171.53, , z=  35.61, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78067316  0.41268771  9.32466714],\n",
      " \t action=[900.17888334897975, 0.30785648013994682, 900.6191723213102, 0.70228076216282254], \n",
      " \t task.sim.pose=[-13.39109791  -0.39179397  35.60769713   2.13468679   2.0914712    0.        ]\n",
      "Episode =  397, total_reward =  171.15, , z=  35.52, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75871333  0.16244978  9.31403114],\n",
      " \t action=[900.62985383716625, 0.06386854632428049, 899.71309988587564, -0.2167903477238024], \n",
      " \t task.sim.pose=[-13.26852651   0.81574362  35.5241603    2.09239753   2.07352767   0.        ]\n",
      "Episode =  398, total_reward =  171.00, , z=  35.53, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80479032 -0.10232369  9.33541244],\n",
      " \t action=[899.39232220542976, 0.13069970129112496, 899.88209061448538, 0.20520658612410936], \n",
      " \t task.sim.pose=[-13.38212159  -1.3430998   35.53473533   2.07892033   2.0582587    0.        ]\n",
      "Episode =  399, total_reward =  170.14, , z=  35.34, v_z=   9.29, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86018396 -2.86991835  9.29308756],\n",
      " \t action=[899.67441491576039, -0.18191062506208153, 900.29678307262429, 0.041856226045621586], \n",
      " \t task.sim.pose=[-13.5060407   -7.89009741  35.33507827   2.03427071   2.08026204   0.        ]\n",
      "Episode =  400, total_reward =  171.30, , z=  35.58, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80618003 -0.29960566  9.33525014],\n",
      " \t action=[899.78303413244373, 0.05672241695441399, 900.15088461949404, 0.80547301549063244], \n",
      " \t task.sim.pose=[-13.47562746  -1.67533877  35.58493135   2.08173243   2.086949     0.        ]\n",
      "Episode =  401, total_reward =  171.30, , z=  35.59, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80677273 -0.78492737  9.34693202],\n",
      " \t action=[899.9765589339936, 0.34181525260652457, 900.23252580497206, -0.32775602485865196], \n",
      " \t task.sim.pose=[-13.4441197   -2.68331599  35.58581777   2.09357263   2.08931785   0.        ]\n",
      "Episode =  402, total_reward =  171.25, , z=  35.54, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77833766  0.3845098   9.31090825],\n",
      " \t action=[899.56163734853499, -0.68838575651762324, 900.93638657916222, -0.78977111202722883], \n",
      " \t task.sim.pose=[-13.41402248   0.40835069  35.53867512   2.1013594    2.09222429   0.        ]\n",
      "Episode =  403, total_reward =  171.19, , z=  35.52, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77639292  0.37856999  9.29721679],\n",
      " \t action=[899.50011703487576, 0.14401914557440909, 900.04830676302026, 0.10250252907972263], \n",
      " \t task.sim.pose=[-13.45613555  -0.3493953   35.51739846   2.14539794   2.12360596   0.        ]\n",
      "Episode =  404, total_reward =  171.59, , z=  35.67, v_z=   9.37, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8901723  -1.11430693  9.36938611],\n",
      " \t action=[899.6681604734282, 0.099263423030374415, 899.1305689797598, 0.26576373281575927], \n",
      " \t task.sim.pose=[-13.74302997  -5.77677347  35.6673025    2.13927202   2.09031391   0.        ]\n",
      "Episode =  405, total_reward =  171.23, , z=  35.56, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79175402 -0.95617025  9.32863558],\n",
      " \t action=[900.45794871456917, 0.17761278287932653, 900.39854603476306, -0.6018650889139191], \n",
      " \t task.sim.pose=[-13.4599919   -2.20393085  35.55666601   2.07963999   2.10911109   0.        ]\n",
      "Episode =  406, total_reward =  171.04, , z=  35.50, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77684542 -1.10997107  9.30521865],\n",
      " \t action=[900.72557926817672, 0.70083915063957292, 900.22788045728532, 0.24989095087814447], \n",
      " \t task.sim.pose=[-13.3813075   -1.6291011   35.50089129   2.06465977   2.10175253   0.        ]\n",
      "Episode =  407, total_reward =  171.21, , z=  35.59, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84813253 -0.77408293  9.36153342],\n",
      " \t action=[900.32279977877045, -0.208432054763521, 899.84665683856451, -0.0030065060509846253], \n",
      " \t task.sim.pose=[-13.53966324  -4.14709055  35.59187852   2.10201787   2.07087566   0.        ]\n",
      "Episode =  408, total_reward =  171.88, , z=  35.68, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79468852 -0.21178137  9.33437707],\n",
      " \t action=[899.99315477330322, 0.37322712420802467, 900.32865927815635, 0.43706816641457918], \n",
      " \t task.sim.pose=[-13.55069489  -1.15446154  35.68112024   2.11919272   2.12259617   0.        ]\n",
      "Episode =  409, total_reward =  170.95, , z=  35.38, v_z=   9.21, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72764165  1.66267581  9.21493282],\n",
      " \t action=[900.1469121811275, -0.10731930630415466, 899.63933214000781, 0.43005612697038609], \n",
      " \t task.sim.pose=[-13.30951737   3.75788604  35.38386668   2.1433181    2.10370953   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  410, total_reward =  172.34, , z=  35.72, v_z=   9.30, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84877716 -3.44091826  9.29994104],\n",
      " \t action=[899.89167537703202, 0.13352656254230161, 900.39864295073767, -0.22344136744901899], \n",
      " \t task.sim.pose=[-13.67799557  -9.04130462  35.72431799   2.10281899   2.16876462   0.        ]\n",
      "Episode =  411, total_reward =  171.53, , z=  35.62, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78732047 -0.99535624  9.34283133],\n",
      " \t action=[900.02927172907903, 0.56197243499406624, 900.2042172345914, -0.096717342911262091], \n",
      " \t task.sim.pose=[-13.37876568  -2.62856366  35.62459086   2.09207999   2.1040703    0.        ]\n",
      "Episode =  412, total_reward =  171.64, , z=  35.65, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80866921 -1.42148423  9.3367124 ],\n",
      " \t action=[899.94632793987114, -0.066829807729233123, 900.16100295632532, 0.43710070609530938], \n",
      " \t task.sim.pose=[-13.51921449  -3.91405484  35.64544657   2.10400793   2.12716521   0.        ]\n",
      "Episode =  413, total_reward =  170.87, , z=  35.51, v_z=   9.35, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7983899  -0.2531941   9.34667303],\n",
      " \t action=[900.08481509817648, -0.325107042869967, 900.03329002259022, -0.087545286778948239], \n",
      " \t task.sim.pose=[-13.3238448   -1.93110421  35.51060871   2.08029423   2.05990541   0.        ]\n",
      "Episode =  414, total_reward =  171.23, , z=  35.54, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88133353 -3.07778352  9.31646742],\n",
      " \t action=[900.32349003461968, 0.025757754023093909, 900.15628751760437, -0.67149305891442557], \n",
      " \t task.sim.pose=[-13.62910122  -8.38611931  35.53663049   2.05310192   2.08723551   0.        ]\n",
      "Episode =  415, total_reward =  171.92, , z=  35.70, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79797144 -1.03313039  9.35244243],\n",
      " \t action=[899.74772471079928, 0.46931897831082092, 900.41133177713084, 0.40657929515379648], \n",
      " \t task.sim.pose=[-13.49846433  -3.71342823  35.70135494   2.12928928   2.1352654    0.        ]\n",
      "Episode =  416, total_reward =  171.16, , z=  35.55, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81197103 -0.91843909  9.34199235],\n",
      " \t action=[899.86861691064394, 0.10856735423403246, 900.58874686104446, 0.29619182498630425], \n",
      " \t task.sim.pose=[-13.50156394  -3.29658015  35.55237704   2.10074345   2.10723172   0.        ]\n",
      "Episode =  417, total_reward =  171.33, , z=  35.56, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78692208  1.21367785  9.28430578],\n",
      " \t action=[900.26725300970509, -0.0041020565099558204, 900.21865959094328, 0.2153497090646373], \n",
      " \t task.sim.pose=[-13.3343435    1.5986877   35.55555699   2.10521566   2.03959711   0.        ]\n",
      "Episode =  418, total_reward =  169.46, , z=  35.05, v_z=   9.17, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.93281606 -4.8253312   9.16725225],\n",
      " \t action=[900.06572206366332, -0.14586879485437204, 900.0286946897171, 0.50956454086670655], \n",
      " \t task.sim.pose=[-13.72584873 -13.41834556  35.05286686   2.03629786   2.10205453   0.        ]\n",
      "Episode =  419, total_reward =  172.40, , z=  35.79, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79157123 -1.42885189  9.35238839],\n",
      " \t action=[899.88339355341816, -0.54898023738289781, 899.87475434762405, 0.36457473947243113], \n",
      " \t task.sim.pose=[-13.52050317  -3.32743705  35.79156058   2.1078049    2.14137084   0.        ]\n",
      "Episode =  420, total_reward =  172.64, , z=  35.82, v_z=   9.35, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76021961 -0.33691     9.34822006],\n",
      " \t action=[899.37643186549712, -0.33707033241664286, 900.04782665956577, -0.095665860813549178], \n",
      " \t task.sim.pose=[-13.42854305  -1.32727405  35.82244977   2.14434525   2.14743379   0.        ]\n",
      "Episode =  421, total_reward =  171.19, , z=  35.57, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86593173 -1.91382667  9.3511744 ],\n",
      " \t action=[899.32627734432742, -0.34478139220873455, 899.60181409108236, 0.31254502597627576], \n",
      " \t task.sim.pose=[-13.61969705  -6.75543804  35.57032543   2.09644058   2.10292297   0.        ]\n",
      "Episode =  422, total_reward =  171.22, , z=  35.51, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88143711 -3.49503568  9.28459841],\n",
      " \t action=[899.74946067520523, 0.40181366969756527, 900.1782229610202, 0.082035343556131124], \n",
      " \t task.sim.pose=[-13.67094421  -9.29743316  35.5056024    2.05924374   2.1156517    0.        ]\n",
      "Episode =  423, total_reward =  172.15, , z=  35.73, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79611318  0.5237638   9.32683264],\n",
      " \t action=[899.62183021262422, 0.49468529972436115, 899.95774882731337, -0.23300784568201754], \n",
      " \t task.sim.pose=[-13.53379843  -0.52976676  35.72931161   2.13776371   2.10668141   0.        ]\n",
      "Episode =  424, total_reward =  171.24, , z=  35.58, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81694364 -1.03105421  9.35100823],\n",
      " \t action=[899.27878678136221, -0.26270396530950463, 899.9412893048177, 0.61935336385487383], \n",
      " \t task.sim.pose=[-13.49063378  -4.29794185  35.57834671   2.12409226   2.11482702   0.        ]\n",
      "Episode =  425, total_reward =  170.93, , z=  35.49, v_z=   9.32, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81094156  0.43140423  9.31923892],\n",
      " \t action=[900.49689873446948, 0.42464362449745308, 899.80301338264439, 0.64837844206615136], \n",
      " \t task.sim.pose=[-13.42961464  -0.12545644  35.49187237   2.08828182   2.04573495   0.        ]\n",
      "Episode =  426, total_reward =  171.54, , z=  35.64, v_z=   9.37, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83189052 -1.12474578  9.36908145],\n",
      " \t action=[900.48074050338653, -0.60464992843151555, 900.38650199737754, 0.067673676969758012], \n",
      " \t task.sim.pose=[-13.54338465  -4.49698207  35.64491254   2.1095986    2.1028385    0.        ]\n",
      "Episode =  427, total_reward =  171.92, , z=  35.64, v_z=   9.29, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75142043  0.9862179   9.29327144],\n",
      " \t action=[900.10436108873239, -0.24133818206669275, 899.70580743865241, 0.11179289270947351], \n",
      " \t task.sim.pose=[-13.34556776   1.51031984  35.63846628   2.13016162   2.09964902   0.        ]\n",
      "Episode =  428, total_reward =  171.52, , z=  35.62, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81769647 -1.86923579  9.33086791],\n",
      " \t action=[899.91595318681289, -0.40168181193578001, 899.61487066021425, -0.031187805461415974], \n",
      " \t task.sim.pose=[-13.48304054  -4.19752484  35.61597865   2.06344273   2.09796754   0.        ]\n",
      "Episode =  429, total_reward =  171.67, , z=  35.65, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79868149  0.41400953  9.33300941],\n",
      " \t action=[899.14945599631506, -0.56568919759264691, 899.60764463034707, 0.48634704509229665], \n",
      " \t task.sim.pose=[-13.42262621  -0.51236999  35.65379031   2.10922103   2.07316095   0.        ]\n",
      "Episode =  430, total_reward =  170.95, , z=  35.46, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76124677  0.39826411  9.29609419],\n",
      " \t action=[900.16289605803547, -0.3155446710035188, 900.23715841080309, 0.66479859014045051], \n",
      " \t task.sim.pose=[-13.31376092   1.54791599  35.46251766   2.08796156   2.07529776   0.        ]\n",
      "Episode =  431, total_reward =  172.13, , z=  35.73, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80679347 -1.33740055  9.35182348],\n",
      " \t action=[900.34172116701711, 0.11626642360964629, 900.94229632319878, 0.58780809022752922], \n",
      " \t task.sim.pose=[-13.55766219  -3.57376527  35.73083245   2.10487686   2.13393451   0.        ]\n",
      "Episode =  432, total_reward =  172.22, , z=  35.78, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8405449  -2.06507308  9.35918962],\n",
      " \t action=[899.95456603097284, 0.015237189312768018, 899.64383406932382, -0.3288575150442774], \n",
      " \t task.sim.pose=[-13.63205949  -5.87724693  35.77795842   2.08577718   2.12564747   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  433, total_reward =  171.32, , z=  35.57, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79430564 -1.07340573  9.33148751],\n",
      " \t action=[899.91524205974952, 0.47549866317462547, 900.39551993862415, 0.078785040385393912], \n",
      " \t task.sim.pose=[-13.44551705  -2.59523265  35.57400301   2.08528867   2.10489574   0.        ]\n",
      "Episode =  434, total_reward =  171.19, , z=  35.56, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82116081 -0.36424586  9.3320932 ],\n",
      " \t action=[900.81669542817531, -0.32932914759038134, 900.16517715324676, -0.36079655395075505], \n",
      " \t task.sim.pose=[-13.55946717  -2.00122406  35.55641855   2.10474286   2.09440036   0.        ]\n",
      "Episode =  435, total_reward =  170.82, , z=  35.33, v_z=   9.18, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.90617423 -4.73597808  9.17913548],\n",
      " \t action=[900.05092431565299, -0.11759623700497462, 900.15417799827605, -0.7391230184566725], \n",
      " \t task.sim.pose=[-13.7179815  -12.36519882  35.33338165   2.04788506   2.12170753   0.        ]\n",
      "Episode =  436, total_reward =  171.73, , z=  35.68, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79043113 -0.87086587  9.34906616],\n",
      " \t action=[899.97757160343315, 0.66454432346195003, 899.90184474605519, -0.20996313959082127], \n",
      " \t task.sim.pose=[-13.42421851  -2.2173441   35.68070188   2.0705523    2.09746738   0.        ]\n",
      "Episode =  437, total_reward =  172.17, , z=  35.72, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8112812  -2.25244595  9.32509007],\n",
      " \t action=[899.75574259713346, -0.46643976724891273, 900.41457899429577, 1.0685041266537438], \n",
      " \t task.sim.pose=[-13.57760493  -5.55822264  35.72138969   2.10650309   2.15773248   0.        ]\n",
      "Episode =  438, total_reward =  170.61, , z=  35.37, v_z=   9.26, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75789372  0.88055024  9.25855266],\n",
      " \t action=[900.65916717945822, -0.24674720554896551, 899.53683777531023, -0.58401441536485021], \n",
      " \t task.sim.pose=[-13.30416859   2.02747149  35.37098028   2.08344957   2.06936072   0.        ]\n",
      "Episode =  439, total_reward =  171.10, , z=  35.52, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78467383 -1.31511602  9.31487053],\n",
      " \t action=[900.27481400567819, -0.63805751428919644, 899.45958024709341, -0.24443724876331252], \n",
      " \t task.sim.pose=[-13.41015126  -3.15936432  35.51714609   2.11189579   2.12192059   0.        ]\n",
      "Episode =  440, total_reward =  171.82, , z=  35.68, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81976687 -2.04645016  9.34216246],\n",
      " \t action=[899.62278461324718, 0.14229666524482967, 900.12490442565615, 0.17211652989776249], \n",
      " \t task.sim.pose=[-13.52529017  -5.58055776  35.68363477   2.08831873   2.12416704   0.        ]\n",
      "Episode =  441, total_reward =  170.29, , z=  35.27, v_z=   9.20, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.752017    1.97316486  9.19735427],\n",
      " \t action=[899.77474106937393, 0.4703018657446727, 899.83795357829808, 0.40009000531890293], \n",
      " \t task.sim.pose=[-13.17368033   3.49605869  35.26816511   2.11121205   2.02973013   0.        ]\n",
      "Episode =  442, total_reward =  171.26, , z=  35.60, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81729636 -1.34395076  9.35062259],\n",
      " \t action=[900.24251858541447, -0.066651508853668773, 899.54835933140032, 0.21973238811095808], \n",
      " \t task.sim.pose=[-13.43585816  -4.32026135  35.59781118   2.07514647   2.08621402   0.        ]\n",
      "Episode =  443, total_reward =  171.23, , z=  35.52, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7463907   0.23336357  9.30365169],\n",
      " \t action=[900.27785066659044, -0.32729518661896273, 900.02225306099206, 0.2435928004462857], \n",
      " \t task.sim.pose=[-13.28056407   0.45573296  35.52214671   2.12757082   2.10345387   0.        ]\n",
      "Episode =  444, total_reward =  170.97, , z=  35.37, v_z=   9.19, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85245057 -4.30025651  9.1929089 ],\n",
      " \t action=[900.95427163434567, -0.21524103240020878, 899.85032204348806, -0.0098346525476981639], \n",
      " \t task.sim.pose=[-13.57347119 -10.76535361  35.37277883   2.07722548   2.15182347   0.        ]\n",
      "Episode =  445, total_reward =  171.45, , z=  35.62, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84203367 -0.73549663  9.34967916],\n",
      " \t action=[900.62708122984918, -0.071808439250421852, 899.37371623236277, -0.51203453005892763], \n",
      " \t task.sim.pose=[-13.6021334   -3.35691348  35.62428131   2.11317207   2.0863159    0.        ]\n",
      "Episode =  446, total_reward =  172.33, , z=  35.80, v_z=   9.38, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8211067  -1.10700189  9.37806386],\n",
      " \t action=[900.1408248676405, 0.14991397670947326, 900.49142352358388, 0.18580635718997854], \n",
      " \t task.sim.pose=[-13.5681164   -4.17978537  35.79636508   2.13320179   2.12194623   0.        ]\n",
      "Episode =  447, total_reward =  170.53, , z=  35.31, v_z=   9.21, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72766366  1.25780675  9.21257062],\n",
      " \t action=[899.2369470400281, -0.29539733986213085, 899.61491852622726, -0.11706945666409806], \n",
      " \t task.sim.pose=[-13.31969811   2.97741279  35.30736132   2.13893363   2.121358     0.        ]\n",
      "Episode =  448, total_reward =  171.84, , z=  35.67, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79569724  0.27942698  9.34044912],\n",
      " \t action=[899.95592318533693, -0.064621820496096771, 899.54921009233021, 0.54634074238119967], \n",
      " \t task.sim.pose=[-13.46798434   0.1121082   35.67310012   2.11463344   2.07968442   0.        ]\n",
      "Episode =  449, total_reward =  171.68, , z=  35.62, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79037798  0.89304339  9.31423982],\n",
      " \t action=[900.60729624159467, -0.12670834309015022, 900.0403255960116, 0.4225833418370421], \n",
      " \t task.sim.pose=[-13.40083402   0.25202058  35.62326714   2.12917649   2.07042015   0.        ]\n",
      "Episode =  450, total_reward =  172.13, , z=  35.69, v_z=   9.31, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75120433  0.7379335   9.31429219],\n",
      " \t action=[899.89741985375542, -0.022196237726979151, 900.53749067243518, 0.053022449542102279], \n",
      " \t task.sim.pose=[-13.39634297   1.15880456  35.69464907   2.13767948   2.1228869    0.        ]\n",
      "Episode =  451, total_reward =  170.62, , z=  35.46, v_z=   9.34, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84770274 -1.59235235  9.33683846],\n",
      " \t action=[900.13815258282386, -0.43865272151395007, 899.61920077693162, -0.33106367495520028], \n",
      " \t task.sim.pose=[-13.54296455  -5.53722526  35.46150412   2.08649336   2.09011624   0.        ]\n",
      "Episode =  452, total_reward =  171.79, , z=  35.61, v_z=   9.26, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85101246 -3.48874481  9.26430555],\n",
      " \t action=[900.78574133822451, -0.57972806836482904, 899.91855412896234, -0.66092600392025547], \n",
      " \t task.sim.pose=[-13.6772035   -8.99958898  35.6068872    2.100448     2.16362208   0.        ]\n",
      "Episode =  453, total_reward =  171.56, , z=  35.52, v_z=   9.25, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73049499  1.52331     9.24667435],\n",
      " \t action=[899.93225362109933, 0.34453203693162038, 899.47816259173067, -0.12136789807288592], \n",
      " \t task.sim.pose=[-13.30321411   3.30501997  35.52232238   2.1388659    2.10138236   0.        ]\n",
      "Episode =  454, total_reward =  172.45, , z=  35.80, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78328989 -1.59441745  9.34662977],\n",
      " \t action=[900.22736409769664, -0.21691984586237467, 899.75533794544936, 0.3047242403024924], \n",
      " \t task.sim.pose=[-13.46211943  -3.5100053   35.79896423   2.09970442   2.14255278   0.        ]\n",
      "Episode =  455, total_reward =  171.40, , z=  35.61, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83606478 -0.33013688  9.34940811],\n",
      " \t action=[899.77914021089771, 0.13716974297513224, 899.54421488971502, -0.57994375352963123], \n",
      " \t task.sim.pose=[-13.59852036  -2.92055264  35.61442697   2.11248243   2.09174253   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  456, total_reward =  170.74, , z=  35.40, v_z=   9.28, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74194075  0.1938132   9.28064447],\n",
      " \t action=[900.38319064125005, 0.24686287380529112, 900.29117068917117, 0.31734704293510468], \n",
      " \t task.sim.pose=[-13.30942051   1.25218036  35.40028519   2.10759522   2.11414127   0.        ]\n",
      "Episode =  457, total_reward =  171.43, , z=  35.50, v_z=   9.25, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73004823  1.62127493  9.24680864],\n",
      " \t action=[899.64639561400065, -0.28908139363510438, 899.7578983460819, 0.21024110873452759], \n",
      " \t task.sim.pose=[-13.23935446   3.68504071  35.49957103   2.1247459    2.08040011   0.        ]\n",
      "Episode =  458, total_reward =  170.38, , z=  35.26, v_z=   9.22, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.69540334  1.31840563  9.21558816],\n",
      " \t action=[899.75904229484775, -0.26818436638359611, 900.3180396421335, -0.23514031074848091], \n",
      " \t task.sim.pose=[-13.15165319   4.89887075  35.25674781   2.10341405   2.0963952    0.        ]\n",
      "Episode =  459, total_reward =  170.86, , z=  35.47, v_z=   9.30, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76522808  0.19829581  9.30193118],\n",
      " \t action=[900.17750378245069, -0.52665000150920827, 900.11761014543208, -0.17779689215411978], \n",
      " \t task.sim.pose=[-13.32623066  -0.38708675  35.4655262    2.11673814   2.10038663   0.        ]\n",
      "Episode =  460, total_reward =  168.63, , z=  34.66, v_z=   8.96, \n",
      " \t score = 2.01 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.61683971  3.60828279  8.9627391 ],\n",
      " \t action=[900.0428251760801, -0.34822182669654134, 899.69431086294992, -0.37279006877161375], \n",
      " \t task.sim.pose=[-12.91877765  10.24808234  34.65606179   2.17042759   2.10394696   0.        ]\n",
      "Episode =  461, total_reward =  172.88, , z=  35.90, v_z=   9.37, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79611397 -1.0063445   9.37064401],\n",
      " \t action=[900.18242395011384, 0.005966085882054023, 900.06133407697098, 0.089838580069711654], \n",
      " \t task.sim.pose=[-13.5750606   -2.58151283  35.89762032   2.1099133    2.13872577   0.        ]\n",
      "Episode =  462, total_reward =  171.29, , z=  35.60, v_z=   9.37, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88843237 -2.00613137  9.37217825],\n",
      " \t action=[899.51471589549033, 0.18834739812992629, 898.95251341448466, 0.47986192135263883], \n",
      " \t task.sim.pose=[-13.60898269  -7.03967089  35.59905378   2.08439017   2.06064898   0.        ]\n",
      "Episode =  463, total_reward =  171.11, , z=  35.52, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79676387 -0.07309     9.32539883],\n",
      " \t action=[900.0537948634942, -0.18433093554993804, 900.27755670583656, 0.27709143328045011], \n",
      " \t task.sim.pose=[-13.48535595  -0.91994922  35.52063917   2.10035023   2.09573589   0.        ]\n",
      "Episode =  464, total_reward =  170.41, , z=  35.26, v_z=   9.19, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75022433  2.22583533  9.18804783],\n",
      " \t action=[900.11204582773007, -0.37878246147566225, 900.40124822438565, 0.086388528156275179], \n",
      " \t task.sim.pose=[-13.24678789   4.47722702  35.26408312   2.09943583   2.03825649   0.        ]\n",
      "Episode =  465, total_reward =  171.18, , z=  35.50, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77423065  0.75508159  9.28741057],\n",
      " \t action=[900.48733174333756, -0.11470335005748422, 899.96395225987476, 0.12320568038298994], \n",
      " \t task.sim.pose=[-13.42165204   0.77325883  35.49816916   2.1445566    2.09923316   0.        ]\n",
      "Episode =  466, total_reward =  171.04, , z=  35.50, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7683596  -0.16591961  9.30637375],\n",
      " \t action=[900.16554869819231, 0.35061018859294302, 899.81510555316595, 0.32653861560056557], \n",
      " \t task.sim.pose=[-13.33721035  -0.9765696   35.50447308   2.12639663   2.10636702   0.        ]\n",
      "Episode =  467, total_reward =  171.91, , z=  35.70, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81789529 -1.9984018   9.34915805],\n",
      " \t action=[900.49791276961605, 0.12734957778773107, 900.37848809043624, -0.036326249082816564], \n",
      " \t task.sim.pose=[-13.45934923  -4.89434718  35.69925404   2.07303883   2.09742579   0.        ]\n",
      "Episode =  468, total_reward =  170.53, , z=  35.31, v_z=   9.24, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72963006  0.96719535  9.23759167],\n",
      " \t action=[899.92605847446612, -0.36140873733329515, 899.74859004238544, -0.35413015509156592], \n",
      " \t task.sim.pose=[-13.28843288   3.6396738   35.31406955   2.0874852    2.09256142   0.        ]\n",
      "Episode =  469, total_reward =  171.10, , z=  35.52, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78948873 -1.08474492  9.31548071],\n",
      " \t action=[899.78946436648698, 0.058642104052660016, 900.2144002128548, 0.15131313356140191], \n",
      " \t task.sim.pose=[-13.42268547  -2.05432947  35.51810034   2.06674159   2.1000585    0.        ]\n",
      "Episode =  470, total_reward =  171.95, , z=  35.73, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81507418  0.04492806  9.36053462],\n",
      " \t action=[900.37184394190479, -0.41014197147989057, 899.55589042288568, -0.259107149289028], \n",
      " \t task.sim.pose=[-13.46073545  -0.89163619  35.73010841   2.09509346   2.05753502   0.        ]\n",
      "Episode =  471, total_reward =  171.89, , z=  35.66, v_z=   9.29, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78307705  1.11550471  9.29437721],\n",
      " \t action=[899.79995532354894, -0.15185258050641934, 899.9951579461374, 0.1841440875314056], \n",
      " \t task.sim.pose=[-13.40470508   1.05449274  35.65570711   2.13887909   2.07532797   0.        ]\n",
      "Episode =  472, total_reward =  170.90, , z=  35.30, v_z=   9.12, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.90135628 -5.13744457  9.12364291],\n",
      " \t action=[900.66943986888839, 0.21325605939586262, 900.66362740382465, 0.3701831892235582], \n",
      " \t task.sim.pose=[-13.74980191 -12.70438287  35.29843158   2.04944392   2.1410378    0.        ]\n",
      "Episode =  473, total_reward =  170.56, , z=  35.30, v_z=   9.21, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72089162  1.72860129  9.2128513 ],\n",
      " \t action=[900.24555503943361, 1.0742347624355384, 899.97554475172524, 0.28790389444164816], \n",
      " \t task.sim.pose=[-13.18191128   4.67669134  35.29751323   2.10356151   2.06708809   0.        ]\n",
      "Episode =  474, total_reward =  170.80, , z=  35.39, v_z=   9.27, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86719838 -3.48784192  9.26634193],\n",
      " \t action=[900.52187805519395, -0.084282502842511153, 899.09528604189279, 0.71929964938286273], \n",
      " \t task.sim.pose=[-13.61726853  -9.9276757   35.39442511   2.10774849   2.14281424   0.        ]\n",
      "Episode =  475, total_reward =  170.65, , z=  35.42, v_z=   9.30, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.89588475 -3.27473764  9.30197561],\n",
      " \t action=[899.98090159745766, -0.33545034349143277, 899.55671770650815, -0.85899221701870854], \n",
      " \t task.sim.pose=[-13.63109404  -9.89346574  35.41681624   2.06879319   2.09502878   0.        ]\n",
      "Episode =  476, total_reward =  171.70, , z=  35.67, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80263559 -0.12340489  9.34670531],\n",
      " \t action=[899.99760058613219, -0.05687636571970088, 899.73278486288427, 0.24635482594345834], \n",
      " \t task.sim.pose=[-13.40833993  -0.42064358  35.66981366   2.06443864   2.05295094   0.        ]\n",
      "Episode =  477, total_reward =  169.80, , z=  35.15, v_z=   9.19, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88124548 -4.25373591  9.19349514],\n",
      " \t action=[900.14178812140801, 0.029465894560700506, 900.25478549418858, -0.13220955135797591], \n",
      " \t task.sim.pose=[-13.61658913 -11.123652    35.15125402   2.05660326   2.12785486   0.        ]\n",
      "Episode =  478, total_reward =  171.20, , z=  35.51, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85933927 -3.34182098  9.28091338],\n",
      " \t action=[900.48330407454489, -0.17200287278100498, 900.26543791449558, 0.18397385570733954], \n",
      " \t task.sim.pose=[-13.58294191  -8.76295572  35.50521256   2.06967476   2.11553847   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  479, total_reward =  171.63, , z=  35.67, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8105679  -0.88487872  9.3483099 ],\n",
      " \t action=[899.24684425894964, -0.027994056436473569, 899.84237676690998, -0.18116947315665735], \n",
      " \t task.sim.pose=[-13.5125754   -2.79528052  35.66818971   2.073591     2.10361037   0.        ]\n",
      "Episode =  480, total_reward =  170.88, , z=  35.25, v_z=   9.09, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.71467088  3.05279249  9.08925673],\n",
      " \t action=[899.93918734447141, 0.60444959637341311, 899.6193352955778, -0.081670994614446407], \n",
      " \t task.sim.pose=[-13.26068039   6.22460208  35.24517635   2.15312211   2.07945148   0.        ]\n",
      "Episode =  481, total_reward =  171.82, , z=  35.71, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81813809 -0.69495506  9.3655177 ],\n",
      " \t action=[899.83029489338674, -0.15893468662311722, 899.9159836618079, 0.20999697383790489], \n",
      " \t task.sim.pose=[-13.47995841  -2.93515053  35.71285292   2.09008534   2.08477709   0.        ]\n",
      "Episode =  482, total_reward =  172.23, , z=  35.75, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7887822  -0.51729237  9.34156221],\n",
      " \t action=[899.8872609677253, -0.19054537447669176, 900.22703008085614, -0.33197216097092141], \n",
      " \t task.sim.pose=[-13.55650782  -2.04925176  35.75119087   2.15055627   2.14989896   0.        ]\n",
      "Episode =  483, total_reward =  169.58, , z=  34.86, v_z=   8.95, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.66881847  3.99756658  8.95425596],\n",
      " \t action=[900.48795706145916, 0.098764027727780368, 900.03948589887682, -0.85204795734952232], \n",
      " \t task.sim.pose=[-13.03124407   9.64377248  34.8584389    2.15302881   2.04980839   0.        ]\n",
      "Episode =  484, total_reward =  171.17, , z=  35.55, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79535198 -0.41706915  9.33243872],\n",
      " \t action=[900.98460012107489, -0.36474767195726671, 899.58694941738872, 0.11159767590648124], \n",
      " \t task.sim.pose=[-13.40901314  -1.29410636  35.55071716   2.09462706   2.0817158    0.        ]\n",
      "Episode =  485, total_reward =  170.62, , z=  35.47, v_z=   9.34, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85710145 -0.97957224  9.34121974],\n",
      " \t action=[899.69987600592174, 0.10047907163654053, 899.67656031179035, -0.0048572434833642208], \n",
      " \t task.sim.pose=[-13.5507794   -4.57135542  35.47107734   2.09020437   2.06930811   0.        ]\n",
      "Episode =  486, total_reward =  171.70, , z=  35.66, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88373799 -2.67836293  9.35329234],\n",
      " \t action=[900.04990250310561, 0.18100454518656783, 899.86152895432406, -0.15220484947165486], \n",
      " \t task.sim.pose=[-13.70847571  -8.37697629  35.66140632   2.08922249   2.1111662    0.        ]\n",
      "Episode =  487, total_reward =  170.66, , z=  35.45, v_z=   9.33, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8007275  -0.45616623  9.32765248],\n",
      " \t action=[900.65789651358568, -0.59705547430653771, 899.59643727762, 0.12129496361784393], \n",
      " \t task.sim.pose=[-13.3936837   -1.84710258  35.45151574   2.08769006   2.07641498   0.        ]\n",
      "Episode =  488, total_reward =  170.38, , z=  35.33, v_z=   9.27, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74421979  0.65357021  9.2718455 ],\n",
      " \t action=[900.16919269974312, 0.12419917992961423, 900.71087586669194, 0.47082803201371404], \n",
      " \t task.sim.pose=[-13.18733441   2.49445269  35.33099253   2.0681551    2.0549834    0.        ]\n",
      "Episode =  489, total_reward =  170.36, , z=  35.37, v_z=   9.30, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86432367 -2.86430037  9.30244028],\n",
      " \t action=[899.86649595776839, 0.17798355679443881, 899.96746528567667, -0.31456616528494152], \n",
      " \t task.sim.pose=[-13.47766407  -7.77958336  35.36579964   2.04588947   2.06640831   0.        ]\n",
      "Episode =  490, total_reward =  170.59, , z=  35.34, v_z=   9.19, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85543023 -4.18570792  9.19082787],\n",
      " \t action=[900.48103524754015, 0.17618586815017556, 900.67003114068712, -0.36368210646134647], \n",
      " \t task.sim.pose=[-13.59367546 -10.42421911  35.33594498   2.04694443   2.14164491   0.        ]\n",
      "Episode =  491, total_reward =  170.31, , z=  35.35, v_z=   9.26, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82662484 -2.71970488  9.26291813],\n",
      " \t action=[899.61877018023802, 0.016518150723779955, 900.35974470578628, 0.160370958725914], \n",
      " \t task.sim.pose=[-13.51620309  -7.0415379   35.3471835    2.07267062   2.13483765   0.        ]\n",
      "Episode =  492, total_reward =  170.49, , z=  35.15, v_z=   9.07, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.69387208  3.14320247  9.07436498],\n",
      " \t action=[899.42512488066041, 0.053812934053194095, 899.795937976152, 0.057670770850013764], \n",
      " \t task.sim.pose=[-13.19712418   7.31998272  35.14858756   2.16373148   2.08638541   0.        ]\n",
      "Episode =  493, total_reward =  170.97, , z=  35.47, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87311655 -3.25873856  9.29134148],\n",
      " \t action=[900.64062193625068, 0.92856563493353794, 900.5194663676748, 0.0092446041577090715], \n",
      " \t task.sim.pose=[-13.62955351  -8.91332506  35.47116092   2.06840306   2.1127754    0.        ]\n",
      "Episode =  494, total_reward =  171.34, , z=  35.41, v_z=   9.19, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.70087473  2.08833827  9.19442748],\n",
      " \t action=[899.86884924042545, 0.18156441174236387, 900.37714477726172, 0.052665069637071821], \n",
      " \t task.sim.pose=[-13.26918176   5.06299809  35.40897563   2.15849424   2.1226058    0.        ]\n",
      "Episode =  495, total_reward =  170.49, , z=  35.17, v_z=   9.10, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7002082   2.9568321   9.10018492],\n",
      " \t action=[900.7939873967797, 0.14776954234797107, 900.05355473114855, -0.60020954290025541], \n",
      " \t task.sim.pose=[-13.18006942   7.09879205  35.17202881   2.16954383   2.07517417   0.        ]\n",
      "Episode =  496, total_reward =  170.94, , z=  35.33, v_z=   9.17, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8863374  -4.76021494  9.16746739],\n",
      " \t action=[900.07607658887503, 0.19242637775680499, 899.75055041591406, 0.036940879536058069], \n",
      " \t task.sim.pose=[-13.72651729 -12.61842065  35.32916158   2.09881622   2.17064891   0.        ]\n",
      "Episode =  497, total_reward =  172.19, , z=  35.75, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8288087  -1.83398661  9.35524334],\n",
      " \t action=[900.1455489544951, -0.14764651469033557, 900.11657482414341, -0.0015936338131630548], \n",
      " \t task.sim.pose=[-13.63612207  -5.33587918  35.74959118   2.1284168    2.14587101   0.        ]\n",
      "Episode =  498, total_reward =  171.09, , z=  35.36, v_z=   9.18, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.70428465  2.32921726  9.18484962],\n",
      " \t action=[900.87557527561148, 0.20426269827214372, 899.53276555876482, 0.038158664628927405], \n",
      " \t task.sim.pose=[-13.13927895   5.45011167  35.36475353   2.130559     2.06643391   0.        ]\n",
      "Episode =  499, total_reward =  171.66, , z=  35.65, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78066586 -1.22051815  9.33707223],\n",
      " \t action=[900.48853314047278, 0.035742966151551869, 900.59564118512696, 0.093507569055958306], \n",
      " \t task.sim.pose=[-13.35133424  -2.3305799   35.65067275   2.05947326   2.09365817   0.        ]\n",
      "Episode =  500, total_reward =  172.52, , z=  35.79, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77925066  0.84012994  9.331226  ],\n",
      " \t action=[899.58802495101497, -0.6409276376746601, 900.21699700391866, -0.2126189993210969], \n",
      " \t task.sim.pose=[ -1.34594617e+01  -2.12391285e-03   3.57948547e+01   2.15990923e+00\n",
      "   2.10635013e+00   0.00000000e+00]\n",
      "Episode =  501, total_reward =  172.22, , z=  35.78, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81422661 -0.9915467   9.37410086],\n",
      " \t action=[900.10558442171464, -0.68386328094240389, 899.3260645497877, 0.22112257044896122], \n",
      " \t task.sim.pose=[-13.52401616  -3.94495701  35.77500671   2.13925527   2.1208424    0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  502, total_reward =  171.24, , z=  35.56, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.92720514 -2.54347     9.36313026],\n",
      " \t action=[900.64016321118436, -0.11050041379408954, 899.59782554072626, -0.20685637445701982], \n",
      " \t task.sim.pose=[-13.78331672  -8.78419154  35.55532973   2.09864107   2.07695876   0.        ]\n",
      "Episode =  503, total_reward =  171.08, , z=  35.51, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77526235 -1.17494211  9.30075059],\n",
      " \t action=[900.04586008460331, 0.21427595944407879, 900.03312623552256, -0.38424827236711079], \n",
      " \t task.sim.pose=[-13.37570654  -1.99452239  35.51315428   2.07256598   2.11137464   0.        ]\n",
      "Episode =  504, total_reward =  171.80, , z=  35.64, v_z=   9.32, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87096942 -3.23520923  9.31692297],\n",
      " \t action=[899.95365135167742, -0.27795334313197251, 900.25270291424147, 0.15972025460318365], \n",
      " \t task.sim.pose=[-13.66815235  -8.86044974  35.63788583   2.07755249   2.12598613   0.        ]\n",
      "Episode =  505, total_reward =  171.27, , z=  35.60, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84102319 -0.34851314  9.35379954],\n",
      " \t action=[899.68053748076227, 0.6992874815139738, 900.22234014376318, -0.40848860134034665], \n",
      " \t task.sim.pose=[-13.50532288  -2.76347506  35.60424328   2.08563545   2.052899     0.        ]\n",
      "Episode =  506, total_reward =  171.79, , z=  35.63, v_z=   9.30, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8550072  -3.11438786  9.30422921],\n",
      " \t action=[899.98078452616903, 0.50834347406389835, 900.38517966302175, -0.045371600837955328], \n",
      " \t task.sim.pose=[-13.65790437  -8.56521315  35.63104433   2.10161992   2.14543484   0.        ]\n",
      "Episode =  507, total_reward =  172.77, , z=  35.83, v_z=   9.33, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85646429 -3.05082104  9.32552558],\n",
      " \t action=[900.14799870050069, 0.0090135623068263726, 899.83747948998325, -0.16562171280465493], \n",
      " \t task.sim.pose=[-13.75665033  -8.40563244  35.82636387   2.13024417   2.17539017   0.        ]\n",
      "Episode =  508, total_reward =  171.59, , z=  35.62, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78232763  0.65942897  9.32488573],\n",
      " \t action=[900.58917646868304, -0.87971555225983256, 900.26866814789605, -0.5363933397214562], \n",
      " \t task.sim.pose=[-13.36357434   0.4089828   35.61889125   2.0955111    2.06619527   0.        ]\n",
      "Episode =  509, total_reward =  171.73, , z=  35.64, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76537004 -0.22974932  9.33121761],\n",
      " \t action=[899.96017449961619, -0.29390734467901214, 899.58971026660345, 0.75168136388009521], \n",
      " \t task.sim.pose=[-13.36003203  -1.45174233  35.64237421   2.14437901   2.12307516   0.        ]\n",
      "Episode =  510, total_reward =  170.17, , z=  35.24, v_z=   9.21, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74289171  1.43846493  9.21456998],\n",
      " \t action=[900.09315395366298, 0.2070962933872626, 899.58882796632679, 0.039061089608896565], \n",
      " \t task.sim.pose=[-13.23153547   3.85248788  35.24414043   2.09063121   2.05817385   0.        ]\n",
      "Episode =  511, total_reward =  171.03, , z=  35.44, v_z=   9.24, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76603682  1.60565113  9.24335537],\n",
      " \t action=[899.83241375748719, -0.45102324013506845, 899.93055840851071, -0.20183475336095968], \n",
      " \t task.sim.pose=[-13.36916499   2.68647343  35.44093429   2.13253626   2.07106906   0.        ]\n",
      "Episode =  512, total_reward =  172.05, , z=  35.72, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81110849 -1.10136874  9.35843033],\n",
      " \t action=[900.51338718867839, -0.2368007056450625, 899.91751436890661, -0.33775345573817372], \n",
      " \t task.sim.pose=[-13.58455119  -4.0403171   35.72052296   2.15354819   2.14851804   0.        ]\n",
      "Episode =  513, total_reward =  170.98, , z=  35.51, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76771496 -0.27907326  9.32322125],\n",
      " \t action=[899.96967793598571, -0.65186311229414451, 900.60539101442566, 0.86403691045252895], \n",
      " \t task.sim.pose=[-13.24563069  -0.16027535  35.50871108   2.05256062   2.06191082   0.        ]\n",
      "Episode =  514, total_reward =  171.00, , z=  35.50, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79243577 -0.63745386  9.3323768 ],\n",
      " \t action=[900.44301841127196, -0.3362266152944548, 899.85236759993688, -0.22059898078960383], \n",
      " \t task.sim.pose=[-13.37985958  -1.72955674  35.50350584   2.10268715   2.08592173   0.        ]\n",
      "Episode =  515, total_reward =  171.53, , z=  35.58, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76164714  0.841457    9.29668373],\n",
      " \t action=[899.98906138313055, -0.055074290484449465, 900.34150445487342, -0.68064328742168345], \n",
      " \t task.sim.pose=[-13.32818753   1.69762739  35.57879981   2.11630391   2.07682086   0.        ]\n",
      "Episode =  516, total_reward =  171.69, , z=  35.64, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76862726 -0.17416112  9.33197616],\n",
      " \t action=[899.43242984275571, 0.29824537636788828, 899.6190497561098, -0.10754407850654835], \n",
      " \t task.sim.pose=[-13.40337006  -0.17492109  35.6443673    2.09455575   2.10883963   0.        ]\n",
      "Episode =  517, total_reward =  170.74, , z=  35.47, v_z=   9.33, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83435661 -0.86381624  9.33416055],\n",
      " \t action=[899.672651960042, -0.23644217399742451, 899.82668156805948, -0.30498192307678795], \n",
      " \t task.sim.pose=[-13.53929302  -3.82442593  35.47245093   2.11702556   2.09452726   0.        ]\n",
      "Episode =  518, total_reward =  172.11, , z=  35.74, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80144609 -0.06537548  9.36033496],\n",
      " \t action=[900.12849761080088, -0.011153251880043735, 900.09316850705045, 0.4925009278569451], \n",
      " \t task.sim.pose=[-13.47832098  -1.61348083  35.74221876   2.12960505   2.09234815   0.        ]\n",
      "Episode =  519, total_reward =  170.52, , z=  35.32, v_z=   9.21, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7744967   1.7760904   9.21424171],\n",
      " \t action=[899.91516310054089, 0.090019328104479268, 899.83349776908631, 0.49818126554124242], \n",
      " \t task.sim.pose=[-13.33625054   2.87793998  35.31967412   2.13029608   2.05391109   0.        ]\n",
      "Episode =  520, total_reward =  171.07, , z=  35.53, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78078928 -0.74875919  9.33395079],\n",
      " \t action=[900.26117742274482, -0.24963792589677281, 900.95992263532878, 0.14264588915066767], \n",
      " \t task.sim.pose=[-13.37132571  -2.42938956  35.52767886   2.09881084   2.11230465   0.        ]\n",
      "Episode =  521, total_reward =  170.27, , z=  35.31, v_z=   9.27, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75749385  1.08793744  9.26596525],\n",
      " \t action=[900.84570480308787, -0.30207858835112233, 900.35047883790867, -0.28604374591363646], \n",
      " \t task.sim.pose=[-13.21800098   2.33859552  35.3115982    2.08849952   2.04481665   0.        ]\n",
      "Episode =  522, total_reward =  171.13, , z=  35.56, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81044548 -0.44535522  9.34143876],\n",
      " \t action=[900.41465219343479, 0.6295843384064207, 900.27271090961221, -0.13903414512684775], \n",
      " \t task.sim.pose=[-13.43283803  -2.12666142  35.55871846   2.08578387   2.07530332   0.        ]\n",
      "Episode =  523, total_reward =  171.57, , z=  35.60, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84374705 -2.78344293  9.31258431],\n",
      " \t action=[900.12411016490194, 0.28442849920788593, 900.33756916455843, 0.85762302392404466], \n",
      " \t task.sim.pose=[-13.58712093  -7.28499492  35.59554291   2.08975584   2.1242988    0.        ]\n",
      "Episode =  524, total_reward =  171.35, , z=  35.52, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74136955  1.06301278  9.28234241],\n",
      " \t action=[900.2172086818664, -0.3328671811059043, 900.18800840565257, -0.23845708833954415], \n",
      " \t task.sim.pose=[-13.24241962   1.81733481  35.51876306   2.11489482   2.08281003   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  525, total_reward =  171.27, , z=  35.59, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80267187 -0.98738017  9.34755311],\n",
      " \t action=[900.49305989248217, -0.88849716908798537, 900.28854667055441, 0.63274495483635607], \n",
      " \t task.sim.pose=[-13.37856305  -2.49906457  35.59240527   2.05472513   2.06736458   0.        ]\n",
      "Episode =  526, total_reward =  171.27, , z=  35.58, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79742781 -1.2731544   9.32730394],\n",
      " \t action=[899.79951379776242, -0.37941743092022823, 900.47326991426633, 0.36526978562663792], \n",
      " \t task.sim.pose=[-13.45490632  -2.49267221  35.57513206   2.04556004   2.09626134   0.        ]\n",
      "Episode =  527, total_reward =  171.07, , z=  35.46, v_z=   9.24, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78325435  1.83445637  9.23816127],\n",
      " \t action=[900.04993262472885, 0.32251006599093934, 899.53024509428906, 0.27038873579373779], \n",
      " \t task.sim.pose=[-13.35192122   2.35370281  35.45555273   2.11933288   2.04119519   0.        ]\n",
      "Episode =  528, total_reward =  170.05, , z=  35.31, v_z=   9.28, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77488819  0.49201369  9.28461912],\n",
      " \t action=[899.90455456094946, 0.19526780576417668, 900.51333201190425, -0.033722228146278121], \n",
      " \t task.sim.pose=[-13.24920853   1.01460802  35.31024209   2.04959301   2.03913104   0.        ]\n",
      "Episode =  529, total_reward =  170.23, , z=  35.08, v_z=   9.03, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.71386426  3.49623079  9.0293113 ],\n",
      " \t action=[899.88158116346449, -0.27958006322175577, 900.31864326076902, -0.45189002509857945], \n",
      " \t task.sim.pose=[-13.23759807   7.11231385  35.07881594   2.17072293   2.06562221   0.        ]\n",
      "Episode =  530, total_reward =  172.78, , z=  35.88, v_z=   9.39, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81513956 -0.63523374  9.38536548],\n",
      " \t action=[900.34454082865409, -0.089057484877570592, 899.85725892261189, 0.18690088737306429], \n",
      " \t task.sim.pose=[-13.5636753   -3.22857691  35.88339439   2.14558838   2.11793019   0.        ]\n",
      "Episode =  531, total_reward =  170.61, , z=  35.45, v_z=   9.34, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83464869 -1.3493084   9.33501142],\n",
      " \t action=[900.37120781735564, -0.1403973058834557, 900.645354306169, -0.25449821554243079], \n",
      " \t task.sim.pose=[-13.49301788  -4.42063803  35.44706224   2.08632195   2.08133719   0.        ]\n",
      "Episode =  532, total_reward =  170.53, , z=  35.41, v_z=   9.34, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.93637786 -3.16624351  9.33610806],\n",
      " \t action=[900.25332548999825, 0.6189624500930142, 899.73831709874003, -0.19730658038090487], \n",
      " \t task.sim.pose=[-13.69985728 -10.42708537  35.41477291   2.05171959   2.05312424   0.        ]\n",
      "Episode =  533, total_reward =  171.43, , z=  35.61, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85480422 -1.60286786  9.3509886 ],\n",
      " \t action=[900.12444117751522, -0.15500316534163536, 900.79085806570174, -0.40780339229704632], \n",
      " \t task.sim.pose=[-13.67180771  -6.35269736  35.60820243   2.12687458   2.13794817   0.        ]\n",
      "Episode =  534, total_reward =  171.06, , z=  35.48, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76625167  1.03010768  9.28708609],\n",
      " \t action=[900.15944197347676, 0.052895110337288886, 900.02424321127296, -0.032627027837218381], \n",
      " \t task.sim.pose=[-13.29924171   1.85662268  35.4831262    2.09625873   2.06003289   0.        ]\n",
      "Episode =  535, total_reward =  171.96, , z=  35.71, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7926215  -0.60237532  9.34989125],\n",
      " \t action=[899.92806565308877, 0.2237473683456776, 899.71469224732425, -0.30175469975029401], \n",
      " \t task.sim.pose=[-13.49314239  -2.1150496   35.7064742    2.12375732   2.11841542   0.        ]\n",
      "Episode =  536, total_reward =  171.35, , z=  35.51, v_z=   9.27, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76422308  1.12695702  9.27109848],\n",
      " \t action=[900.27700652650685, -0.1815608190671153, 899.66284284856511, 0.066913814813329281], \n",
      " \t task.sim.pose=[-13.43855428   1.70740143  35.5115092    2.15128986   2.10891675   0.        ]\n",
      "Episode =  537, total_reward =  172.03, , z=  35.71, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79306135  0.39831621  9.3390223 ],\n",
      " \t action=[900.39063254257087, 0.13618655409055874, 899.53821578647592, 0.22434985808063179], \n",
      " \t task.sim.pose=[-13.48036601   0.39664278  35.71051409   2.11348454   2.08108119   0.        ]\n",
      "Episode =  538, total_reward =  171.42, , z=  35.63, v_z=   9.38, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84512636 -1.75434647  9.37683708],\n",
      " \t action=[900.14799028161531, 0.075935176729399062, 900.18564805048436, -0.51196986198506478], \n",
      " \t task.sim.pose=[-13.50959266  -6.13715578  35.62784794   2.08972767   2.09006632   0.        ]\n",
      "Episode =  539, total_reward =  171.72, , z=  35.60, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74147273  0.93081247  9.2909983 ],\n",
      " \t action=[900.11473570026385, -0.398033514495374, 900.46000639445788, 0.38035900568425302], \n",
      " \t task.sim.pose=[-13.32690285   2.3592043   35.59647332   2.11943445   2.09678855   0.        ]\n",
      "Episode =  540, total_reward =  171.82, , z=  35.65, v_z=   9.32, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75207568  0.40231946  9.32441633],\n",
      " \t action=[900.10711526050966, -0.078545743774565094, 900.78957527102182, 1.2418352611103844], \n",
      " \t task.sim.pose=[-13.3108675    0.84891731  35.64969101   2.10130589   2.09511375   0.        ]\n",
      "Episode =  541, total_reward =  171.53, , z=  35.58, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73614443  0.17452342  9.30839243],\n",
      " \t action=[899.89436284696637, 0.22044615623537278, 899.6694096854701, -0.39748577570546695], \n",
      " \t task.sim.pose=[-13.27173196   0.66375926  35.57914532   2.1273457    2.11734172   0.        ]\n",
      "Episode =  542, total_reward =  172.37, , z=  35.75, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74858163 -0.47770946  9.3294212 ],\n",
      " \t action=[900.21794111462577, 0.4168263962870048, 900.53965294257966, 0.48181821532141028], \n",
      " \t task.sim.pose=[-13.39627404  -0.52911469  35.74699284   2.12526056   2.14384568   0.        ]\n",
      "Episode =  543, total_reward =  170.68, , z=  35.47, v_z=   9.32, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83515925 -1.69114855  9.32019449],\n",
      " \t action=[900.20836403584519, -0.55002843978875748, 900.15156737219252, -0.19373070619126509], \n",
      " \t task.sim.pose=[-13.56257768  -4.64712418  35.46669359   2.05522205   2.09495138   0.        ]\n",
      "Episode =  544, total_reward =  171.69, , z=  35.65, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7855272  -0.63655306  9.34529973],\n",
      " \t action=[900.29506514375112, -0.55637163320885674, 899.50813780337785, -0.10447063847544268], \n",
      " \t task.sim.pose=[-13.39725436  -1.97276886  35.65489896   2.09940071   2.09883303   0.        ]\n",
      "Episode =  545, total_reward =  170.22, , z=  35.37, v_z=   9.32, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83169349 -1.6143872   9.31633925],\n",
      " \t action=[899.8760093759505, 0.1677491548172077, 899.75939971190724, -0.27104393001117039], \n",
      " \t task.sim.pose=[-13.46053692  -4.62134146  35.37043346   2.06520986   2.07472019   0.        ]\n",
      "Episode =  546, total_reward =  171.00, , z=  35.49, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76686009  0.21015276  9.29927192],\n",
      " \t action=[899.50381079448471, 0.14096908707727823, 899.20782393279831, -0.40132482809202996], \n",
      " \t task.sim.pose=[-13.37144523  -0.07435111  35.48944353   2.12017872   2.10505701   0.        ]\n",
      "Episode =  547, total_reward =  171.91, , z=  35.71, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79247506 -0.44685963  9.35689178],\n",
      " \t action=[899.8645258497171, -0.08742250842823146, 899.84098147407997, -0.21446585802171056], \n",
      " \t task.sim.pose=[-13.4018336   -1.78318344  35.71404807   2.09820599   2.09090636   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  548, total_reward =  171.59, , z=  35.54, v_z=   9.24, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77201705  1.93564018  9.24280723],\n",
      " \t action=[900.2852894165984, -0.049925008797766179, 899.71901868027817, 0.23895294314425264], \n",
      " \t task.sim.pose=[-13.36453758   3.0531123   35.53712647   2.13111985   2.05012135   0.        ]\n",
      "Episode =  549, total_reward =  170.56, , z=  35.39, v_z=   9.26, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86073062 -3.32294014  9.26239396],\n",
      " \t action=[899.81447782377654, 0.91714877553985086, 900.09318431319502, 0.52191503544753026], \n",
      " \t task.sim.pose=[-13.57948533  -8.96566316  35.38668439   2.05414486   2.1180607    0.        ]\n",
      "Episode =  550, total_reward =  171.71, , z=  35.64, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7651625  -0.45817867  9.33045685],\n",
      " \t action=[899.69719886225698, -1.1953457008136383, 900.12114120026467, 0.36930118707725423], \n",
      " \t task.sim.pose=[-13.3968456   -0.78410351  35.64342825   2.09715173   2.11352577   0.        ]\n",
      "Episode =  551, total_reward =  171.87, , z=  35.67, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77897732 -0.42403948  9.33378057],\n",
      " \t action=[900.09256002889549, -0.12265707386907451, 899.8439523190259, -0.062602940520093756], \n",
      " \t task.sim.pose=[-13.46727245  -0.80066532  35.67367181   2.10765158   2.1159169    0.        ]\n",
      "Episode =  552, total_reward =  171.45, , z=  35.58, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86954082 -3.12032233  9.30621138],\n",
      " \t action=[900.42194101745861, -0.057066854900019739, 900.11072880162487, 0.054860925022017643], \n",
      " \t task.sim.pose=[-13.71262142  -9.33722364  35.57532533   2.10191959   2.15103785   0.        ]\n",
      "Episode =  553, total_reward =  171.86, , z=  35.68, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80209907 -1.28816931  9.34694288],\n",
      " \t action=[900.24601066617981, 0.014683376663273212, 899.68663181663237, 0.19706810930749255], \n",
      " \t task.sim.pose=[-13.45968473  -3.65729893  35.68223121   2.12129164   2.11896561   0.        ]\n",
      "Episode =  554, total_reward =  171.41, , z=  35.58, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78952699  0.07216623  9.31889228],\n",
      " \t action=[899.86390651925001, -0.29145690171654753, 899.59844690290527, -0.77836182957025413], \n",
      " \t task.sim.pose=[-13.48247958  -0.10177581  35.58078387   2.1093712    2.10014755   0.        ]\n",
      "Episode =  555, total_reward =  171.26, , z=  35.56, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85365383 -2.25351773  9.34872522],\n",
      " \t action=[900.163074749104, 0.5675735712477884, 900.38381509838348, -0.2840805326774184], \n",
      " \t task.sim.pose=[-13.56951082  -7.65046712  35.5640788    2.11497866   2.11924524   0.        ]\n",
      "Episode =  556, total_reward =  171.27, , z=  35.59, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79952185 -1.04202427  9.33374116],\n",
      " \t action=[899.6340526540132, -0.29750972961725014, 900.50818344569154, -0.054777977475882367], \n",
      " \t task.sim.pose=[-13.41852297  -2.67946715  35.58855956   2.05565089   2.08853804   0.        ]\n",
      "Episode =  557, total_reward =  171.37, , z=  35.60, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80855301 -0.09230811  9.33176663],\n",
      " \t action=[900.25118319203739, -0.69290780626485571, 900.07106226512656, 0.16992995702742808], \n",
      " \t task.sim.pose=[-13.45571613  -1.38126677  35.59722103   2.10381426   2.07842058   0.        ]\n",
      "Episode =  558, total_reward =  171.69, , z=  35.69, v_z=   9.38, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85864125 -1.27259205  9.37725122],\n",
      " \t action=[899.8045532817265, -0.62555979945941553, 899.79012549651782, 0.12782071512082405], \n",
      " \t task.sim.pose=[-13.62349224  -5.09057637  35.6919476    2.09563213   2.09070141   0.        ]\n",
      "Episode =  559, total_reward =  172.04, , z=  35.73, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79090412 -0.03454732  9.35014849],\n",
      " \t action=[900.11846290392077, -0.20127454381435933, 899.94411473967421, -0.59526341248604731], \n",
      " \t task.sim.pose=[-13.45404498  -1.12789851  35.7340617    2.09551127   2.09431971   0.        ]\n",
      "Episode =  560, total_reward =  171.37, , z=  35.60, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81291686 -0.43108304  9.35602158],\n",
      " \t action=[900.78758727678155, -0.039884537860738867, 900.6051571793397, 0.19512807330660256], \n",
      " \t task.sim.pose=[-13.45689056  -2.20221516  35.59910294   2.09815519   2.07717868   0.        ]\n",
      "Episode =  561, total_reward =  171.39, , z=  35.59, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77278619 -0.95706547  9.33460248],\n",
      " \t action=[899.85538693409842, 0.40722740174642447, 900.33400552293654, -0.045400454126239831], \n",
      " \t task.sim.pose=[-13.36095624  -2.30832742  35.58974002   2.09707514   2.11454123   0.        ]\n",
      "Episode =  562, total_reward =  170.39, , z=  35.32, v_z=   9.21, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86160346 -3.77985051  9.20515691],\n",
      " \t action=[899.85647786461516, 0.084251527770838636, 899.48497983577283, -0.36918568041691863], \n",
      " \t task.sim.pose=[-13.62101273  -9.35083781  35.31981975   2.0540561    2.12931977   0.        ]\n",
      "Episode =  563, total_reward =  170.23, , z=  35.17, v_z=   9.12, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72640112  2.71024032  9.1222417 ],\n",
      " \t action=[900.4893408560373, -0.34166066391888694, 900.02801702808097, -0.042147395335073987], \n",
      " \t task.sim.pose=[-13.18670692   5.49459906  35.16955946   2.14146871   2.05164315   0.        ]\n",
      "Episode =  564, total_reward =  170.54, , z=  35.26, v_z=   9.18, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72313766  2.05408634  9.17911162],\n",
      " \t action=[899.43512701000236, -0.31727859546513848, 900.02268272892104, -0.30089046215341725], \n",
      " \t task.sim.pose=[-13.25965654   4.50431062  35.26318792   2.12729513   2.08843282   0.        ]\n",
      "Episode =  565, total_reward =  170.96, , z=  35.39, v_z=   9.22, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76823455  1.93001383  9.22030357],\n",
      " \t action=[900.7209888219096, -0.27485678019126725, 899.07972536403815, -0.69861178234497656], \n",
      " \t task.sim.pose=[-13.3553242    4.61819217  35.39488659   2.10726503   2.03728813   0.        ]\n",
      "Episode =  566, total_reward =  170.92, , z=  35.45, v_z=   9.28, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76010707  0.33719625  9.2764044 ],\n",
      " \t action=[900.06442080947193, -0.019037316692001115, 899.4820570988029, -0.4588243972263133], \n",
      " \t task.sim.pose=[-13.36473208   1.18290035  35.44704937   2.08952277   2.09427109   0.        ]\n",
      "Episode =  567, total_reward =  171.77, , z=  35.65, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78878176 -0.09779855  9.33835717],\n",
      " \t action=[900.33521008931359, -0.013593422649784748, 899.81731433837001, -0.38124185572548985], \n",
      " \t task.sim.pose=[-13.4445576   -0.13856015  35.65203856   2.11428301   2.09004838   0.        ]\n",
      "Episode =  568, total_reward =  171.85, , z=  35.70, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80931866 -0.65890537  9.3508174 ],\n",
      " \t action=[899.76753413013603, -0.62941849992029275, 899.78233029850287, 0.31404451121470017], \n",
      " \t task.sim.pose=[-13.53299244  -3.41680668  35.70151423   2.13288265   2.12583776   0.        ]\n",
      "Episode =  569, total_reward =  171.90, , z=  35.58, v_z=   9.22, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75361295  2.12194026  9.22274642],\n",
      " \t action=[900.36276893426907, 0.31641158355263466, 899.92598420242439, -0.018686643345187021], \n",
      " \t task.sim.pose=[-13.35647372   3.96055274  35.57547259   2.15117792   2.06828829   0.        ]\n",
      "Episode =  570, total_reward =  171.29, , z=  35.53, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8940512  -3.12322503  9.30922813],\n",
      " \t action=[900.0265458169348, 0.3508829537060924, 900.49885086861161, 0.10397959246981675], \n",
      " \t task.sim.pose=[-13.80067048  -9.08509828  35.53235413   2.09820318   2.13574828   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  571, total_reward =  171.02, , z=  35.46, v_z=   9.27, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77816092  1.28655006  9.27289205],\n",
      " \t action=[900.43494030670161, 0.28613831247723087, 899.95858252956111, 0.23924057936571708], \n",
      " \t task.sim.pose=[-13.34414569   2.12760933  35.46412899   2.10396033   2.04879548   0.        ]\n",
      "Episode =  572, total_reward =  171.72, , z=  35.65, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7871702  -1.37104278  9.32308943],\n",
      " \t action=[899.68375780233669, -0.11543218639796315, 900.21820473770538, 0.0042398460381333769], \n",
      " \t task.sim.pose=[-13.49644482  -3.50354317  35.65350871   2.09954038   2.14387746   0.        ]\n",
      "Episode =  573, total_reward =  170.60, , z=  35.42, v_z=   9.30, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83372981 -2.2620835   9.30206488],\n",
      " \t action=[900.01800964049744, -0.21240896912983598, 899.80131709742761, 0.19975989315264236], \n",
      " \t task.sim.pose=[-13.54456766  -6.43088076  35.42102474   2.09628341   2.12419577   0.        ]\n",
      "Episode =  574, total_reward =  171.29, , z=  35.53, v_z=   9.27, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84986112 -3.2289394   9.26914839],\n",
      " \t action=[900.40249466699015, -0.084518000424624096, 900.32984583423274, -0.342729889204055], \n",
      " \t task.sim.pose=[-13.6143444   -7.8202181   35.52788502   2.05875449   2.12426529   0.        ]\n",
      "Episode =  575, total_reward =  172.30, , z=  35.64, v_z=   9.23, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75480439  2.17277747  9.23118587],\n",
      " \t action=[900.65129487739102, -0.086076995888638513, 899.94514024252078, 0.0599259750989799], \n",
      " \t task.sim.pose=[-13.42057085   3.75108512  35.64239335   2.16026603   2.08299844   0.        ]\n",
      "Episode =  576, total_reward =  171.87, , z=  35.69, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79451243 -0.38636273  9.34684202],\n",
      " \t action=[899.30017439814446, 0.019811037124080333, 900.05398503178833, -0.36429361100581559], \n",
      " \t task.sim.pose=[-13.46118945  -2.34663959  35.6926742    2.13412546   2.11783256   0.        ]\n",
      "Episode =  577, total_reward =  171.81, , z=  35.66, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83260897 -2.12125095  9.32513265],\n",
      " \t action=[899.61744092785671, 0.38443797407493352, 899.81805640411176, -0.26925991013204004], \n",
      " \t task.sim.pose=[-13.67397403  -5.78038763  35.65670619   2.11813006   2.15717648   0.        ]\n",
      "Episode =  578, total_reward =  171.69, , z=  35.66, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84744415 -1.46578834  9.35489465],\n",
      " \t action=[899.90354124534815, -0.29961202271846843, 900.03046063534077, -0.14557811971478829], \n",
      " \t task.sim.pose=[-13.68374142  -5.58409296  35.65943498   2.13283066   2.13890132   0.        ]\n",
      "Episode =  579, total_reward =  171.71, , z=  35.68, v_z=   9.38, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88191869 -1.80467464  9.37748097],\n",
      " \t action=[900.38347146481397, -0.10026954730800455, 900.00687919592258, -0.44388897117158793], \n",
      " \t task.sim.pose=[-13.70856759  -6.97033364  35.68256558   2.10942265   2.09856429   0.        ]\n",
      "Episode =  580, total_reward =  171.86, , z=  35.69, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81052062 -1.73194573  9.34782543],\n",
      " \t action=[899.99336447400526, -0.4230494618410135, 899.72089910769012, -0.10275011477830213], \n",
      " \t task.sim.pose=[-13.51653875  -4.33410211  35.68935957   2.08654654   2.11895336   0.        ]\n",
      "Episode =  581, total_reward =  171.28, , z=  35.60, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81506886 -0.41766169  9.35413735],\n",
      " \t action=[900.12735227175119, 0.36095610932522565, 900.3862944091419, 0.73808536221314491], \n",
      " \t task.sim.pose=[-13.43086843  -2.12197186  35.60440658   2.05914261   2.05762984   0.        ]\n",
      "Episode =  582, total_reward =  171.41, , z=  35.62, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8056923  -0.96747189  9.3494189 ],\n",
      " \t action=[899.70366038798647, 0.28905400717095914, 899.891666165213, -0.11454624893077786], \n",
      " \t task.sim.pose=[-13.43905454  -3.4088261   35.62284284   2.09651334   2.10093648   0.        ]\n",
      "Episode =  583, total_reward =  171.27, , z=  35.55, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84313035 -2.53822498  9.31155192],\n",
      " \t action=[900.31932037808758, 0.24327293235478578, 899.45388019486199, -0.28285535682233048], \n",
      " \t task.sim.pose=[-13.60014989  -6.82686734  35.54893505   2.09150918   2.12856909   0.        ]\n",
      "Episode =  584, total_reward =  171.50, , z=  35.61, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79216694 -0.12651862  9.32221723],\n",
      " \t action=[899.86215319814596, -0.021000156762682499, 899.83255646877319, 0.59726142727921561], \n",
      " \t task.sim.pose=[-13.49571641  -1.43973291  35.61335171   2.12001718   2.11502288   0.        ]\n",
      "Episode =  585, total_reward =  170.48, , z=  35.41, v_z=   9.31, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78803505 -0.57877736  9.31431251],\n",
      " \t action=[900.73050980462017, 0.42705954830211362, 899.22366151067581, -0.21469207747721009], \n",
      " \t task.sim.pose=[-13.29877791  -1.96519519  35.40687874   2.08999438   2.07398652   0.        ]\n",
      "Episode =  586, total_reward =  170.83, , z=  35.45, v_z=   9.30, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87495993 -3.05548851  9.29576069],\n",
      " \t action=[900.36307195844995, -0.24131650915144803, 900.12955962392039, -0.41288628063257471], \n",
      " \t task.sim.pose=[-13.65796002  -9.00683088  35.45051388   2.09269478   2.12601873   0.        ]\n",
      "Episode =  587, total_reward =  171.38, , z=  35.50, v_z=   9.26, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7302038   1.41838736  9.25578073],\n",
      " \t action=[899.90063682657535, 0.038261050110978231, 900.07630276983707, 0.59154038462862391], \n",
      " \t task.sim.pose=[-13.26109893   3.30479688  35.4979263    2.1237029    2.08636413   0.        ]\n",
      "Episode =  588, total_reward =  171.17, , z=  35.56, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80809721 -1.67466603  9.32390171],\n",
      " \t action=[900.05929289474852, 0.41520473926356677, 899.85385902038956, -0.12575135340563082], \n",
      " \t task.sim.pose=[-13.44791402  -4.28305621  35.55735521   2.06573513   2.10608869   0.        ]\n",
      "Episode =  589, total_reward =  171.88, , z=  35.72, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85957425 -1.55299413  9.37313804],\n",
      " \t action=[900.22878447029393, -0.29140446377768531, 899.93636917441847, -0.49667986567331379], \n",
      " \t task.sim.pose=[-13.68361788  -6.05252385  35.71784895   2.12334228   2.11808908   0.        ]\n",
      "Episode =  590, total_reward =  172.40, , z=  35.82, v_z=   9.39, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84436997 -1.59417678  9.39275915],\n",
      " \t action=[899.7311220364096, -0.47698168146077441, 899.52504181341612, -0.086121045794061185], \n",
      " \t task.sim.pose=[-13.59534569  -6.306992    35.82265314   2.12901565   2.12260078   0.        ]\n",
      "Episode =  591, total_reward =  171.48, , z=  35.63, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81253586 -0.44406284  9.34185627],\n",
      " \t action=[899.9136719834969, 0.70236011948532318, 899.91064097824403, 0.25411302882762188], \n",
      " \t task.sim.pose=[-13.48011563  -2.52886196  35.63032848   2.10452279   2.08645945   0.        ]\n",
      "Episode =  592, total_reward =  172.13, , z=  35.72, v_z=   9.31, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82548623 -2.48934584  9.30970769],\n",
      " \t action=[899.35623610110417, -0.42276186022275536, 899.6586438766908, 0.65353138173546155], \n",
      " \t task.sim.pose=[-13.66600284  -6.07122438  35.71570811   2.10815922   2.16585453   0.        ]\n",
      "Episode =  593, total_reward =  171.08, , z=  35.39, v_z=   9.19, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73867456  2.19011506  9.18850127],\n",
      " \t action=[899.81131088021777, -0.17533228188176719, 900.4114544171448, -0.39236683817916884], \n",
      " \t task.sim.pose=[-13.30874053   4.32924398  35.39218452   2.15781427   2.07990323   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  594, total_reward =  170.79, , z=  35.37, v_z=   9.24, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8950613  -4.08729947  9.24205445],\n",
      " \t action=[900.10193706311975, -0.23214741084190299, 900.06994969073355, 0.46399591804109536], \n",
      " \t task.sim.pose=[-13.67788708 -11.64965324  35.36680769   2.0868158    2.13038296   0.        ]\n",
      "Episode =  595, total_reward =  172.47, , z=  35.77, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76513994  0.82218372  9.32969708],\n",
      " \t action=[900.48453617282439, 0.30106466670595, 900.62720733014589, -0.17584173465392061], \n",
      " \t task.sim.pose=[-13.44394442   1.49249737  35.76801067   2.11025196   2.10019824   0.        ]\n",
      "Episode =  596, total_reward =  171.50, , z=  35.62, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80177919 -1.27633578  9.33686125],\n",
      " \t action=[899.90207609399044, -0.42374950919889665, 899.66777721923552, 0.34645183423393588], \n",
      " \t task.sim.pose=[-13.4279891   -2.97393614  35.61767511   2.08450963   2.09458694   0.        ]\n",
      "Episode =  597, total_reward =  172.51, , z=  35.84, v_z=   9.38, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84441253 -1.19830858  9.38159814],\n",
      " \t action=[900.01389715224366, -0.034841659532839242, 900.10797150191888, -0.32203721012471986], \n",
      " \t task.sim.pose=[-13.70253467  -4.43987493  35.84457996   2.11039118   2.12286926   0.        ]\n",
      "Episode =  598, total_reward =  172.34, , z=  35.78, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80056201  0.34840341  9.34167017],\n",
      " \t action=[900.15119543343371, -0.29961879799906521, 900.15046839170611, 0.16164275338455097], \n",
      " \t task.sim.pose=[-13.54495945  -0.58132515  35.77578726   2.13015432   2.10599652   0.        ]\n",
      "Episode =  599, total_reward =  171.73, , z=  35.65, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[ -1.78651474e+00  -8.59050977e-03   9.33405799e+00],\n",
      " \t action=[900.0673401462908, 0.12792760024839339, 900.25571917429374, 0.044326431038352709], \n",
      " \t task.sim.pose=[-13.50788294  -1.29196228  35.64543389   2.13651523   2.12596807   0.        ]\n",
      "Episode =  600, total_reward =  171.14, , z=  35.55, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82519869 -1.52150173  9.333815  ],\n",
      " \t action=[900.65621508514528, 0.58008593264339048, 900.35496713731914, -0.38665833882297906], \n",
      " \t task.sim.pose=[-13.45969555  -4.00565907  35.55193443   2.06610098   2.07910979   0.        ]\n",
      "Episode =  601, total_reward =  170.72, , z=  35.38, v_z=   9.24, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76327704  1.53996558  9.24196059],\n",
      " \t action=[900.25149151672872, 0.082526617887130602, 899.66594437938681, 0.35957805210018068], \n",
      " \t task.sim.pose=[-13.26763386   2.60200086  35.38107243   2.10958037   2.05148452   0.        ]\n",
      "Episode =  602, total_reward =  171.53, , z=  35.57, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81713592 -2.69663748  9.28502741],\n",
      " \t action=[899.79909097624773, 0.22830282230491244, 899.6920462275508, 0.56158152766481118], \n",
      " \t task.sim.pose=[-13.53859819  -6.0161511   35.56961493   2.08539643   2.14034471   0.        ]\n",
      "Episode =  603, total_reward =  171.62, , z=  35.64, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81374347 -0.20373536  9.35262985],\n",
      " \t action=[900.18511839045152, -0.80990497620028423, 899.72000399297406, -0.3068893398785531], \n",
      " \t task.sim.pose=[-13.49060139  -1.98333385  35.64459216   2.12114228   2.08798239   0.        ]\n",
      "Episode =  604, total_reward =  171.79, , z=  35.67, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84573986 -2.16377554  9.35009841],\n",
      " \t action=[900.13697304925029, 0.34292088813703897, 900.25017740992951, -0.018627456032453832], \n",
      " \t task.sim.pose=[-13.58863018  -6.57835211  35.67392181   2.10206957   2.11867331   0.        ]\n",
      "Episode =  605, total_reward =  171.51, , z=  35.59, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79584067 -2.00075111  9.30364271],\n",
      " \t action=[899.71804251256094, -0.51472348501757359, 900.20725281909586, 0.85089241585840358], \n",
      " \t task.sim.pose=[-13.47841109  -4.62583401  35.58954985   2.09332884   2.14306869   0.        ]\n",
      "Episode =  606, total_reward =  172.08, , z=  35.72, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81301624 -2.0184376   9.32577444],\n",
      " \t action=[900.02468044353134, -0.30681636597045869, 899.90363092758128, -0.12678813116182761], \n",
      " \t task.sim.pose=[-13.57900936  -4.81787994  35.72034809   2.09159047   2.14014592   0.        ]\n",
      "Episode =  607, total_reward =  170.37, , z=  35.38, v_z=   9.30, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76859452 -0.70578355  9.29655058],\n",
      " \t action=[900.23238049913755, -0.46523206597444583, 899.91810110706137, 0.69858536078323064], \n",
      " \t task.sim.pose=[-13.27532569  -1.03890244  35.3842439    2.05911131   2.08123172   0.        ]\n",
      "Episode =  608, total_reward =  171.55, , z=  35.61, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81581193 -1.99167429  9.33096002],\n",
      " \t action=[900.47744415862905, -0.84093231797612511, 900.17653754717242, 0.02826631646069918], \n",
      " \t task.sim.pose=[-13.52342289  -4.99753192  35.61270959   2.0956036    2.12776297   0.        ]\n",
      "Episode =  609, total_reward =  169.80, , z=  35.27, v_z=   9.30, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86837698 -2.45426192  9.30026353],\n",
      " \t action=[900.48614485231712, -0.1822359902350934, 899.48475375149133, -0.96485833393323461], \n",
      " \t task.sim.pose=[-13.54061961  -7.88217466  35.2682319    2.07877989   2.09076868   0.        ]\n",
      "Episode =  610, total_reward =  170.81, , z=  35.16, v_z=   9.06, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.68108958  3.32593085  9.05806516],\n",
      " \t action=[899.97053175642634, 0.57628917888183528, 899.93370889419145, -0.039769630847674237], \n",
      " \t task.sim.pose=[-13.21613888   8.11914327  35.16445933   2.158475     2.09283149   0.        ]\n",
      "Episode =  611, total_reward =  171.72, , z=  35.67, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85330732 -2.06072314  9.34276001],\n",
      " \t action=[899.93488903726109, 0.8427430934761666, 900.26110180317471, -0.18402154153042932], \n",
      " \t task.sim.pose=[-13.6834903   -6.32762831  35.66570834   2.10318474   2.13300058   0.        ]\n",
      "Episode =  612, total_reward =  172.25, , z=  35.77, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81656294 -1.31366638  9.36634322],\n",
      " \t action=[900.20386723409581, 0.34316001291295617, 900.0884240903531, -0.24372077890695418], \n",
      " \t task.sim.pose=[-13.56491069  -4.04177098  35.77156202   2.12495486   2.12727599   0.        ]\n",
      "Episode =  613, total_reward =  171.13, , z=  35.51, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75280018  0.05588789  9.30749852],\n",
      " \t action=[900.46220008346506, -0.28634093920164749, 899.74962908674956, -0.072343271531981668], \n",
      " \t task.sim.pose=[-13.29201029   0.52019063  35.50794486   2.08007629   2.09228794   0.        ]\n",
      "Episode =  614, total_reward =  170.10, , z=  35.06, v_z=   9.07, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.67214175  3.18956771  9.07207143],\n",
      " \t action=[899.87969005697175, 0.68139085085247197, 899.93568937980115, -0.22485441992006594], \n",
      " \t task.sim.pose=[-13.05551248   8.21598885  35.05869844   2.14651081   2.06818225   0.        ]\n",
      "Episode =  615, total_reward =  172.67, , z=  35.86, v_z=   9.37, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81509596  0.38501277  9.36538857],\n",
      " \t action=[900.30306828337882, -0.38093000868135068, 900.50160790688903, -0.68061766906283683], \n",
      " \t task.sim.pose=[-13.55810993  -1.27621706  35.85902712   2.13856659   2.09044368   0.        ]\n",
      "Episode =  616, total_reward =  171.81, , z=  35.64, v_z=   9.30, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84665091 -3.06315322  9.30415616],\n",
      " \t action=[900.24534342210177, -0.40771294077924447, 900.58116549598662, 0.20116607643270945], \n",
      " \t task.sim.pose=[-13.60573216  -8.01810468  35.64179225   2.08054922   2.13259536   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  617, total_reward =  171.61, , z=  35.65, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.799456   0.1788432  9.3381438],\n",
      " \t action=[899.68300693135006, -0.51449400040882631, 899.98695748318164, -0.20756712867796359], \n",
      " \t task.sim.pose=[-13.39813706  -0.61157766  35.65192116   2.07816386   2.05746124   0.        ]\n",
      "Episode =  618, total_reward =  170.32, , z=  35.17, v_z=   9.14, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72520767  2.63674595  9.13844818],\n",
      " \t action=[899.97626715907722, 0.3068610885658945, 900.53857048888051, -0.10904920970524704], \n",
      " \t task.sim.pose=[-13.24056788   6.24894894  35.16518163   2.10467309   2.0568364    0.        ]\n",
      "Episode =  619, total_reward =  171.62, , z=  35.67, v_z=   9.37, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85112494 -1.97429468  9.36687782],\n",
      " \t action=[899.95617546372114, -0.21656880641983706, 899.52121752997232, -0.14156862766430445], \n",
      " \t task.sim.pose=[-13.51825919  -6.00689573  35.67028884   2.05873105   2.07539688   0.        ]\n",
      "Episode =  620, total_reward =  170.11, , z=  35.24, v_z=   9.22, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74041276  1.3679161   9.21900069],\n",
      " \t action=[899.86852172329282, 0.095380862351679904, 899.96520670271457, 0.0075008228475185734], \n",
      " \t task.sim.pose=[-13.26138978   3.16256934  35.23930935   2.10406351   2.07875984   0.        ]\n",
      "Episode =  621, total_reward =  171.85, , z=  35.61, v_z=   9.27, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84641907 -3.4612774   9.27420189],\n",
      " \t action=[900.23842303019046, 0.12662384326339857, 899.96401268486409, -0.11017368620888091], \n",
      " \t task.sim.pose=[-13.65988349  -8.66155506  35.60792459   2.09996759   2.16419035   0.        ]\n",
      "Episode =  622, total_reward =  172.93, , z=  35.88, v_z=   9.35, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77265346 -0.78944675  9.34825882],\n",
      " \t action=[899.84017058061954, 0.0025381710933506663, 899.85194549294226, -0.055615670852143057], \n",
      " \t task.sim.pose=[-13.54873342  -1.81031866  35.87663371   2.14565777   2.16782186   0.        ]\n",
      "Episode =  623, total_reward =  169.47, , z=  34.83, v_z=   8.95, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.67237973  4.03697808  8.9498711 ],\n",
      " \t action=[900.69422812087055, -0.17124060779426103, 899.88328382323891, 0.38459079486730152], \n",
      " \t task.sim.pose=[-13.01105753   9.41953002  34.82899417   2.15282399   2.03944665   0.        ]\n",
      "Episode =  624, total_reward =  171.34, , z=  35.60, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83360425 -1.7448293   9.34612576],\n",
      " \t action=[899.64419163010689, -0.081911699284883899, 900.67602031633226, 0.26558073230280099], \n",
      " \t task.sim.pose=[-13.53361459  -5.13509883  35.59939324   2.07461346   2.10039547   0.        ]\n",
      "Episode =  625, total_reward =  171.47, , z=  35.59, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82959706 -2.84153192  9.29781465],\n",
      " \t action=[900.39275609233687, -0.17027328662220842, 900.0534804409541, 0.44147235152381703], \n",
      " \t task.sim.pose=[-13.52024893  -6.94217755  35.59154743   2.04599824   2.11630057   0.        ]\n",
      "Episode =  626, total_reward =  171.09, , z=  35.55, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82584195 -1.26860813  9.33913386],\n",
      " \t action=[899.35114174853481, 0.72399852479357085, 899.09514091326923, 0.041676342215733769], \n",
      " \t task.sim.pose=[-13.53100769  -3.92676446  35.55313924   2.08767534   2.09981408   0.        ]\n",
      "Episode =  627, total_reward =  170.69, , z=  35.29, v_z=   9.17, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73001799  2.30860029  9.17014806],\n",
      " \t action=[900.34951471228078, -0.064006007555831163, 899.27050606369562, 0.22211849149906973], \n",
      " \t task.sim.pose=[-13.20118474   5.16937654  35.29449868   2.12911303   2.05601423   0.        ]\n",
      "Episode =  628, total_reward =  170.94, , z=  35.49, v_z=   9.30, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81349404 -2.0086897   9.29935426],\n",
      " \t action=[900.14705384788022, 0.44889499966652141, 899.79605877497954, -0.17227073496855094], \n",
      " \t task.sim.pose=[-13.49840324  -4.98399062  35.49232104   2.08122009   2.11984669   0.        ]\n",
      "Episode =  629, total_reward =  170.66, , z=  35.47, v_z=   9.33, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86096954 -2.22584557  9.33245002],\n",
      " \t action=[900.01495203369063, 0.026912413456405486, 900.29609237467048, -0.12688369520040629], \n",
      " \t task.sim.pose=[-13.55060164  -6.66186245  35.47358441   2.05439663   2.08026749   0.        ]\n",
      "Episode =  630, total_reward =  172.37, , z=  35.79, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82353386 -2.11850639  9.36031665],\n",
      " \t action=[900.24055880270669, 0.45810348234050402, 899.63298380095114, -0.049055077575666961], \n",
      " \t task.sim.pose=[-13.55081725  -5.81212791  35.78520384   2.11071867   2.13270294   0.        ]\n",
      "Episode =  631, total_reward =  172.91, , z=  35.92, v_z=   9.39, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85287711 -2.06708779  9.38731359],\n",
      " \t action=[899.95907896843164, -0.045471114561340342, 900.06716073131372, -0.23193416416326468], \n",
      " \t task.sim.pose=[-13.69467474  -6.45045927  35.91724832   2.10762027   2.13137513   0.        ]\n",
      "Episode =  632, total_reward =  171.57, , z=  35.60, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8256325  -2.73333988  9.29031132],\n",
      " \t action=[899.94549982275817, -1.0714078177688859, 899.84508174882785, -0.46423236688198694], \n",
      " \t task.sim.pose=[-13.56984714  -6.39713546  35.59937373   2.07706739   2.13812566   0.        ]\n",
      "Episode =  633, total_reward =  170.68, , z=  35.45, v_z=   9.30, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80370106 -1.67906517  9.29869457],\n",
      " \t action=[900.31957113355725, -0.55716256770951977, 900.23571942191313, -0.50538610831119224], \n",
      " \t task.sim.pose=[-13.43473377  -3.36494029  35.45168808   2.03201336   2.09321569   0.        ]\n",
      "Episode =  634, total_reward =  171.53, , z=  35.58, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74946353  0.93505982  9.29851576],\n",
      " \t action=[900.21343411564885, 0.31047112543597111, 900.08295544717078, -0.1427907379880789], \n",
      " \t task.sim.pose=[-13.24587055   1.82953849  35.57844014   2.11729425   2.07160214   0.        ]\n",
      "Episode =  635, total_reward =  169.93, , z=  35.22, v_z=   9.22, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88719599 -3.8987672   9.22219106],\n",
      " \t action=[899.6862228108065, 0.28985837610783627, 900.16298290129691, 0.44770369375125979], \n",
      " \t task.sim.pose=[-13.65089407 -10.71027539  35.21980506   2.05891034   2.11961314   0.        ]\n",
      "Episode =  636, total_reward =  171.14, , z=  35.51, v_z=   9.27, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83119916 -2.87621691  9.2748695 ],\n",
      " \t action=[899.93969284615378, 0.21424733313358096, 900.30789656318882, -0.8950747646493199], \n",
      " \t task.sim.pose=[-13.50698061  -6.35541501  35.50717274   2.04129125   2.10293548   0.        ]\n",
      "Episode =  637, total_reward =  171.49, , z=  35.64, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80823853 -0.43231607  9.35244112],\n",
      " \t action=[899.7864603373464, -0.34113926000890749, 899.88746679258236, -0.057047487031391342], \n",
      " \t task.sim.pose=[-13.45383278  -2.1857518   35.63992489   2.08088074   2.08138177   0.        ]\n",
      "Episode =  638, total_reward =  171.08, , z=  35.55, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86620965 -0.62561595  9.35249202],\n",
      " \t action=[900.12972260903814, -0.17849291320005045, 899.80985757464077, -0.73108137747953295], \n",
      " \t task.sim.pose=[-13.63029797  -4.65041565  35.5530715    2.14011206   2.08291154   0.        ]\n",
      "Episode =  639, total_reward =  172.42, , z=  35.82, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80655312 -1.71939465  9.35861258],\n",
      " \t action=[900.11448397760842, 0.38531645537200937, 900.22089587370681, 0.26372342982173469], \n",
      " \t task.sim.pose=[-13.53700004  -4.56086227  35.8151062    2.09633347   2.13126951   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  640, total_reward =  171.49, , z=  35.60, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79320813 -1.8226826   9.31360895],\n",
      " \t action=[899.18649906495318, -0.2136539179010109, 899.85425029667465, -0.38964752885730192], \n",
      " \t task.sim.pose=[-13.42997735  -3.68051667  35.60117364   2.07857332   2.11820596   0.        ]\n",
      "Episode =  641, total_reward =  170.50, , z=  35.32, v_z=   9.18, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85571739 -3.96843837  9.18459885],\n",
      " \t action=[900.34258603371859, 0.69331317835495787, 900.67353113578611, 0.16307924176948455], \n",
      " \t task.sim.pose=[-13.60036316  -9.34866284  35.31907163   2.03255364   2.13256209   0.        ]\n",
      "Episode =  642, total_reward =  172.02, , z=  35.75, v_z=   9.38, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83734281 -0.92846556  9.38329591],\n",
      " \t action=[899.99970997396838, 0.40973061667660604, 900.15540125689847, 0.37383591169191133], \n",
      " \t task.sim.pose=[-13.49701392  -3.81347656  35.75314371   2.10456997   2.07130246   0.        ]\n",
      "Episode =  643, total_reward =  171.84, , z=  35.60, v_z=   9.25, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76719048  1.69820487  9.25180148],\n",
      " \t action=[900.1829670648641, 0.93814197478275407, 900.18732519414561, 0.24346309776386643], \n",
      " \t task.sim.pose=[-13.43953903   2.66162827  35.5975418    2.13754447   2.08836559   0.        ]\n",
      "Episode =  644, total_reward =  171.91, , z=  35.71, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8069339  -0.72717482  9.36890421],\n",
      " \t action=[900.2868241684223, 0.489522916697682, 899.96727334247851, 0.62815275021316108], \n",
      " \t task.sim.pose=[-13.49310217  -2.45460097  35.71187285   2.08600447   2.09682442   0.        ]\n",
      "Episode =  645, total_reward =  172.09, , z=  35.71, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76280025 -0.05752712  9.34192603],\n",
      " \t action=[900.16255979736025, -0.51890945587105664, 899.77161225827626, 0.11438693497969621], \n",
      " \t task.sim.pose=[-13.40303893  -0.27238619  35.712937     2.12648536   2.11591985   0.        ]\n",
      "Episode =  646, total_reward =  171.29, , z=  35.53, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75624877  0.6616055   9.28766084],\n",
      " \t action=[900.09460693273786, 0.38378452000192148, 899.68142216004412, 0.83262440562266971], \n",
      " \t task.sim.pose=[-13.31404559   0.8655227   35.52558215   2.14396937   2.1009026    0.        ]\n",
      "Episode =  647, total_reward =  171.91, , z=  35.69, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77448847 -0.7539232   9.3398575 ],\n",
      " \t action=[900.31475270423709, 0.021299685802560697, 899.92373376882051, -0.2300928314649735], \n",
      " \t task.sim.pose=[-13.40578054  -1.62942475  35.68733945   2.10715376   2.11510944   0.        ]\n",
      "Episode =  648, total_reward =  171.43, , z=  35.61, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82245323 -1.39793473  9.33518588],\n",
      " \t action=[899.72435414547454, -0.47061613769993954, 900.46253154443821, 0.0042652307354014221], \n",
      " \t task.sim.pose=[-13.59126697  -4.18795829  35.60670273   2.10133284   2.12757957   0.        ]\n",
      "Episode =  649, total_reward =  171.07, , z=  35.56, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83461538 -1.88661804  9.34063902],\n",
      " \t action=[899.37878171702607, 0.30623362887936639, 900.22236624918764, 0.071245077888106301], \n",
      " \t task.sim.pose=[-13.4574127   -5.10104941  35.55870572   2.03611644   2.07497393   0.        ]\n",
      "Episode =  650, total_reward =  171.67, , z=  35.53, v_z=   9.21, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74784635  2.02392549  9.21470706],\n",
      " \t action=[899.69648322101887, 0.62346906754451337, 899.86306482677094, -0.094174520643289988], \n",
      " \t task.sim.pose=[-13.3478178    3.0676077   35.53345265   2.16887313   2.09257668   0.        ]\n",
      "Episode =  651, total_reward =  171.99, , z=  35.67, v_z=   9.31, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75600015  0.71703462  9.31321595],\n",
      " \t action=[899.90099996685535, -0.33607389039151025, 900.08256071979804, -0.46066049538497722], \n",
      " \t task.sim.pose=[-13.37190921   1.38975354  35.66550177   2.13461657   2.10110389   0.        ]\n",
      "Episode =  652, total_reward =  171.89, , z=  35.68, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81031148 -2.28680481  9.32741432],\n",
      " \t action=[899.89617254693815, 0.083654660504716233, 899.44926172271676, 0.037765076867877043], \n",
      " \t task.sim.pose=[-13.48726891  -5.39567456  35.68272732   2.07886771   2.12367454   0.        ]\n",
      "Episode =  653, total_reward =  170.21, , z=  35.14, v_z=   9.09, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.89736163 -5.25138731  9.08763364],\n",
      " \t action=[900.34159826788664, -0.95141533572902925, 900.02249205966098, 0.78015419104917227], \n",
      " \t task.sim.pose=[-13.68975357 -13.15683693  35.13885796   2.05357024   2.13797377   0.        ]\n",
      "Episode =  654, total_reward =  170.64, , z=  35.37, v_z=   9.24, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75807397  1.383519    9.2376137 ],\n",
      " \t action=[899.974760215277, 0.038772173645769403, 900.19858893431751, -0.53868501440655459], \n",
      " \t task.sim.pose=[-13.31713264   2.52021045  35.3665939    2.12162272   2.0761017    0.        ]\n",
      "Episode =  655, total_reward =  171.07, , z=  35.54, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82259273 -0.01672179  9.33527881],\n",
      " \t action=[900.49293261897435, 0.14573602012200354, 899.22267144776004, 0.28281588609245739], \n",
      " \t task.sim.pose=[-13.47168943  -1.92072698  35.53813255   2.11836716   2.06965232   0.        ]\n",
      "Episode =  656, total_reward =  170.06, , z=  35.11, v_z=   9.11, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.70107393  2.90790091  9.10648227],\n",
      " \t action=[899.91816823582963, 0.029005847066824728, 899.8327716947806, 0.48395051373086184], \n",
      " \t task.sim.pose=[-13.06489598   6.7612708   35.11438362   2.1327792    2.04468489   0.        ]\n",
      "Episode =  657, total_reward =  171.74, , z=  35.59, v_z=   9.25, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79612029 -2.96691477  9.25026489],\n",
      " \t action=[900.04892303078293, 0.1284937581822243, 900.22489817459086, -0.36458360346889518], \n",
      " \t task.sim.pose=[-13.50059263  -5.78927744  35.59387978   2.06357645   2.15482543   0.        ]\n",
      "Episode =  658, total_reward =  171.18, , z=  35.42, v_z=   9.21, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74148002  1.90921135  9.21169032],\n",
      " \t action=[900.38025125634113, -0.10808705303630742, 900.49157199925105, -0.16530265982875231], \n",
      " \t task.sim.pose=[-13.34367403   4.60773061  35.41646717   2.10609611   2.07690717   0.        ]\n",
      "Episode =  659, total_reward =  171.05, , z=  35.25, v_z=   9.03, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.70842388  3.61170707  9.03295259],\n",
      " \t action=[899.34398940645838, -0.44529388454651331, 899.88038679843532, -0.067299521632824266], \n",
      " \t task.sim.pose=[-13.17157629   6.85091834  35.24912524   2.16553056   2.05835488   0.        ]\n",
      "Episode =  660, total_reward =  171.88, , z=  35.67, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.89993576 -2.98439268  9.35140359],\n",
      " \t action=[899.97902796491326, 0.41198894050782831, 900.67374942358845, 0.167089192929607], \n",
      " \t task.sim.pose=[-13.8078686   -9.86227562  35.67212205   2.11487845   2.14012836   0.        ]\n",
      "Episode =  661, total_reward =  172.42, , z=  35.78, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87971588 -3.14554158  9.34237027],\n",
      " \t action=[900.30595224082469, -0.041672647247030056, 900.18349855455051, -0.0075652109690321698], \n",
      " \t task.sim.pose=[-13.74718918  -9.23812368  35.77960537   2.09543168   2.13888535   0.        ]\n",
      "Episode =  662, total_reward =  171.40, , z=  35.54, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75416712  0.37319882  9.29239633],\n",
      " \t action=[899.79435611526139, -0.44914699907925026, 899.82028012969658, -0.55167643627271923], \n",
      " \t task.sim.pose=[-13.40119661   1.16722595  35.54418445   2.12843021   2.11973092   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  663, total_reward =  170.74, , z=  35.16, v_z=   9.06, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.69958623  3.40134243  9.06019916],\n",
      " \t action=[899.80125055219241, 0.32900190380356509, 900.23232222931676, -0.1295570792866938], \n",
      " \t task.sim.pose=[-13.21558101   7.70729891  35.16342164   2.16516749   2.07837145   0.        ]\n",
      "Episode =  664, total_reward =  170.99, , z=  35.32, v_z=   9.13, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.92717966 -5.28791688  9.12932169],\n",
      " \t action=[899.6836659900224, -0.4948494492610499, 899.26699405311081, 0.014109889979214862], \n",
      " \t task.sim.pose=[-13.84592014 -13.94660483  35.3159655    2.06359731   2.14776408   0.        ]\n",
      "Episode =  665, total_reward =  171.79, , z=  35.65, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82959507 -1.8248326   9.33596493],\n",
      " \t action=[899.67862027431784, 1.1064905707851322, 899.58548483423817, -0.066790389365400743], \n",
      " \t task.sim.pose=[-13.63311704  -5.09931534  35.64865827   2.12637863   2.14336671   0.        ]\n",
      "Episode =  666, total_reward =  171.29, , z=  35.56, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79210676 -0.32853179  9.32873143],\n",
      " \t action=[900.33578343762429, 0.26622444693345948, 900.10532974507032, -0.24350241031816527], \n",
      " \t task.sim.pose=[-13.44070934  -1.78910067  35.56165351   2.13549759   2.10582912   0.        ]\n",
      "Episode =  667, total_reward =  171.06, , z=  35.51, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82005469 -2.26219221  9.31088811],\n",
      " \t action=[899.72611829065795, -0.36310057030403031, 899.60581156087528, 0.72353340502454166], \n",
      " \t task.sim.pose=[-13.44833547  -5.39291874  35.51392593   2.0705823    2.09991078   0.        ]\n",
      "Episode =  668, total_reward =  170.96, , z=  35.52, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86057759 -2.16616963  9.35007249],\n",
      " \t action=[900.3075737902069, 0.019784839801444971, 900.5167627688711, 0.62793275563773754], \n",
      " \t task.sim.pose=[-13.56648415  -7.02707814  35.51830782   2.0771542    2.09262234   0.        ]\n",
      "Episode =  669, total_reward =  170.49, , z=  35.36, v_z=   9.26, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77662266  1.14260907  9.2638793 ],\n",
      " \t action=[900.82575350814307, 0.27756262063856735, 899.63315321115977, 0.52528851334583504], \n",
      " \t task.sim.pose=[-13.31764911   1.87663549  35.36278073   2.10319294   2.05093119   0.        ]\n",
      "Episode =  670, total_reward =  170.37, , z=  35.17, v_z=   9.13, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.694021    2.4806821   9.13184994],\n",
      " \t action=[899.82518831112554, 0.077992120296747541, 900.23745076805255, 0.21523345086314122], \n",
      " \t task.sim.pose=[-13.21261778   5.92312759  35.1704909    2.15903792   2.10915751   0.        ]\n",
      "Episode =  671, total_reward =  171.29, , z=  35.52, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85664899 -3.24257651  9.29254888],\n",
      " \t action=[900.3370644791305, 0.32783898740703732, 899.60703306690004, 0.21144352691259027], \n",
      " \t task.sim.pose=[-13.57793692  -8.73629427  35.51641243   2.09122317   2.12645694   0.        ]\n",
      "Episode =  672, total_reward =  170.73, , z=  35.03, v_z=   8.89, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.69552662  4.6443977   8.89141003],\n",
      " \t action=[900.06731896991187, 0.19086607404449027, 900.33357906860113, 0.37060470166405318], \n",
      " \t task.sim.pose=[-13.18031589   9.57675244  35.02635657   2.16727975   2.04188297   0.        ]\n",
      "Episode =  673, total_reward =  170.70, , z=  35.42, v_z=   9.27, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81987299 -2.56480596  9.27434446],\n",
      " \t action=[900.11591421528829, 0.47410784637673398, 899.86943076389821, -0.31252688048473687], \n",
      " \t task.sim.pose=[-13.47651916  -5.49314687  35.4152587    2.05238558   2.10670545   0.        ]\n",
      "Episode =  674, total_reward =  170.73, , z=  35.45, v_z=   9.32, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77900859 -0.25583675  9.31524236],\n",
      " \t action=[899.96427904440975, -0.001879853726670766, 899.427817848259, 0.013498601409333601], \n",
      " \t task.sim.pose=[-13.32719176  -0.81733616  35.4544899    2.09473381   2.0828105    0.        ]\n",
      "Episode =  675, total_reward =  170.84, , z=  35.46, v_z=   9.28, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79923415 -2.38750143  9.28030591],\n",
      " \t action=[899.78710890546256, -0.06332006082239755, 900.23981923463964, -0.30314177680056043], \n",
      " \t task.sim.pose=[-13.42558151  -5.30964692  35.45804826   2.05554256   2.12295288   0.        ]\n",
      "Episode =  676, total_reward =  171.22, , z=  35.45, v_z=   9.21, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87624708 -4.24129553  9.21313616],\n",
      " \t action=[899.57415582454519, -0.19558171646179429, 899.75693402596823, -0.49091661494980177], \n",
      " \t task.sim.pose=[-13.69074507 -11.01214304  35.44889655   2.08161549   2.15559042   0.        ]\n",
      "Episode =  677, total_reward =  172.48, , z=  35.79, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80070254  0.65209505  9.33274058],\n",
      " \t action=[900.23769934794905, 0.42763472345134024, 899.18346228127734, 0.050170099594709111], \n",
      " \t task.sim.pose=[-13.5566219   -0.44247882  35.79306178   2.16474883   2.10768266   0.        ]\n",
      "Episode =  678, total_reward =  170.94, , z=  35.51, v_z=   9.34, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83121567 -1.49481719  9.33985247],\n",
      " \t action=[900.15813779686664, -0.42241645521202853, 899.53420402585425, 0.10028155740961897], \n",
      " \t task.sim.pose=[-13.47569394  -4.10397886  35.50868563   2.08160757   2.07880083   0.        ]\n",
      "Episode =  679, total_reward =  171.52, , z=  35.57, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75923917  0.39719594  9.29652871],\n",
      " \t action=[899.89894997091562, -0.10793584687955927, 900.37751423727514, -0.52351459100353748], \n",
      " \t task.sim.pose=[-13.44063489   0.57417294  35.56524923   2.13209898   2.12901603   0.        ]\n",
      "Episode =  680, total_reward =  170.78, , z=  35.48, v_z=   9.33, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81816554 -0.60540167  9.33489255],\n",
      " \t action=[899.81161554091511, -0.39398242991926963, 899.84635919278219, -0.40294739757897768], \n",
      " \t task.sim.pose=[-13.45484342  -2.65409483  35.48468738   2.08953294   2.07863525   0.        ]\n",
      "Episode =  681, total_reward =  172.05, , z=  35.69, v_z=   9.30, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83254649 -2.88334228  9.29735576],\n",
      " \t action=[899.41758670832166, -0.63491413107254802, 899.46115418269335, 0.098660104291193401], \n",
      " \t task.sim.pose=[-13.62942994  -7.26668083  35.68772268   2.10335531   2.16016785   0.        ]\n",
      "Episode =  682, total_reward =  170.97, , z=  35.50, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86324856 -2.60891871  9.31811601],\n",
      " \t action=[900.17679696399523, -0.08851702150269164, 899.39617039089694, -0.082116738882405726], \n",
      " \t task.sim.pose=[-13.62759903  -7.62588736  35.49970509   2.08405305   2.11360445   0.        ]\n",
      "Episode =  683, total_reward =  171.54, , z=  35.57, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85139623 -3.33695999  9.28578105],\n",
      " \t action=[899.83007740279129, -0.2044608954130292, 900.52848054699768, -0.60306978956645718], \n",
      " \t task.sim.pose=[-13.59415525  -8.25865784  35.57077241   2.05576953   2.12060875   0.        ]\n",
      "Episode =  684, total_reward =  171.27, , z=  35.60, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81700138 -1.62674312  9.34584212],\n",
      " \t action=[899.81165256675672, 0.33549263712076804, 900.28489483412079, -0.093098707609925391], \n",
      " \t task.sim.pose=[-13.43129089  -5.06650434  35.59685074   2.07520471   2.0965363    0.        ]\n",
      "Episode =  685, total_reward =  171.58, , z=  35.65, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82869955 -0.35729412  9.35634275],\n",
      " \t action=[900.28733270305031, 0.1837710060914394, 900.2866373071505, -0.2187619236224147], \n",
      " \t task.sim.pose=[-13.57642203  -2.09952346  35.65436672   2.08925851   2.08153758   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  686, total_reward =  171.61, , z=  35.63, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7798052  -0.08737168  9.33376923],\n",
      " \t action=[899.9255059543375, -0.11610235700438321, 900.01060521865645, 0.41942230186318602], \n",
      " \t task.sim.pose=[-13.40523038  -0.92278207  35.63227135   2.10596044   2.10081267   0.        ]\n",
      "Episode =  687, total_reward =  170.66, , z=  35.45, v_z=   9.34, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8710116 -2.1857294  9.3395983],\n",
      " \t action=[899.78180775222654, -0.34904760644343524, 899.50284379176992, -0.4441654718896656], \n",
      " \t task.sim.pose=[-13.56501201  -7.77520392  35.45179257   2.09679838   2.09262262   0.        ]\n",
      "Episode =  688, total_reward =  171.42, , z=  35.60, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80185067 -1.1929709   9.34425035],\n",
      " \t action=[899.63742034832683, 0.26224923553955448, 899.77796680288463, -0.050314042459748368], \n",
      " \t task.sim.pose=[-13.4522626   -4.20602179  35.60105116   2.12237928   2.12516625   0.        ]\n",
      "Episode =  689, total_reward =  170.88, , z=  35.43, v_z=   9.26, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79712158  1.35666071  9.25975919],\n",
      " \t action=[900.27396423810637, 0.054305277953378001, 900.14344512644595, -0.0049009367007483151], \n",
      " \t task.sim.pose=[-13.46776986   1.12862351  35.43028285   2.13537808   2.06958094   0.        ]\n",
      "Episode =  690, total_reward =  170.88, , z=  35.50, v_z=   9.33, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83624914 -1.79328964  9.32872406],\n",
      " \t action=[900.06542377594201, -0.56065785718778416, 900.32213755960072, 0.11894027927466697], \n",
      " \t task.sim.pose=[-13.50099147  -5.45892155  35.50300001   2.0761375    2.09051897   0.        ]\n",
      "Episode =  691, total_reward =  171.44, , z=  35.60, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79081607  0.37195465  9.32118427],\n",
      " \t action=[900.09492396714381, -0.13367189733128015, 899.95685392088456, -0.66096071077057961], \n",
      " \t task.sim.pose=[-13.43830498  -0.14842024  35.59570899   2.11446257   2.08255742   0.        ]\n",
      "Episode =  692, total_reward =  171.54, , z=  35.48, v_z=   9.18, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87254859 -4.47914489  9.17619607],\n",
      " \t action=[899.58188580794092, -0.17945406494447019, 899.65165701664944, -0.10935694474799318], \n",
      " \t task.sim.pose=[-13.77983319 -11.11329156  35.47773171   2.09308635   2.18705772   0.        ]\n",
      "Episode =  693, total_reward =  170.61, , z=  35.35, v_z=   9.24, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75589666  1.41108123  9.23865459],\n",
      " \t action=[900.63492776544115, -0.31751473845591993, 900.02252615874158, -0.25827953683115523], \n",
      " \t task.sim.pose=[-13.25359575   2.42997158  35.35295964   2.12724513   2.06159172   0.        ]\n",
      "Episode =  694, total_reward =  171.62, , z=  35.57, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77016299  1.3430395   9.28502872],\n",
      " \t action=[900.46038759698286, -0.024949625987932655, 900.53448066839155, -0.11864611195151986], \n",
      " \t task.sim.pose=[-13.36759865   2.00569044  35.57057632   2.10897669   2.06584269   0.        ]\n",
      "Episode =  695, total_reward =  171.39, , z=  35.59, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79489409 -0.92279432  9.3320777 ],\n",
      " \t action=[900.16881592466166, -0.86634346831857556, 900.05579249524033, 0.18381641538887317], \n",
      " \t task.sim.pose=[-13.45329275  -2.24991461  35.58992509   2.07807213   2.10430192   0.        ]\n",
      "Episode =  696, total_reward =  171.49, , z=  35.58, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83635999 -2.92627391  9.30457276],\n",
      " \t action=[899.90164033091253, 0.092229226566811262, 900.68276947537117, -0.042760297851286724], \n",
      " \t task.sim.pose=[-13.56281956  -7.8282069   35.57562908   2.08523416   2.14077646   0.        ]\n",
      "Episode =  697, total_reward =  172.24, , z=  35.79, v_z=   9.39, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85229915 -1.3205897   9.39057671],\n",
      " \t action=[899.8006399238169, 0.2375012211897454, 899.61458027075435, -0.95128026422178369], \n",
      " \t task.sim.pose=[-13.66165101  -5.65294296  35.79220189   2.13198871   2.121158     0.        ]\n",
      "Episode =  698, total_reward =  170.83, , z=  35.46, v_z=   9.31, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75436057 -0.27904272  9.31199856],\n",
      " \t action=[900.40495439831511, -0.050801003065702843, 900.37731888229382, -0.89091356080287576], \n",
      " \t task.sim.pose=[-13.22091782   0.27006281  35.46013524   2.06370427   2.07128439   0.        ]\n",
      "Episode =  699, total_reward =  172.00, , z=  35.72, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80720668 -1.29979992  9.36201417],\n",
      " \t action=[900.26823044160949, 0.20626840438531754, 899.82285398672252, -0.42645702248242867], \n",
      " \t task.sim.pose=[-13.48983683  -4.4471407   35.71722609   2.12341859   2.12814212   0.        ]\n",
      "Episode =  700, total_reward =  171.16, , z=  35.54, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85083285 -2.54240477  9.32641282],\n",
      " \t action=[899.45774095389743, 0.20522700785870446, 900.47458124421701, 0.67516999533880984], \n",
      " \t task.sim.pose=[-13.56063915  -7.46760672  35.53705473   2.08736666   2.11551362   0.        ]\n",
      "Episode =  701, total_reward =  170.79, , z=  35.50, v_z=   9.34, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8128811  -0.89268064  9.3415954 ],\n",
      " \t action=[900.43510966128383, 0.22068390972412788, 900.34486201719653, -0.89997251066225048], \n",
      " \t task.sim.pose=[-13.3700506   -2.4554736   35.50034895   2.04678622   2.04950061   0.        ]\n",
      "Episode =  702, total_reward =  172.08, , z=  35.74, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82516635 -1.3002502   9.369653  ],\n",
      " \t action=[899.59420845229999, 0.38741940661087165, 900.11905453006261, 0.022635579067555041], \n",
      " \t task.sim.pose=[-13.57364838  -4.63727945  35.74049496   2.1338834    2.1289144    0.        ]\n",
      "Episode =  703, total_reward =  171.99, , z=  35.71, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83604349 -2.06742899  9.36229194],\n",
      " \t action=[899.47501749638798, 0.027786874206888267, 900.10541537862582, -0.037632758561175983], \n",
      " \t task.sim.pose=[-13.56374561  -6.64033995  35.71433252   2.12348274   2.13151841   0.        ]\n",
      "Episode =  704, total_reward =  171.81, , z=  35.67, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78115146 -0.74089899  9.32934906],\n",
      " \t action=[899.40634863608318, 0.39593611849472177, 899.08164627912288, 0.42487014848929466], \n",
      " \t task.sim.pose=[-13.45009187  -2.19773525  35.6672682    2.12452037   2.13090225   0.        ]\n",
      "Episode =  705, total_reward =  171.54, , z=  35.62, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79742113 -1.39935501  9.33313336],\n",
      " \t action=[899.64606878041354, 0.23793837567302176, 899.63875011799246, -0.21820691161230213], \n",
      " \t task.sim.pose=[-13.43676157  -2.87415156  35.61905145   2.06491744   2.10130023   0.        ]\n",
      "Episode =  706, total_reward =  171.32, , z=  35.59, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84181113 -1.16290924  9.34943289],\n",
      " \t action=[899.4935618409188, -0.096685473682338902, 899.9917826313764, -0.20831391091940799], \n",
      " \t task.sim.pose=[-13.63011118  -5.2764407   35.59409993   2.12430307   2.12539163   0.        ]\n",
      "Episode =  707, total_reward =  169.53, , z=  35.00, v_z=   9.11, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.70514958  2.56998253  9.10521389],\n",
      " \t action=[900.13788274904596, -0.5465361926169201, 899.70703594846793, -0.24632998114115773], \n",
      " \t task.sim.pose=[-13.21033883   6.37878738  34.99847534   2.13866436   2.0857591    0.        ]\n",
      "Episode =  708, total_reward =  171.57, , z=  35.64, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8003955  -0.4044262   9.34916712],\n",
      " \t action=[900.90756048420212, -0.37666306474250943, 899.99733554375848, 0.64154006480246251], \n",
      " \t task.sim.pose=[-13.4541242   -2.12937913  35.63882361   2.1037294    2.09465071   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  709, total_reward =  170.89, , z=  35.39, v_z=   9.24, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73751947  1.40841729  9.24263804],\n",
      " \t action=[900.69113618461961, -0.63826529651390129, 899.51187812028809, 0.37303554020050667], \n",
      " \t task.sim.pose=[-13.27151856   3.32362462  35.39343216   2.12915668   2.08189089   0.        ]\n",
      "Episode =  710, total_reward =  171.39, , z=  35.58, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78739057 -0.5718187   9.33477027],\n",
      " \t action=[899.93768201319813, -0.043820879734346528, 899.66117933609769, -0.49949789767346886], \n",
      " \t task.sim.pose=[-13.43166131  -2.6988889   35.58357969   2.14140373   2.12424967   0.        ]\n",
      "Episode =  711, total_reward =  171.19, , z=  35.52, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77433873  0.7853812   9.29712312],\n",
      " \t action=[900.09721960205263, 0.072609902465842896, 899.71046665096981, -0.10613504596701939], \n",
      " \t task.sim.pose=[-13.33658142   0.99317912  35.51555368   2.11414287   2.06916882   0.        ]\n",
      "Episode =  712, total_reward =  170.90, , z=  35.49, v_z=   9.33, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84582938 -2.36206082  9.32693716],\n",
      " \t action=[899.87829764672233, -0.2963752506641667, 900.09537124999997, 0.39869434107212165], \n",
      " \t task.sim.pose=[-13.51638984  -6.61033369  35.49422941   2.06390774   2.09526783   0.        ]\n",
      "Episode =  713, total_reward =  170.41, , z=  35.36, v_z=   9.27, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85864304 -3.2105404   9.26620064],\n",
      " \t action=[900.00793846827207, 1.4023787726373689, 899.97064889471142, -0.023731966872439517], \n",
      " \t task.sim.pose=[-13.53841589  -7.76202512  35.3602747    2.0210289    2.0832534    0.        ]\n",
      "Episode =  714, total_reward =  171.84, , z=  35.70, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80733242 -0.47135037  9.36587319],\n",
      " \t action=[900.37372248831264, -0.056021456006934589, 899.72607122088459, -0.10373779014733878], \n",
      " \t task.sim.pose=[-13.47658443  -2.13951158  35.70460535   2.09418384   2.08903443   0.        ]\n",
      "Episode =  715, total_reward =  171.86, , z=  35.65, v_z=   9.31, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78665304  0.77321562  9.31121253],\n",
      " \t action=[899.99386198930392, 0.4422425746969097, 899.76743456634642, 0.11622596956078757], \n",
      " \t task.sim.pose=[-13.47333619   0.70123684  35.65331468   2.13121855   2.09090654   0.        ]\n",
      "Episode =  716, total_reward =  171.63, , z=  35.57, v_z=   9.26, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78323577  1.45256958  9.26431279],\n",
      " \t action=[900.53060530433152, 0.12681940539024444, 899.19840747554315, -0.034554140859738958], \n",
      " \t task.sim.pose=[-13.43931465   2.19387581  35.57029871   2.1311569    2.06740799   0.        ]\n",
      "Episode =  717, total_reward =  170.91, , z=  35.40, v_z=   9.24, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75187634  1.46200324  9.23582961],\n",
      " \t action=[899.73481130435869, 0.19727394655754085, 899.84620141376661, 0.43004930779220929], \n",
      " \t task.sim.pose=[-13.33100578   2.95386673  35.39867599   2.1113147    2.0773023    0.        ]\n",
      "Episode =  718, total_reward =  171.07, , z=  35.53, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83401176 -2.12382314  9.33410765],\n",
      " \t action=[900.14571966654182, 0.017706325745229207, 900.30693569812729, -0.77927923047078029], \n",
      " \t task.sim.pose=[-13.49813013  -6.24119447  35.53167951   2.07937095   2.10476077   0.        ]\n",
      "Episode =  719, total_reward =  172.37, , z=  35.67, v_z=   9.26, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72638944  1.50806481  9.25985043],\n",
      " \t action=[900.35049231649509, -0.15676883548449694, 900.58372766086745, 0.036537127579949862], \n",
      " \t task.sim.pose=[-13.36476519   3.32392791  35.67031396   2.15380492   2.12381694   0.        ]\n",
      "Episode =  720, total_reward =  169.99, , z=  35.26, v_z=   9.21, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8457353  -3.80849454  9.20919103],\n",
      " \t action=[899.73984194652326, -0.5118160808959975, 900.67750535491757, 0.11327017639527449], \n",
      " \t task.sim.pose=[-13.46734881  -9.05223757  35.25711297   2.00093403   2.1014412    0.        ]\n",
      "Episode =  721, total_reward =  171.35, , z=  35.56, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76875448 -0.58800177  9.31097289],\n",
      " \t action=[900.08535040003824, -0.46808578642752652, 901.09475639718335, 0.10203135195788643], \n",
      " \t task.sim.pose=[-13.42972929  -0.97978172  35.55706632   2.10657459   2.12652479   0.        ]\n",
      "Episode =  722, total_reward =  172.29, , z=  35.76, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77806558 -0.76130667  9.34555843],\n",
      " \t action=[899.64189973453836, 0.7903089621118069, 899.77703851073704, 0.16604923994958901], \n",
      " \t task.sim.pose=[-13.47041823  -1.20748836  35.75930584   2.10603039   2.12563627   0.        ]\n",
      "Episode =  723, total_reward =  171.12, , z=  35.54, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82229666 -1.28193528  9.32725154],\n",
      " \t action=[899.63902209801176, -0.069644836684043226, 900.21511596480957, -0.13870526967656793], \n",
      " \t task.sim.pose=[-13.5538231   -3.64934678  35.5374898    2.10219028   2.11460578   0.        ]\n",
      "Episode =  724, total_reward =  170.15, , z=  34.98, v_z=   8.98, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.67161624  3.86290784  8.97917957],\n",
      " \t action=[899.64940753370115, -0.59739689199266621, 899.51697668813756, 0.70653970623500406], \n",
      " \t task.sim.pose=[-13.09363112   9.01272308  34.97947023   2.16373189   2.07107785   0.        ]\n",
      "Episode =  725, total_reward =  171.29, , z=  35.56, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82283893 -2.56150285  9.31377236],\n",
      " \t action=[899.73830920361331, -0.098402883523499685, 899.82283025254878, 0.13286924124807001], \n",
      " \t task.sim.pose=[-13.4226249   -6.7738447   35.55585405   2.0769864    2.10738021   0.        ]\n",
      "Episode =  726, total_reward =  169.88, , z=  35.24, v_z=   9.26, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.91762844 -3.65747101  9.26414798],\n",
      " \t action=[900.25421504072301, 0.027804958355796494, 900.0225176161789, -0.404262611971616], \n",
      " \t task.sim.pose=[-13.68725604 -10.67765194  35.24122283   2.04093878   2.08056619   0.        ]\n",
      "Episode =  727, total_reward =  171.37, , z=  35.53, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7990007   1.03145511  9.28131848],\n",
      " \t action=[900.73985383839749, 0.49608223104247562, 900.08566718526538, -0.045074974274937327], \n",
      " \t task.sim.pose=[-13.48601089   0.22956964  35.53321646   2.14516929   2.07967348   0.        ]\n",
      "Episode =  728, total_reward =  171.87, , z=  35.67, v_z=   9.29, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80509943 -2.60685373  9.29382406],\n",
      " \t action=[899.02949235705296, 0.46839184127916467, 900.12379251407845, 0.49450750621667494], \n",
      " \t task.sim.pose=[-13.49212959  -5.6121926   35.66903777   2.05486641   2.132757     0.        ]\n",
      "Episode =  729, total_reward =  171.22, , z=  35.55, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79234929 -0.59787269  9.33025814],\n",
      " \t action=[899.96392211603222, -0.55615452120309539, 899.76602882341331, -0.69281938886449224], \n",
      " \t task.sim.pose=[-13.43012948  -2.13749678  35.55384965   2.11301774   2.10383363   0.        ]\n",
      "Episode =  730, total_reward =  170.49, , z=  35.42, v_z=   9.33, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85032947 -1.86786184  9.32922015],\n",
      " \t action=[900.14986923063066, 0.65848517421534991, 900.25460185937561, 0.013488682953313291], \n",
      " \t task.sim.pose=[-13.49697855  -5.62866848  35.42110122   2.06191116   2.07389043   0.        ]\n",
      "Episode =  731, total_reward =  170.60, , z=  35.25, v_z=   9.17, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.71938544  2.16429247  9.16635141],\n",
      " \t action=[899.62952990933081, 0.072495791767705667, 899.70179338566913, -0.12796208925968242], \n",
      " \t task.sim.pose=[-13.26221266   5.51359228  35.25299672   2.12874683   2.08350959   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  732, total_reward =  170.41, , z=  35.18, v_z=   9.13, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.70808688  2.64085696  9.12971541],\n",
      " \t action=[900.1262554128308, 0.3953926144615646, 900.04614925076953, 0.5535747819649911], \n",
      " \t task.sim.pose=[-13.17603491   6.17150425  35.18452921   2.11668519   2.06737999   0.        ]\n",
      "Episode =  733, total_reward =  171.69, , z=  35.69, v_z=   9.37, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84688018 -1.73880664  9.36718037],\n",
      " \t action=[899.98936066065255, 0.18580520658059638, 900.26920029321332, 0.047774244687191103], \n",
      " \t task.sim.pose=[-13.53480774  -5.33840332  35.68872971   2.06171201   2.07955355   0.        ]\n",
      "Episode =  734, total_reward =  170.47, , z=  35.42, v_z=   9.33, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78734273 -0.5541152   9.32619071],\n",
      " \t action=[900.02339816296694, -0.2775246238592608, 899.82210583634685, 0.099857729781511279], \n",
      " \t task.sim.pose=[-13.26167103  -2.52645431  35.42400207   2.09166355   2.06681416   0.        ]\n",
      "Episode =  735, total_reward =  170.98, , z=  35.53, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81342559 -0.9227227   9.33735334],\n",
      " \t action=[900.08782250923355, -0.42614443382390754, 899.80905917227369, -0.16218337770865227], \n",
      " \t task.sim.pose=[-13.42298078  -3.31685878  35.53090089   2.08676228   2.08211412   0.        ]\n",
      "Episode =  736, total_reward =  171.52, , z=  35.64, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83498143 -1.42155708  9.35172138],\n",
      " \t action=[899.34167257566048, -0.23988347300302112, 899.68155252638178, -0.16901838050422613], \n",
      " \t task.sim.pose=[-13.54995097  -4.43800195  35.64137423   2.09007363   2.09629339   0.        ]\n",
      "Episode =  737, total_reward =  171.94, , z=  35.72, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80455304 -1.77588909  9.34307399],\n",
      " \t action=[900.55593883645702, -0.04413616908933736, 899.42188399089196, -0.35920948120351143], \n",
      " \t task.sim.pose=[-13.44762985  -4.14635104  35.71828404   2.06719474   2.10036152   0.        ]\n",
      "Episode =  738, total_reward =  171.20, , z=  35.57, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79961065 -0.27325124  9.34284324],\n",
      " \t action=[900.60043280228228, -0.32408158556085898, 900.31152700228461, 0.17986326282091047], \n",
      " \t task.sim.pose=[-13.40412833  -1.34173148  35.56991192   2.06441843   2.06789043   0.        ]\n",
      "Episode =  739, total_reward =  170.66, , z=  35.35, v_z=   9.21, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76276234  1.78617551  9.2137884 ],\n",
      " \t action=[899.78863157902492, 0.31380937563634914, 900.29342673251745, 0.02855517705424946], \n",
      " \t task.sim.pose=[-13.35757541   2.7446544   35.34504467   2.131118     2.07380436   0.        ]\n",
      "Episode =  740, total_reward =  169.34, , z=  35.06, v_z=   9.18, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.92356682 -4.73725603  9.1805383 ],\n",
      " \t action=[900.49209018557133, 0.47601224010465126, 900.43536914053561, 0.22622156780706176], \n",
      " \t task.sim.pose=[-13.66766016 -13.46957264  35.06439763   2.03101443   2.09725848   0.        ]\n",
      "Episode =  741, total_reward =  171.09, , z=  35.50, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86877509 -2.7517099   9.30979828],\n",
      " \t action=[900.17043588587489, -0.68925930564862492, 899.46750251894116, -0.029845409527929745], \n",
      " \t task.sim.pose=[-13.66140028  -7.57986535  35.50411705   2.08374899   2.11779429   0.        ]\n",
      "Episode =  742, total_reward =  172.04, , z=  35.70, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82165878 -2.4798096   9.33371484],\n",
      " \t action=[900.50144698071153, 0.24195545266531893, 900.00545103974321, 0.24134340831643275], \n",
      " \t task.sim.pose=[-13.57381781  -7.13650332  35.69968628   2.12927463   2.16198503   0.        ]\n",
      "Episode =  743, total_reward =  171.59, , z=  35.65, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79592783 -0.18271511  9.34765729],\n",
      " \t action=[899.54484032566825, 0.19387846713424592, 900.0834127573786, -0.46563194965849292], \n",
      " \t task.sim.pose=[-13.39711987  -1.73806868  35.64712182   2.1044764    2.08555666   0.        ]\n",
      "Episode =  744, total_reward =  170.10, , z=  35.18, v_z=   9.13, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88028853 -4.76701697  9.12821158],\n",
      " \t action=[899.44116006772447, -0.33303720895740152, 899.89467047082212, -0.19626228840442234], \n",
      " \t task.sim.pose=[-13.66794237 -11.90238434  35.17959807   2.04881188   2.14965572   0.        ]\n",
      "Episode =  745, total_reward =  170.53, , z=  35.38, v_z=   9.27, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78099277  1.09771563  9.26945296],\n",
      " \t action=[899.87191322454873, 0.095722991308277883, 899.40589320893832, -0.50393653895033186], \n",
      " \t task.sim.pose=[-13.29663656   1.75033654  35.38178983   2.08007348   2.03581378   0.        ]\n",
      "Episode =  746, total_reward =  172.17, , z=  35.69, v_z=   9.29, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76300649  1.47844234  9.28573482],\n",
      " \t action=[900.06236630035539, -0.10779524195615098, 900.00540990051729, -0.4646596752171962], \n",
      " \t task.sim.pose=[-13.34756608   2.03198482  35.68994823   2.14181308   2.07793011   0.        ]\n",
      "Episode =  747, total_reward =  171.57, , z=  35.64, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85357242 -1.95294054  9.36144633],\n",
      " \t action=[900.13776446885106, -0.053460602687205899, 900.81000535225814, 0.26956121783564507], \n",
      " \t task.sim.pose=[-13.61905865  -6.246186    35.63748125   2.09332815   2.11196764   0.        ]\n",
      "Episode =  748, total_reward =  171.55, , z=  35.62, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78779805 -0.38931064  9.34451376],\n",
      " \t action=[900.29978048309727, 0.15837568217351236, 900.02808283539662, 0.17125909432355985], \n",
      " \t task.sim.pose=[-13.42638848  -1.75058823  35.62415957   2.1089102    2.10172622   0.        ]\n",
      "Episode =  749, total_reward =  170.65, , z=  35.44, v_z=   9.31, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84420728 -1.91573102  9.31310907],\n",
      " \t action=[899.64650966263366, 0.52861314259506686, 899.90898389821803, 0.94584074386257488], \n",
      " \t task.sim.pose=[-13.59882283  -5.65229411  35.44060682   2.08658047   2.11427157   0.        ]\n",
      "Episode =  750, total_reward =  171.75, , z=  35.65, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79381928  0.22266905  9.34107074],\n",
      " \t action=[900.5694535355658, -0.9208113924451472, 900.94388854583747, 0.21869533098470115], \n",
      " \t task.sim.pose=[-13.47557453  -0.74598216  35.6544784    2.11305799   2.0976522    0.        ]\n",
      "Episode =  751, total_reward =  170.32, , z=  35.13, v_z=   9.08, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.71186258  3.11535451  9.07929504],\n",
      " \t action=[899.61520529903032, 0.30833245255103392, 899.8610166134963, 0.13105208778497437], \n",
      " \t task.sim.pose=[-13.19084351   6.9054859   35.13388618   2.14476859   2.05678086   0.        ]\n",
      "Episode =  752, total_reward =  170.88, , z=  35.45, v_z=   9.29, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7459607   0.43266316  9.29136222],\n",
      " \t action=[900.12677812721483, -0.69710983868128373, 900.36317529980056, -0.33877746472700698], \n",
      " \t task.sim.pose=[-13.24177676   1.13172808  35.44852187   2.08994425   2.08544924   0.        ]\n",
      "Episode =  753, total_reward =  171.10, , z=  35.55, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8034176  -0.39379867  9.32643548],\n",
      " \t action=[899.45724920762177, -0.30223123071861213, 900.2863481318808, 0.24676530611064365], \n",
      " \t task.sim.pose=[-13.462531    -2.34276861  35.54544611   2.08961937   2.09463741   0.        ]\n",
      "Episode =  754, total_reward =  171.38, , z=  35.61, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8067118  -0.30523551  9.35258779],\n",
      " \t action=[900.22086130365074, 0.19061488629630446, 900.12524817390749, -0.16644739326415095], \n",
      " \t task.sim.pose=[-13.43198306  -2.84683374  35.60600789   2.11419403   2.09220192   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  755, total_reward =  171.46, , z=  35.60, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87219818 -2.65322158  9.3545146 ],\n",
      " \t action=[899.77334950224508, 0.61645705999925471, 900.5479057683242, 0.4458544036373614], \n",
      " \t task.sim.pose=[-13.60632213  -8.85393148  35.59986583   2.09229842   2.10996396   0.        ]\n",
      "Episode =  756, total_reward =  171.96, , z=  35.58, v_z=   9.23, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7563195   2.20814803  9.22860661],\n",
      " \t action=[900.08150818072841, -0.15277619321943892, 900.06963475371617, 0.42015251823540561], \n",
      " \t task.sim.pose=[-13.37591847   3.790994    35.58167906   2.13660531   2.06925019   0.        ]\n",
      "Episode =  757, total_reward =  171.83, , z=  35.69, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80571966 -1.67852046  9.34893993],\n",
      " \t action=[900.07223206264837, 0.7595271169863147, 900.1594112291873, -0.31306543058043018], \n",
      " \t task.sim.pose=[-13.45023122  -4.76598558  35.68726045   2.0937962    2.11647096   0.        ]\n",
      "Episode =  758, total_reward =  169.91, , z=  35.15, v_z=   9.17, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75417698  2.28020563  9.16634129],\n",
      " \t action=[900.86959746319724, -0.015791818646189448, 899.91147908882795, 0.54407658332720499], \n",
      " \t task.sim.pose=[-13.22711167   4.54352915  35.15497033   2.1031633    2.02799526   0.        ]\n",
      "Episode =  759, total_reward =  171.53, , z=  35.59, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86295278 -3.31112726  9.3046348 ],\n",
      " \t action=[899.68958964353976, 0.069378855557422764, 900.61151831441907, -0.22056950447405252], \n",
      " \t task.sim.pose=[-13.6078789   -9.11397114  35.59050941   2.0697466    2.12368359   0.        ]\n",
      "Episode =  760, total_reward =  170.98, , z=  35.51, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78576437 -1.03596078  9.31206467],\n",
      " \t action=[899.57269387543897, -0.081229760359942255, 899.56863268752636, 0.38367807630543632], \n",
      " \t task.sim.pose=[-13.412646    -2.45711804  35.51073397   2.07756012   2.11253032   0.        ]\n",
      "Episode =  761, total_reward =  169.60, , z=  35.10, v_z=   9.19, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72440834  1.6457407   9.19056144],\n",
      " \t action=[900.55417354171141, -0.14773946862520759, 900.36701059375821, -0.060773781536551871], \n",
      " \t task.sim.pose=[-13.15751709   4.5925737   35.09999039   2.0856375    2.05720915   0.        ]\n",
      "Episode =  762, total_reward =  172.68, , z=  35.74, v_z=   9.25, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73334877  1.80667054  9.25429407],\n",
      " \t action=[899.69883425072965, -0.77350911663046928, 900.62212312230736, -0.071309986113001433], \n",
      " \t task.sim.pose=[-13.38614322   2.83274803  35.74332299   2.20151363   2.13046043   0.        ]\n",
      "Episode =  763, total_reward =  171.29, , z=  35.51, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87801844 -3.39221135  9.28498657],\n",
      " \t action=[899.47592115073951, -0.28623109358686172, 899.37966000742279, -0.10448989112041951], \n",
      " \t task.sim.pose=[-13.72353871  -9.93330845  35.51468262   2.11063347   2.15287591   0.        ]\n",
      "Episode =  764, total_reward =  171.10, , z=  35.55, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80553008 -0.52827111  9.34711187],\n",
      " \t action=[900.5787090695261, 0.30987378550100758, 900.90513448395927, 0.099625721979906268], \n",
      " \t task.sim.pose=[-13.40676426  -1.67158147  35.5511219    2.0588277    2.0669631    0.        ]\n",
      "Episode =  765, total_reward =  171.89, , z=  35.70, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81408393 -0.45491873  9.35351025],\n",
      " \t action=[899.52093858014905, 0.077040088772353799, 899.5399366605094, -0.11280531320756695], \n",
      " \t task.sim.pose=[-13.55321164  -2.69811224  35.70375951   2.13297971   2.11456218   0.        ]\n",
      "Episode =  766, total_reward =  171.37, , z=  35.60, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88163548 -2.62126841  9.34205821],\n",
      " \t action=[900.04641133809127, -0.29126871725354836, 899.84894991261933, 0.087276055964264299], \n",
      " \t task.sim.pose=[-13.70527206  -8.16914923  35.59986905   2.08713942   2.11500558   0.        ]\n",
      "Episode =  767, total_reward =  171.11, , z=  35.56, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84443973 -2.30673241  9.33716266],\n",
      " \t action=[900.29133401476167, 0.50193320603665847, 899.25682923761269, 1.0634534240447509], \n",
      " \t task.sim.pose=[-13.47381688  -6.31932953  35.55938294   2.04621754   2.07351606   0.        ]\n",
      "Episode =  768, total_reward =  169.82, , z=  35.00, v_z=   9.06, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.69568068  3.14770845  9.05876897],\n",
      " \t action=[899.90559310594801, 0.029710811389713931, 900.34584179080173, -0.076274030327314585], \n",
      " \t task.sim.pose=[-13.14923726   7.48712209  35.00324322   2.1495658    2.07038529   0.        ]\n",
      "Episode =  769, total_reward =  170.48, , z=  35.41, v_z=   9.31, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76778482 -0.44228733  9.30500277],\n",
      " \t action=[900.03615335537404, 0.26433773022923568, 900.36804960839061, -0.27997113909947385], \n",
      " \t task.sim.pose=[-13.25457997  -0.62433321  35.40778219   2.04639243   2.06806456   0.        ]\n",
      "Episode =  770, total_reward =  170.00, , z=  35.13, v_z=   9.11, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7313012   2.83991555  9.11199921],\n",
      " \t action=[899.92460230872143, -0.13758758567889318, 899.86419385274007, -0.50746477148384173], \n",
      " \t task.sim.pose=[-13.14779235   5.48113667  35.13485179   2.12975462   2.0335588    0.        ]\n",
      "Episode =  771, total_reward =  171.33, , z=  35.60, v_z=   9.37, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85242132 -1.69624151  9.36625957],\n",
      " \t action=[900.10859481938257, 0.10949287828704726, 900.60950548003075, 0.60327820562979517], \n",
      " \t task.sim.pose=[-13.57702313  -5.96504627  35.59997466   2.10455843   2.0969984    0.        ]\n",
      "Episode =  772, total_reward =  172.07, , z=  35.76, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82017593 -1.20161263  9.37303573],\n",
      " \t action=[899.97267140866779, 0.19712242538331726, 900.64406215084182, -0.3088240276923776], \n",
      " \t task.sim.pose=[-13.51190933  -4.42232127  35.75806165   2.10196058   2.10906633   0.        ]\n",
      "Episode =  773, total_reward =  171.57, , z=  35.51, v_z=   9.25, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74818251  1.68774185  9.24523431],\n",
      " \t action=[900.06054197215212, 0.53175080451620782, 900.27337856726888, 0.33423238123102772], \n",
      " \t task.sim.pose=[-13.35471844   3.77242594  35.51450519   2.12102699   2.08014411   0.        ]\n",
      "Episode =  774, total_reward =  170.38, , z=  35.37, v_z=   9.29, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75736317 -1.05035338  9.28830296],\n",
      " \t action=[900.22737749153282, 0.50145687591900556, 899.48613933415788, 0.20876609319290462], \n",
      " \t task.sim.pose=[-13.23885136  -1.75635028  35.36651982   2.07560408   2.10354949   0.        ]\n",
      "Episode =  775, total_reward =  171.33, , z=  35.58, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80499191 -1.12212761  9.33431285],\n",
      " \t action=[900.12387004166726, -0.027808753223447683, 899.59010720164599, 0.20030978149401968], \n",
      " \t task.sim.pose=[-13.47868141  -3.14670222  35.57819173   2.09576686   2.10617763   0.        ]\n",
      "Episode =  776, total_reward =  170.38, , z=  35.37, v_z=   9.29, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88213349 -3.08237353  9.29338145],\n",
      " \t action=[899.69104195497755, 0.1294618544125572, 900.51906248388173, -1.0914149079725384], \n",
      " \t task.sim.pose=[-13.65411174  -9.53400664  35.36830864   2.07903204   2.11869648   0.        ]\n",
      "Episode =  777, total_reward =  172.44, , z=  35.77, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75891847  0.58618453  9.33449562],\n",
      " \t action=[900.17484352104702, 0.85466780057490344, 899.87497244467443, -0.11088520927246753], \n",
      " \t task.sim.pose=[-13.36041806   0.41799708  35.77322243   2.14280643   2.10238195   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  778, total_reward =  171.54, , z=  35.61, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78924521 -0.18131471  9.33300785],\n",
      " \t action=[899.76598816034675, 0.26331054141219862, 899.62377865983774, 0.085999514361875085], \n",
      " \t task.sim.pose=[-13.43528218  -1.56318542  35.61410902   2.13990929   2.10899692   0.        ]\n",
      "Episode =  779, total_reward =  171.40, , z=  35.62, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83791182 -0.48560332  9.35673037],\n",
      " \t action=[900.33950253693274, -0.0085154280364520499, 900.31240767682812, -0.36133585354195674], \n",
      " \t task.sim.pose=[-13.57030562  -3.51004717  35.61745412   2.11815494   2.08901551   0.        ]\n",
      "Episode =  780, total_reward =  170.83, , z=  35.48, v_z=   9.32, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86834567 -2.77275727  9.32170882],\n",
      " \t action=[899.71686176167293, -0.064627243158369763, 900.08741299763471, 0.056050659429508709], \n",
      " \t task.sim.pose=[-13.57915892  -8.05646464  35.47608822   2.05794476   2.09425997   0.        ]\n",
      "Episode =  781, total_reward =  172.33, , z=  35.83, v_z=   9.41, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87993226 -1.63250557  9.40613496],\n",
      " \t action=[900.76422672140586, 0.11861979653168885, 899.68266546947382, 0.17771492705207445], \n",
      " \t task.sim.pose=[-13.67234155  -6.53992645  35.83042329   2.10218733   2.084963     0.        ]\n",
      "Episode =  782, total_reward =  170.85, , z=  35.50, v_z=   9.34, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82134495 -0.98438238  9.34330735],\n",
      " \t action=[900.32740860275237, -0.28231390536223105, 899.61874843806299, 0.79043081653028224], \n",
      " \t task.sim.pose=[-13.43509893  -3.08126542  35.5045244    2.07335765   2.06623223   0.        ]\n",
      "Episode =  783, total_reward =  171.76, , z=  35.68, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82760972 -1.78271277  9.36237178],\n",
      " \t action=[900.29197414223279, 0.37418721653935394, 900.73308052979303, -0.37657984131188366], \n",
      " \t task.sim.pose=[-13.54815914  -5.82841375  35.68085011   2.10561476   2.12372006   0.        ]\n",
      "Episode =  784, total_reward =  170.89, , z=  35.49, v_z=   9.32, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8401371  -2.18738674  9.31562754],\n",
      " \t action=[900.04830253595105, 0.38570234484786131, 899.71881564215676, 0.17049281964761401], \n",
      " \t task.sim.pose=[-13.5569147   -6.0729378   35.48603339   2.0864657    2.10942578   0.        ]\n",
      "Episode =  785, total_reward =  172.17, , z=  35.75, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78705325 -0.39831518  9.35449264],\n",
      " \t action=[899.65137078350699, 0.84847428598451602, 900.44843767296732, 0.51084392547878443], \n",
      " \t task.sim.pose=[-13.46863869  -2.25216395  35.74791992   2.14050316   2.12926135   0.        ]\n",
      "Episode =  786, total_reward =  171.36, , z=  35.52, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87537298 -3.51009012  9.28216943],\n",
      " \t action=[900.07237371468273, 0.066837306610300615, 899.73650041320695, 0.0041371973490216263], \n",
      " \t task.sim.pose=[-13.67051711  -9.55363218  35.5249391    2.08610295   2.12897096   0.        ]\n",
      "Episode =  787, total_reward =  171.01, , z=  35.45, v_z=   9.26, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76109336  1.54699969  9.26474888],\n",
      " \t action=[900.68729390870294, -0.073626888754332404, 900.35889643979431, -0.3056520979968067], \n",
      " \t task.sim.pose=[-13.26428156   2.67187646  35.45001487   2.11088243   2.04649462   0.        ]\n",
      "Episode =  788, total_reward =  170.16, , z=  35.13, v_z=   9.07, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.90511242 -5.45674674  9.07116918],\n",
      " \t action=[899.4517583195842, -0.63415465837179874, 900.81769095917252, 0.29138791958605503], \n",
      " \t task.sim.pose=[-13.7910921  -14.13040695  35.12682032   2.06275876   2.17674385   0.        ]\n",
      "Episode =  789, total_reward =  171.44, , z=  35.59, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83523512 -2.32561448  9.31331877],\n",
      " \t action=[899.35037759911506, 0.35282439452621378, 899.33893919201523, 0.84677600368654771], \n",
      " \t task.sim.pose=[-13.60296145  -6.41184686  35.59208596   2.0980471    2.13967763   0.        ]\n",
      "Episode =  790, total_reward =  170.88, , z=  35.46, v_z=   9.30, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76867619  0.72087894  9.29590693],\n",
      " \t action=[900.29972331674787, -0.64175241294478969, 900.05875789564357, 0.31343562317203022], \n",
      " \t task.sim.pose=[-13.28167184   0.5004772   35.45511959   2.11791112   2.06814889   0.        ]\n",
      "Episode =  791, total_reward =  172.33, , z=  35.76, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86127125 -2.78189261  9.35174046],\n",
      " \t action=[899.56039289658133, 0.17359376400005216, 900.21031024801482, 0.015994965076606873], \n",
      " \t task.sim.pose=[-13.69122445  -7.96099975  35.76071029   2.10872975   2.14020027   0.        ]\n",
      "Episode =  792, total_reward =  170.69, , z=  35.44, v_z=   9.29, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79965988  0.47744358  9.2909908 ],\n",
      " \t action=[899.95445259266864, -0.058712858176719035, 899.61467619065104, 0.38695517933341872], \n",
      " \t task.sim.pose=[-13.42489172  -0.21909934  35.43877006   2.09314514   2.06934813   0.        ]\n",
      "Episode =  793, total_reward =  171.99, , z=  35.70, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84760795 -2.21729225  9.35879817],\n",
      " \t action=[900.05321308415409, -0.37778640926671081, 900.18192786202087, -0.55725215863641486], \n",
      " \t task.sim.pose=[-13.60438523  -6.86153151  35.69963562   2.1228073    2.12240967   0.        ]\n",
      "Episode =  794, total_reward =  171.03, , z=  35.45, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7384863   0.57442984  9.27572468],\n",
      " \t action=[899.53365434579973, -0.38396831552644534, 900.68356785487617, -0.18190515113598654], \n",
      " \t task.sim.pose=[-13.32024729   2.17398704  35.45051085   2.08873786   2.10842659   0.        ]\n",
      "Episode =  795, total_reward =  171.37, , z=  35.57, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87322499 -3.0024802   9.31297163],\n",
      " \t action=[899.63248811516689, 0.51105568547809355, 900.27262134295813, 0.10636889357141027], \n",
      " \t task.sim.pose=[-13.74385373  -8.78182982  35.56968968   2.08935858   2.14552712   0.        ]\n",
      "Episode =  796, total_reward =  172.96, , z=  35.92, v_z=   9.38, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84154904 -1.83822398  9.37631872],\n",
      " \t action=[899.21568054708757, -0.077518835552662424, 899.63874136627248, -0.53581823175324472], \n",
      " \t task.sim.pose=[-13.729277    -6.10091862  35.91563842   2.15447002   2.16424898   0.        ]\n",
      "Episode =  797, total_reward =  170.76, , z=  35.40, v_z=   9.27, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73398347  0.86072736  9.27269975],\n",
      " \t action=[900.61620573994912, 0.067588070765504729, 900.22650224561539, 0.0024561600891890786], \n",
      " \t task.sim.pose=[-13.21956217   1.81520794  35.40098556   2.12214236   2.09153108   0.        ]\n",
      "Episode =  798, total_reward =  171.40, , z=  35.51, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.92586767 -3.76815674  9.30061163],\n",
      " \t action=[899.34605955552684, -0.18125508719757538, 900.32038335689072, -0.78724438379337258], \n",
      " \t task.sim.pose=[-13.85525234 -11.62598251  35.51491463   2.1114674    2.13855661   0.        ]\n",
      "Episode =  799, total_reward =  172.17, , z=  35.73, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78317408 -0.56111674  9.34886339],\n",
      " \t action=[900.33398458450483, 0.32455018641362698, 899.4325498848408, 0.051244604020292267], \n",
      " \t task.sim.pose=[-13.48723894  -1.77030822  35.73388024   2.1447316    2.13108999   0.        ]\n",
      "Episode =  800, total_reward =  170.77, , z=  35.41, v_z=   9.26, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76118625  1.15071501  9.25710936],\n",
      " \t action=[899.8386068069151, -0.36153783199891798, 899.49867862037911, -0.19097877122577278], \n",
      " \t task.sim.pose=[-13.27366456   1.84995686  35.41297208   2.09366216   2.05883135   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  801, total_reward =  171.93, , z=  35.74, v_z=   9.38, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86909528 -1.27726172  9.38409629],\n",
      " \t action=[899.9360155580614, -0.043965709329206654, 900.33655132381796, 0.47116318677795421], \n",
      " \t task.sim.pose=[-13.67754952  -5.9462695   35.7390678    2.1176819    2.09756612   0.        ]\n",
      "Episode =  802, total_reward =  171.81, , z=  35.65, v_z=   9.30, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80827433 -2.46568424  9.29977931],\n",
      " \t action=[899.43031730813925, -0.24891631384249033, 899.79316016347741, -0.33954362328037579], \n",
      " \t task.sim.pose=[-13.48646361  -5.14358004  35.64667111   2.07316229   2.12234658   0.        ]\n",
      "Episode =  803, total_reward =  171.69, , z=  35.50, v_z=   9.15, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84460742 -4.61081257  9.15287891],\n",
      " \t action=[900.01577807954777, -0.32401956143904631, 899.66644092097874, -0.23899629891392421], \n",
      " \t task.sim.pose=[-13.65392494 -10.733384    35.50282352   2.06701319   2.18254707   0.        ]\n",
      "Episode =  804, total_reward =  171.24, , z=  35.52, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85267333 -3.13914026  9.29920905],\n",
      " \t action=[899.97767018134005, 0.1191772852997794, 900.11455797875794, 0.13251373373451195], \n",
      " \t task.sim.pose=[-13.60095155  -8.69823049  35.52327726   2.08213559   2.13980885   0.        ]\n",
      "Episode =  805, total_reward =  171.69, , z=  35.66, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88535479 -2.62956003  9.35214706],\n",
      " \t action=[900.41528664096245, 0.007610717269830182, 899.53854568665884, -0.4995076478724122], \n",
      " \t task.sim.pose=[-13.68721806  -8.06728781  35.66371983   2.08877911   2.10129917   0.        ]\n",
      "Episode =  806, total_reward =  171.35, , z=  35.50, v_z=   9.25, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75638942  1.61057255  9.24747396],\n",
      " \t action=[900.35396047244842, 0.2333063085244847, 900.09513298742127, -0.070768915830520779], \n",
      " \t task.sim.pose=[-13.33249549   2.39232127  35.49619161   2.14011018   2.08155894   0.        ]\n",
      "Episode =  807, total_reward =  170.96, , z=  35.50, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79137521  0.33500075  9.31925527],\n",
      " \t action=[900.190417928172, 0.25184581627335961, 900.31797946237236, -0.43924810586504726], \n",
      " \t task.sim.pose=[-13.36992383   0.05025851  35.49606939   2.09156592   2.05950741   0.        ]\n",
      "Episode =  808, total_reward =  168.99, , z=  34.81, v_z=   9.01, \n",
      " \t score = 2.01 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.6765643   3.28120789  9.01338233],\n",
      " \t action=[900.33314497060678, 0.55457322540288811, 899.74338119001425, 0.2954495371646424], \n",
      " \t task.sim.pose=[-13.10674397   8.40436423  34.8113815    2.16076035   2.07704841   0.        ]\n",
      "Episode =  809, total_reward =  172.21, , z=  35.69, v_z=   9.27, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80510959 -3.13587539  9.2685956 ],\n",
      " \t action=[900.59130257592119, 0.063383765927421121, 899.69318809011656, 0.63707106294752636], \n",
      " \t task.sim.pose=[-13.56113393  -6.76683737  35.69174839   2.08809728   2.16994039   0.        ]\n",
      "Episode =  810, total_reward =  171.44, , z=  35.59, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79105024 -0.94373012  9.33381989],\n",
      " \t action=[900.4480784564812, 0.27950614364424486, 900.4873825341017, 0.053556059988000032], \n",
      " \t task.sim.pose=[-13.46274649  -2.56792094  35.59430613   2.11272722   2.11971957   0.        ]\n",
      "Episode =  811, total_reward =  171.06, , z=  35.48, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88670679 -3.34548009  9.28358751],\n",
      " \t action=[899.92253542100559, 1.1718490233716325, 899.71494928484708, -0.39847487966795175], \n",
      " \t task.sim.pose=[-13.74012699  -9.13895376  35.47845129   2.08455124   2.12546158   0.        ]\n",
      "Episode =  812, total_reward =  171.62, , z=  35.61, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75743815  0.69998812  9.29985606],\n",
      " \t action=[899.43181192730287, -0.51380388529447862, 900.12449923555437, 0.16165651161324565], \n",
      " \t task.sim.pose=[-13.32608473   1.3715466   35.60587833   2.10006473   2.08453101   0.        ]\n",
      "Episode =  813, total_reward =  171.62, , z=  35.67, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82950813 -0.66889095  9.36214713],\n",
      " \t action=[900.02638034561119, -0.1229070043544922, 899.7704926610561, -0.37627894891212621], \n",
      " \t task.sim.pose=[-13.57349896  -3.67024609  35.66744932   2.10286558   2.1036843    0.        ]\n",
      "Episode =  814, total_reward =  170.48, , z=  35.23, v_z=   9.16, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.70018443  2.51648678  9.15641417],\n",
      " \t action=[900.34984887809071, 0.10402287572087178, 900.25000668428777, -0.22766474022289518], \n",
      " \t task.sim.pose=[-13.09965131   6.17780121  35.23041828   2.12336498   2.06119628   0.        ]\n",
      "Episode =  815, total_reward =  171.33, , z=  35.55, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74650456 -0.02725884  9.3140008 ],\n",
      " \t action=[899.76807678198668, 0.5277691171628216, 899.69685849717621, -0.055170876136491256], \n",
      " \t task.sim.pose=[-13.27961753   0.13738358  35.55207511   2.11565381   2.107623     0.        ]\n",
      "Episode =  816, total_reward =  171.47, , z=  35.60, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85302188 -2.02557488  9.36387923],\n",
      " \t action=[900.80506233816027, 0.010007826559917887, 899.80904276294336, -0.11103153144153446], \n",
      " \t task.sim.pose=[-13.56269821  -6.93740452  35.60234256   2.12443665   2.10885138   0.        ]\n",
      "Episode =  817, total_reward =  171.45, , z=  35.60, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77430288  0.0973864   9.32567218],\n",
      " \t action=[899.60135150589053, 0.021457585927529846, 899.51016731494428, 0.058402249735538508], \n",
      " \t task.sim.pose=[-13.31999801  -0.52867085  35.60396551   2.09639335   2.08222135   0.        ]\n",
      "Episode =  818, total_reward =  171.73, , z=  35.67, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78231733 -0.76532364  9.33880824],\n",
      " \t action=[899.66698329040548, -0.061245071788585181, 900.0154258815777, 0.36950126860533716], \n",
      " \t task.sim.pose=[-13.40132344  -1.8217988   35.67044415   2.08078968   2.1031948    0.        ]\n",
      "Episode =  819, total_reward =  170.26, , z=  35.29, v_z=   9.26, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.87853491 -3.48226044  9.26280141],\n",
      " \t action=[900.00470188526242, -0.29027827339326517, 900.10595604956268, -0.17182543752320023], \n",
      " \t task.sim.pose=[-13.65178886  -9.80112629  35.29339617   2.08615041   2.1302098    0.        ]\n",
      "Episode =  820, total_reward =  171.73, , z=  35.64, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8084688   0.70113186  9.31892615],\n",
      " \t action=[899.95947312287694, -0.81494496416296247, 900.21484763786873, -0.13289487118127469], \n",
      " \t task.sim.pose=[-13.53861711  -0.76642801  35.6380178    2.15629034   2.09328572   0.        ]\n",
      "Episode =  821, total_reward =  169.93, , z=  35.12, v_z=   9.14, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.69888821  2.23300931  9.13938909],\n",
      " \t action=[899.45553753654485, -0.58289786174395875, 899.8080244355898, 0.88086501261392658], \n",
      " \t task.sim.pose=[-13.16246077   5.44596266  35.11814686   2.14691677   2.09372541   0.        ]\n",
      "Episode =  822, total_reward =  170.07, , z=  35.29, v_z=   9.25, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78127895  0.95503015  9.25382183],\n",
      " \t action=[899.13407591326711, -0.52368965313011262, 900.32294011741476, 0.17739743396157831], \n",
      " \t task.sim.pose=[-13.3194041    0.77546349  35.29140424   2.09908666   2.06020316   0.        ]\n",
      "Episode =  823, total_reward =  170.66, , z=  35.42, v_z=   9.29, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7717553   0.28254935  9.28992953],\n",
      " \t action=[899.75297423694678, -0.54447536137301, 899.86165047790439, -0.42240012139897259], \n",
      " \t task.sim.pose=[-13.33637263   0.28611951  35.4182582    2.09511958   2.07916153   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  824, total_reward =  171.35, , z=  35.54, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.89568024 -3.39569313  9.31622312],\n",
      " \t action=[899.75863313343098, -0.32705426485843525, 900.277580403451, -0.3551145833833862], \n",
      " \t task.sim.pose=[-13.68231367 -10.24496201  35.54205776   2.08977863   2.11033766   0.        ]\n",
      "Episode =  825, total_reward =  170.90, , z=  35.51, v_z=   9.33, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82248746 -1.91642234  9.32582796],\n",
      " \t action=[899.55772569801286, -0.34213094175787534, 900.08295372060525, -0.22769073839073301], \n",
      " \t task.sim.pose=[-13.43046912  -5.17890408  35.50853331   2.05651392   2.08970743   0.        ]\n",
      "Episode =  826, total_reward =  171.99, , z=  35.68, v_z=   9.31, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74561722 -0.06893797  9.31276209],\n",
      " \t action=[899.67955710006197, 0.32787997987590989, 899.67159804731853, -0.16013326850671467], \n",
      " \t task.sim.pose=[-13.3253647    0.5314353   35.68495321   2.09283076   2.11188292   0.        ]\n",
      "Episode =  827, total_reward =  172.66, , z=  35.86, v_z=   9.37, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79826317 -0.55100616  9.37020579],\n",
      " \t action=[899.81502857924295, -0.054266293529243947, 899.75044835738163, 0.55734887603347616], \n",
      " \t task.sim.pose=[-13.52742024  -2.31175646  35.86385048   2.11744498   2.12013      0.        ]\n",
      "Episode =  828, total_reward =  172.48, , z=  35.83, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81869846 -1.12999535  9.37411054],\n",
      " \t action=[899.90168291193834, -0.07970407439746352, 899.89538806850953, 0.031997600194006701], \n",
      " \t task.sim.pose=[-13.57407143  -3.98469637  35.82995865   2.12260403   2.12422137   0.        ]\n",
      "Episode =  829, total_reward =  170.86, , z=  35.46, v_z=   9.30, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7950993   0.63209022  9.29580226],\n",
      " \t action=[900.03087304711482, -0.049881684739049914, 900.10895604477696, -0.095591522980196852], \n",
      " \t task.sim.pose=[-13.46758165   0.48859328  35.45617864   2.1094517    2.07584382   0.        ]\n",
      "Episode =  830, total_reward =  170.89, , z=  35.36, v_z=   9.22, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.90796183 -4.42095732  9.21800356],\n",
      " \t action=[899.22008697244382, -0.10253109967143528, 899.97239775078231, 0.23882315566960222], \n",
      " \t task.sim.pose=[-13.75278948 -12.32024008  35.3623956    2.08631432   2.13927452   0.        ]\n",
      "Episode =  831, total_reward =  170.58, , z=  35.44, v_z=   9.31, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79614656 -1.05382095  9.31385154],\n",
      " \t action=[899.77629323912151, -0.43808736569270856, 899.94825866957035, -0.53748796412190203], \n",
      " \t task.sim.pose=[-13.34687829  -2.73622471  35.43676372   2.06611709   2.08274768   0.        ]\n",
      "Episode =  832, total_reward =  169.47, , z=  34.88, v_z=   8.95, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.96879119 -6.549909    8.94616813],\n",
      " \t action=[899.74508161741755, -0.26507918846327161, 899.98878280216854, 0.13827810518967742], \n",
      " \t task.sim.pose=[-13.95205161 -17.22956636  34.87586805   2.04324533   2.15522431   0.        ]\n",
      "Episode =  833, total_reward =  172.02, , z=  35.69, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7509458   0.15985482  9.32535643],\n",
      " \t action=[899.23883448445008, 0.17766695527993626, 899.83126646165454, -0.60182297284060349], \n",
      " \t task.sim.pose=[-13.35921831   0.68671273  35.68837024   2.10417424   2.11257297   0.        ]\n",
      "Episode =  834, total_reward =  171.38, , z=  35.57, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84531267 -2.7467579   9.30868606],\n",
      " \t action=[900.0764441936044, -0.51826183561436623, 899.60438115152624, 0.15769103450679378], \n",
      " \t task.sim.pose=[-13.63026576  -7.37958665  35.56911903   2.08748478   2.14113902   0.        ]\n",
      "Episode =  835, total_reward =  171.29, , z=  35.49, v_z=   9.26, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88213193 -3.76919955  9.25823627],\n",
      " \t action=[900.25120598947024, 0.1545885032939332, 899.99723305622604, 0.13727324902482529], \n",
      " \t task.sim.pose=[-13.7272569   -9.78567771  35.49451008   2.07516707   2.13979601   0.        ]\n",
      "Episode =  836, total_reward =  171.72, , z=  35.61, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.90254132 -3.5700822   9.31462377],\n",
      " \t action=[900.57021876050248, -0.47422827853229899, 899.95892860666822, 0.27791500541215702], \n",
      " \t task.sim.pose=[-13.75224329 -10.45775144  35.60614183   2.08932732   2.12065977   0.        ]\n",
      "Episode =  837, total_reward =  170.75, , z=  35.23, v_z=   9.14, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.69825566  2.56432569  9.14039852],\n",
      " \t action=[900.41060899637762, -0.22061923183640472, 900.44740804805986, -0.26470054236944202], \n",
      " \t task.sim.pose=[-13.17648261   6.53567713  35.23342617   2.13987388   2.08014529   0.        ]\n",
      "Episode =  838, total_reward =  171.34, , z=  35.54, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84761284 -3.19677531  9.28970916],\n",
      " \t action=[899.82142621295634, 0.20502435458319276, 899.96844885116366, -0.073468978450689004], \n",
      " \t task.sim.pose=[-13.55630103  -8.16740779  35.53904771   2.0656307    2.12032305   0.        ]\n",
      "Episode =  839, total_reward =  172.05, , z=  35.75, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79790648  0.2035894   9.36475349],\n",
      " \t action=[900.43115492767379, -0.8803381392605063, 900.3093332677073, 0.15603393831903661], \n",
      " \t task.sim.pose=[-13.38660605   0.11767567  35.75171465   2.05729819   2.04467109   0.        ]\n",
      "Episode =  840, total_reward =  173.08, , z=  35.95, v_z=   9.38, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84189507 -2.45832452  9.38172813],\n",
      " \t action=[899.82813805110834, -0.059698631322913101, 900.25952609861736, -0.64728107847319893], \n",
      " \t task.sim.pose=[-13.60483195  -7.06914874  35.95037512   2.08963945   2.12514687   0.        ]\n",
      "Episode =  841, total_reward =  172.18, , z=  35.75, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7877506  -0.15367286  9.34984099],\n",
      " \t action=[900.19210871474968, 0.080204405723589334, 900.01460078288403, 0.10613030094535893], \n",
      " \t task.sim.pose=[-13.45175065  -0.58579199  35.74796839   2.11076268   2.0964312    0.        ]\n",
      "Episode =  842, total_reward =  172.10, , z=  35.70, v_z=   9.32, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76568822  0.54428115  9.31973152],\n",
      " \t action=[899.74553549228699, 0.6100321331754025, 899.73879664487163, -0.75546833764639354], \n",
      " \t task.sim.pose=[-13.42537705   0.14531954  35.69900317   2.14658367   2.11575923   0.        ]\n",
      "Episode =  843, total_reward =  171.08, , z=  35.48, v_z=   9.26, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85999203 -3.40079498  9.25763059],\n",
      " \t action=[899.58143352553907, -0.39310489680851302, 900.14913741537714, 0.037782364705355898], \n",
      " \t task.sim.pose=[-13.68995257  -8.66406532  35.4759329    2.06647133   2.14610085   0.        ]\n",
      "Episode =  844, total_reward =  169.92, , z=  35.18, v_z=   9.20, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7231993   1.82974117  9.20022467],\n",
      " \t action=[900.21021615578377, 0.51913464588964686, 899.72980808266641, -0.26213956046464731], \n",
      " \t task.sim.pose=[-13.13546542   3.64604449  35.18004357   2.10861621   2.06493145   0.        ]\n",
      "Episode =  845, total_reward =  171.11, , z=  35.54, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79630336 -1.07259355  9.32366236],\n",
      " \t action=[899.60899339438754, -0.25253584330566953, 900.57728151650383, -0.41154075917228461], \n",
      " \t task.sim.pose=[-13.44061251  -2.59918749  35.5358185    2.06964741   2.10101717   0.        ]\n",
      "Episode =  846, total_reward =  171.68, , z=  35.57, v_z=   9.25, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77048553  1.69316546  9.24657518],\n",
      " \t action=[899.19118845308572, -0.57071117607751942, 899.8976544200973, -0.35345848994887036], \n",
      " \t task.sim.pose=[-13.41755148   2.38969151  35.56862046   2.1503255    2.08175882   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  847, total_reward =  172.76, , z=  35.89, v_z=   9.38, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81227079 -0.79212601  9.3768373 ],\n",
      " \t action=[899.42517259674219, -0.41651092635241155, 900.34545693252005, -0.24401838943779228], \n",
      " \t task.sim.pose=[-13.58984396  -2.68517413  35.89432639   2.10279719   2.11582193   0.        ]\n",
      "Episode =  848, total_reward =  171.64, , z=  35.56, v_z=   9.27, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7460227   1.24577046  9.2728122 ],\n",
      " \t action=[900.00861062629804, -0.4849143781325102, 900.54273354290353, -0.019432251283050091], \n",
      " \t task.sim.pose=[-13.38601017   2.58243484  35.55906456   2.13349487   2.10909989   0.        ]\n",
      "Episode =  849, total_reward =  170.85, , z=  35.37, v_z=   9.22, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73306432  1.86810769  9.21629535],\n",
      " \t action=[900.04792809378625, -0.027828691657722976, 900.9142460204265, -0.034950684265547122], \n",
      " \t task.sim.pose=[-13.26154861   3.74609506  35.37176692   2.131606     2.08142604   0.        ]\n",
      "Episode =  850, total_reward =  172.01, , z=  35.69, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76901956 -0.25636869  9.32808657],\n",
      " \t action=[900.05231142598154, 0.34631037659816111, 899.41714766244081, 0.18576631420082129], \n",
      " \t task.sim.pose=[-13.43075329  -0.2067361   35.69377146   2.10782312   2.11670562   0.        ]\n",
      "Episode =  851, total_reward =  171.50, , z=  35.50, v_z=   9.24, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72653792  1.5315852   9.23573932],\n",
      " \t action=[899.89662845841258, 0.049696222888545583, 899.62106936691305, 0.55513427468799914], \n",
      " \t task.sim.pose=[-13.30394093   3.64087403  35.50017448   2.12301744   2.10105834   0.        ]\n",
      "Episode =  852, total_reward =  170.91, , z=  35.48, v_z=   9.30, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83731233 -2.58384794  9.30072805],\n",
      " \t action=[899.80170002901366, 0.19407432584556317, 900.25890598935041, -0.29735148060480049], \n",
      " \t task.sim.pose=[-13.529441    -6.81962833  35.47744798   2.07380269   2.1114816    0.        ]\n",
      "Episode =  853, total_reward =  171.35, , z=  35.52, v_z=   9.27, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74366915  1.30733173  9.26753445],\n",
      " \t action=[900.02105886112929, -0.17953420628152389, 899.91139550861567, -0.83183703225840377], \n",
      " \t task.sim.pose=[-13.26779335   2.78277016  35.51543078   2.12572621   2.07900565   0.        ]\n",
      "Episode =  854, total_reward =  172.33, , z=  35.79, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83351341 -1.74291696  9.36408821],\n",
      " \t action=[899.61085366462407, 0.58282148634003206, 900.7705877137729, 0.39235904005976902], \n",
      " \t task.sim.pose=[-13.63501708  -5.14993127  35.78980737   2.09986532   2.1315077    0.        ]\n",
      "Episode =  855, total_reward =  171.57, , z=  35.63, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78733037 -0.08126187  9.34002941],\n",
      " \t action=[900.44431923969364, 0.10635757379100569, 900.3686617086496, 0.65213217739325646], \n",
      " \t task.sim.pose=[-13.40612825  -1.73580108  35.62989171   2.13110757   2.10132355   0.        ]\n",
      "Episode =  856, total_reward =  171.61, , z=  35.64, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78741035  0.20808178  9.33439333],\n",
      " \t action=[899.80230188925248, -0.38791544327705463, 900.06907046668471, -0.43403279109988524], \n",
      " \t task.sim.pose=[-13.39367342  -0.86622408  35.63666254   2.11522883   2.08266302   0.        ]\n",
      "Episode =  857, total_reward =  170.56, , z=  35.42, v_z=   9.30, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79803135  0.17743506  9.29586265],\n",
      " \t action=[899.97392435535323, -0.58421769813698154, 899.35851695147835, 0.0063099649186699192], \n",
      " \t task.sim.pose=[-13.38379145  -0.31952205  35.41970015   2.08264191   2.06108087   0.        ]\n",
      "Episode =  858, total_reward =  172.44, , z=  35.85, v_z=   9.40, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85207113 -1.39279849  9.40014754],\n",
      " \t action=[900.39842216096963, -0.27165602302187619, 900.00982740391635, -0.21362920296710772], \n",
      " \t task.sim.pose=[-13.60456443  -4.9334349   35.84862022   2.08261457   2.08338274   0.        ]\n",
      "Episode =  859, total_reward =  170.61, , z=  35.25, v_z=   9.14, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72259524  2.58229664  9.13716495],\n",
      " \t action=[900.16613035461796, 0.23390728692912857, 899.20249184799184, 0.10111590695933989], \n",
      " \t task.sim.pose=[-13.27497299   5.21253056  35.24647763   2.16257739   2.08649633   0.        ]\n",
      "Episode =  860, total_reward =  171.20, , z=  35.53, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75477187 -0.3707231   9.31050913],\n",
      " \t action=[900.26612162608933, -0.060508108843053632, 900.04862297577301, 0.62053173380494719], \n",
      " \t task.sim.pose=[-13.27272605   0.32044339  35.53399783   2.06787895   2.08535927   0.        ]\n",
      "Episode =  861, total_reward =  171.25, , z=  35.56, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88386522 -2.56737815  9.3316427 ],\n",
      " \t action=[900.40569509991326, -0.020894218938532744, 899.91449283931388, -0.019006641670507481], \n",
      " \t task.sim.pose=[-13.75560022  -7.59640682  35.55877059   2.08653959   2.1177112    0.        ]\n",
      "Episode =  862, total_reward =  170.80, , z=  35.48, v_z=   9.32, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78306273 -0.0588663   9.31733725],\n",
      " \t action=[899.58004853813145, -0.7438186617366207, 900.01549818595129, -0.047113541537336733], \n",
      " \t task.sim.pose=[-13.2984067   -0.38816617  35.48148549   2.05616072   2.05675763   0.        ]\n",
      "Episode =  863, total_reward =  171.56, , z=  35.64, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79576196 -0.68379013  9.33515334],\n",
      " \t action=[899.70653236055216, 0.60106141686012804, 900.06382919347789, -0.24152271174390519], \n",
      " \t task.sim.pose=[-13.43946618  -2.14006976  35.63785577   2.07584662   2.0926364    0.        ]\n",
      "Episode =  864, total_reward =  170.95, , z=  35.43, v_z=   9.25, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74903165  1.2327345   9.25319869],\n",
      " \t action=[899.99302744289275, -0.48749439154518692, 899.73818412620369, 0.067277163345454846], \n",
      " \t task.sim.pose=[-13.29660236   2.19595538  35.43335023   2.13887533   2.08626892   0.        ]\n",
      "Episode =  865, total_reward =  172.33, , z=  35.80, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81261736 -1.34496886  9.36269649],\n",
      " \t action=[899.26598760515776, -0.43225782585795547, 900.27656418965171, 0.037089525507353394], \n",
      " \t task.sim.pose=[-13.53903586  -3.1558755   35.80135816   2.07022381   2.10465796   0.        ]\n",
      "Episode =  866, total_reward =  171.81, , z=  35.60, v_z=   9.28, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.739357    1.33654865  9.27570329],\n",
      " \t action=[899.42093552697645, -0.25411591706439818, 900.09151244225131, -0.33595598460814424], \n",
      " \t task.sim.pose=[-13.29672838   2.90664992  35.59857793   2.12374056   2.08860987   0.        ]\n",
      "Episode =  867, total_reward =  172.76, , z=  35.87, v_z=   9.36, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84493364 -2.38474332  9.35626806],\n",
      " \t action=[899.56822975839168, 0.14686498649595597, 899.61239432183982, 0.17500002961203606], \n",
      " \t task.sim.pose=[-13.66130098  -6.95152411  35.86916679   2.11766039   2.14496098   0.        ]\n",
      "Episode =  868, total_reward =  170.41, , z=  35.17, v_z=   9.06, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88767245 -5.42502771  9.06155461],\n",
      " \t action=[899.52965530662539, -0.053504860042943192, 900.63303287197004, 0.17224271547122832], \n",
      " \t task.sim.pose=[-13.72249435 -13.1030844   35.17257355   2.03378233   2.16281064   0.        ]\n",
      "Episode =  869, total_reward =  171.54, , z=  35.51, v_z=   9.24, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86449501 -3.86238135  9.23862302],\n",
      " \t action=[899.77790155676109, 0.44883958920323319, 900.28302747544694, -0.29358226671546572], \n",
      " \t task.sim.pose=[-13.70358627  -9.44847864  35.51169722   2.08809806   2.15818082   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  870, total_reward =  171.62, , z=  35.62, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80694193  0.86360522  9.31712586],\n",
      " \t action=[899.45288669734805, 0.35828082677113354, 899.70140913419812, -0.03662285883343433], \n",
      " \t task.sim.pose=[-13.47085567   0.39902201  35.62368994   2.11978798   2.06369605   0.        ]\n",
      "Episode =  871, total_reward =  171.72, , z=  35.69, v_z=   9.37, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83108145 -0.53992558  9.36906889],\n",
      " \t action=[900.28365345744703, -0.3407244221847468, 900.11442473833881, -0.22487274164037402], \n",
      " \t task.sim.pose=[-13.51230926  -3.46322031  35.69414617   2.12158434   2.08242278   0.        ]\n",
      "Episode =  872, total_reward =  173.51, , z=  36.00, v_z=   9.38, \n",
      " \t score = 2.07 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83294192 -2.25994151  9.37500337],\n",
      " \t action=[899.89752233209913, -0.53310864429377203, 899.71855299847653, -0.47296422448170777], \n",
      " \t task.sim.pose=[-13.70969153  -6.70791414  36.00395976   2.15574974   2.17865871   0.        ]\n",
      "Episode =  873, total_reward =  171.39, , z=  35.51, v_z=   9.25, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76001271  1.35460968  9.25290312],\n",
      " \t action=[899.7821909350007, 0.23795022560367945, 900.03726598976073, 0.087794971391524132], \n",
      " \t task.sim.pose=[-13.39971375   1.80749054  35.50701016   2.14069225   2.10071849   0.        ]\n",
      "Episode =  874, total_reward =  170.40, , z=  35.31, v_z=   9.23, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75573331  1.65614     9.23296479],\n",
      " \t action=[899.89209135004967, -0.045853745206995214, 900.27349832748689, -0.12232688722666463], \n",
      " \t task.sim.pose=[-13.22035564   3.15589146  35.31445544   2.09068754   2.04048812   0.        ]\n",
      "Episode =  875, total_reward =  171.90, , z=  35.66, v_z=   9.30, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8720599  -3.29143499  9.30391042],\n",
      " \t action=[900.19454165565594, 0.21918082209967385, 899.75427293592384, 0.19455494397749212], \n",
      " \t task.sim.pose=[-13.69674403  -8.91378102  35.66161515   2.08309473   2.13110344   0.        ]\n",
      "Episode =  876, total_reward =  171.68, , z=  35.62, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77925395  0.47781564  9.31326179],\n",
      " \t action=[900.1661427003362, -0.34473476199410918, 900.15508756085705, -0.38633963739983834], \n",
      " \t task.sim.pose=[-13.46723504   0.1718252   35.61679013   2.12859502   2.10502628   0.        ]\n",
      "Episode =  877, total_reward =  171.01, , z=  35.43, v_z=   9.24, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73896461  1.37879462  9.24495398],\n",
      " \t action=[900.07059549767905, -0.38579577625306194, 899.33694492670816, -0.30061087601448211], \n",
      " \t task.sim.pose=[-13.28751538   2.84976155  35.4264447    2.12153971   2.0884041    0.        ]\n",
      "Episode =  878, total_reward =  171.29, , z=  35.56, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76947374 -0.3614286   9.32082254],\n",
      " \t action=[900.07140624019519, -0.24843027568846007, 899.72924893630613, 0.32691099967490478], \n",
      " \t task.sim.pose=[-13.36986592  -1.95722238  35.56421439   2.10857466   2.12066632   0.        ]\n",
      "Episode =  879, total_reward =  171.28, , z=  35.53, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76821011  1.08517326  9.27739345],\n",
      " \t action=[900.22757346877017, 0.072495614404082684, 899.29536334850354, -0.061514725154090982], \n",
      " \t task.sim.pose=[-13.33499827   0.70202327  35.52754317   2.15752268   2.08701246   0.        ]\n",
      "Episode =  880, total_reward =  172.05, , z=  35.71, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80311913  0.45094576  9.33892394],\n",
      " \t action=[900.30481069295001, 0.29877909632432981, 899.92717832754317, 0.53276035606903804], \n",
      " \t task.sim.pose=[-13.54635379  -0.98026057  35.71415857   2.13439984   2.10232851   0.        ]\n",
      "Episode =  881, total_reward =  171.65, , z=  35.69, v_z=   9.38, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83715462 -0.73665344  9.37835894],\n",
      " \t action=[900.27708271607685, 0.0047601608461898814, 899.82293687664867, 0.63674495389770636], \n",
      " \t task.sim.pose=[-13.50227894  -3.43777674  35.6875207    2.0828258    2.06450123   0.        ]\n",
      "Episode =  882, total_reward =  171.37, , z=  35.58, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78719481 -1.3267641   9.31840995],\n",
      " \t action=[900.3768292566773, -0.021229058625506281, 899.28547535211726, -0.010816131870420909], \n",
      " \t task.sim.pose=[-13.41720797  -2.43819801  35.57979286   2.07142403   2.10645166   0.        ]\n",
      "Episode =  883, total_reward =  171.32, , z=  35.53, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75878082 -0.16913688  9.28737291],\n",
      " \t action=[900.09860225359853, -0.64983296455488526, 900.03136175855036, -0.28306554795012984], \n",
      " \t task.sim.pose=[-13.42539926   0.84591391  35.52913201   2.08554806   2.11611637   0.        ]\n",
      "Episode =  884, total_reward =  170.64, , z=  35.33, v_z=   9.22, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.89294464 -4.13065012  9.22182366],\n",
      " \t action=[900.44173937304333, 0.23434245980636226, 900.58112021411739, 0.34357201326582798], \n",
      " \t task.sim.pose=[-13.697971   -10.75476726  35.33410968   2.05357688   2.11573888   0.        ]\n",
      "Episode =  885, total_reward =  169.99, , z=  35.22, v_z=   9.23, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.70331773  0.96728389  9.22885796],\n",
      " \t action=[900.16277236687938, -0.035067923179803055, 900.73828783509384, -0.18232483436170077], \n",
      " \t task.sim.pose=[-13.12850588   3.46010283  35.2160395    2.09146603   2.0947621    0.        ]\n",
      "Episode =  886, total_reward =  171.02, , z=  35.51, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79583293 -0.17739151  9.32357451],\n",
      " \t action=[899.92394497392775, 0.8188675370831513, 900.36780286659302, 0.53849975912914716], \n",
      " \t task.sim.pose=[-13.44130935  -0.27456424  35.51360233   2.07124988   2.07118937   0.        ]\n",
      "Episode =  887, total_reward =  171.18, , z=  35.58, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82889513 -0.45312021  9.35124161],\n",
      " \t action=[900.23927210011152, -0.3511380151592291, 899.75778600376566, -0.3300249782576874], \n",
      " \t task.sim.pose=[-13.46980978  -2.77291843  35.58351804   2.08825688   2.06271843   0.        ]\n",
      "Episode =  888, total_reward =  170.75, , z=  35.46, v_z=   9.31, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82619086 -1.5144009   9.31301852],\n",
      " \t action=[899.9140089001304, -0.63408316496795059, 899.23044904702704, -0.88468853910535883], \n",
      " \t task.sim.pose=[-13.52835531  -4.26549572  35.46456162   2.09437107   2.10721437   0.        ]\n",
      "Episode =  889, total_reward =  171.43, , z=  35.62, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80913237 -0.46397954  9.35079437],\n",
      " \t action=[900.39378214150236, 0.14638750089107302, 900.22071979508496, -0.49595188896525716], \n",
      " \t task.sim.pose=[-13.46087514  -2.27491795  35.61699546   2.09648365   2.08618516   0.        ]\n",
      "Episode =  890, total_reward =  171.65, , z=  35.55, v_z=   9.26, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74744252  1.7006435   9.2584885 ],\n",
      " \t action=[901.11851303692652, 0.45592457351584426, 899.78578640183309, 0.14247511362796617], \n",
      " \t task.sim.pose=[-13.26089841   3.14920988  35.55156069   2.14348272   2.06574914   0.        ]\n",
      "Episode =  891, total_reward =  171.63, , z=  35.61, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8621156  -3.54699845  9.28931487],\n",
      " \t action=[900.28386673128512, -0.073425614461814295, 900.2795353335423, -0.76859306274585049], \n",
      " \t task.sim.pose=[-13.62294067  -9.77255644  35.60755065   2.07031803   2.13160419   0.        ]\n",
      "Episode =  892, total_reward =  171.14, , z=  35.46, v_z=   9.23, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.857597   -3.79168308  9.2265694 ],\n",
      " \t action=[899.53334430074938, -0.36917333697930493, 899.64933915926974, -0.25860867183083547], \n",
      " \t task.sim.pose=[-13.62837239  -9.77598259  35.46072164   2.08850872   2.14717028   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  893, total_reward =  170.46, , z=  35.27, v_z=   9.17, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86726837 -4.33821736  9.16546612],\n",
      " \t action=[899.69254040034377, 0.1437439759064994, 900.04234072180168, 0.14528216573527908], \n",
      " \t task.sim.pose=[-13.66999204 -10.80703887  35.27231104   2.06657657   2.15528729   0.        ]\n",
      "Episode =  894, total_reward =  171.65, , z=  35.55, v_z=   9.25, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75808012  1.44200014  9.25077701],\n",
      " \t action=[900.11466629466804, 0.16596001660419801, 899.1312042554398, 0.46054381957388058], \n",
      " \t task.sim.pose=[-13.40922052   2.58433495  35.54615427   2.14987827   2.09681616   0.        ]\n",
      "Episode =  895, total_reward =  171.55, , z=  35.64, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86749818 -1.32026606  9.35908807],\n",
      " \t action=[899.77178885217427, -0.23660168586915958, 899.24963845636125, -0.094225039090026649], \n",
      " \t task.sim.pose=[-13.7352507   -6.19833864  35.6407079    2.15149844   2.13161498   0.        ]\n",
      "Episode =  896, total_reward =  170.66, , z=  35.39, v_z=   9.27, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75457896  0.82932172  9.27214948],\n",
      " \t action=[899.82868150697686, -0.70698466318374731, 899.60108114239381, 0.61183990971380442], \n",
      " \t task.sim.pose=[-13.28291319   1.21464881  35.39304125   2.11385042   2.08246705   0.        ]\n",
      "Episode =  897, total_reward =  171.45, , z=  35.58, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84272337 -2.96287796  9.29818533],\n",
      " \t action=[899.51865523124252, 0.1759452891745063, 899.67547765057122, -0.037793365646443977], \n",
      " \t task.sim.pose=[-13.56184253  -7.50850897  35.5799955    2.06579761   2.12082326   0.        ]\n",
      "Episode =  898, total_reward =  170.92, , z=  35.42, v_z=   9.24, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.75438489  1.47585314  9.24230229],\n",
      " \t action=[900.03695058855374, -0.23046234582511882, 899.75224000457376, 0.55331617157882118], \n",
      " \t task.sim.pose=[-13.31881238   2.69940749  35.42084362   2.12794198   2.07529497   0.        ]\n",
      "Episode =  899, total_reward =  171.12, , z=  35.40, v_z=   9.22, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.69797359  1.37671423  9.2230539 ],\n",
      " \t action=[899.92665683525115, -0.007834799359148048, 899.87575448701057, 0.017040852048840704], \n",
      " \t task.sim.pose=[-13.21257986   3.77507919  35.40043441   2.13306281   2.12509305   0.        ]\n",
      "Episode =  900, total_reward =  172.03, , z=  35.73, v_z=   9.36, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81173971 -0.7640955   9.36237551],\n",
      " \t action=[899.27115079629471, -0.21357289488406181, 900.21985995137709, 0.05726788061221702], \n",
      " \t task.sim.pose=[-13.54583446  -3.21919505  35.7309142    2.12912602   2.12648051   0.        ]\n",
      "Episode =  901, total_reward =  171.30, , z=  35.58, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79964282  0.14642914  9.33024278],\n",
      " \t action=[900.0139264831962, 0.098762397604683222, 899.7718004628407, -0.66173159290497552], \n",
      " \t task.sim.pose=[-13.4456533   -1.19824088  35.57971954   2.10774128   2.08247919   0.        ]\n",
      "Episode =  902, total_reward =  171.26, , z=  35.55, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78003569 -1.5124691   9.30952611],\n",
      " \t action=[899.7696743023439, -0.36341092890138038, 899.94547873909926, -0.21552868213000753], \n",
      " \t task.sim.pose=[-13.40743513  -3.26772711  35.54852459   2.08942146   2.12720418   0.        ]\n",
      "Episode =  903, total_reward =  171.79, , z=  35.69, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8070186  -0.48620825  9.35445593],\n",
      " \t action=[899.24741377331941, -0.31602659854180409, 900.03415641043284, 0.14360941133628524], \n",
      " \t task.sim.pose=[-13.48682144  -2.42285601  35.68907394   2.10259145   2.09809679   0.        ]\n",
      "Episode =  904, total_reward =  171.42, , z=  35.47, v_z=   9.18, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83365686 -4.1202117   9.18420117],\n",
      " \t action=[899.83746400802204, -0.24073886759574289, 900.72631273945501, 0.50657543213208001], \n",
      " \t task.sim.pose=[-13.60328979  -9.18171042  35.46604048   2.06891507   2.16996204   0.        ]\n",
      "Episode =  905, total_reward =  170.91, , z=  35.52, v_z=   9.34, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82393011 -1.59501894  9.33845583],\n",
      " \t action=[899.78026126572718, -0.21740344384388052, 899.83463188076018, 0.16497936554822465], \n",
      " \t task.sim.pose=[-13.44524648  -5.01936991  35.5199654    2.08234816   2.09015184   0.        ]\n",
      "Episode =  906, total_reward =  170.92, , z=  35.25, v_z=   9.11, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.69928345  3.02488229  9.10776518],\n",
      " \t action=[900.40253630035591, -0.45300311322272324, 900.16377918923547, -0.19194629569609528], \n",
      " \t task.sim.pose=[-13.20644657   7.19198767  35.24638295   2.15388584   2.07836045   0.        ]\n",
      "Episode =  907, total_reward =  171.79, , z=  35.63, v_z=   9.31, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74802648  0.18684459  9.30516912],\n",
      " \t action=[899.22628305952185, 0.17181591765090945, 899.8888463766549, -0.12202513806285634], \n",
      " \t task.sim.pose=[-13.39582657   0.63554416  35.63360319   2.12773316   2.13482895   0.        ]\n",
      "Episode =  908, total_reward =  171.24, , z=  35.56, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81286315 -0.65517653  9.34037064],\n",
      " \t action=[900.68937448284316, 0.1786786317179728, 899.73248866492486, -0.22573519509048529], \n",
      " \t task.sim.pose=[-13.49406119  -2.95106465  35.56373896   2.11906921   2.09855244   0.        ]\n",
      "Episode =  909, total_reward =  171.36, , z=  35.57, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76741419  0.55897821  9.31419607],\n",
      " \t action=[900.15773845362412, 0.092895161548696301, 900.02642291498546, -0.061649168557667569], \n",
      " \t task.sim.pose=[-13.32190631   1.0486856   35.56790521   2.08375389   2.06914932   0.        ]\n",
      "Episode =  910, total_reward =  171.24, , z=  35.61, v_z=   9.37, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83931433 -0.92378809  9.36820453],\n",
      " \t action=[899.77623476337169, -0.17963835047320342, 900.40363941541489, 0.042005355139030073], \n",
      " \t task.sim.pose=[-13.49538538  -3.84086583  35.60633864   2.07177465   2.06422581   0.        ]\n",
      "Episode =  911, total_reward =  171.14, , z=  35.54, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77392068  0.13147755  9.31478718],\n",
      " \t action=[899.1406524651162, 0.21305805124961658, 900.1226485003242, 0.17448966750049899], \n",
      " \t task.sim.pose=[-13.3622742   -0.61087035  35.5391051    2.09746876   2.09459434   0.        ]\n",
      "Episode =  912, total_reward =  168.62, , z=  34.70, v_z=   8.96, \n",
      " \t score = 2.01 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.67776923  3.7919279   8.96016299],\n",
      " \t action=[900.17058610787205, 0.23280514227427523, 899.91525339496161, -0.21094317647040547], \n",
      " \t task.sim.pose=[-12.97019421   9.26256088  34.69854553   2.12929637   2.02911553   0.        ]\n",
      "Episode =  913, total_reward =  171.49, , z=  35.64, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81829273 -0.80297155  9.35931641],\n",
      " \t action=[899.95383617208211, 0.61038472846794134, 900.44105117267338, 0.029101976078218322], \n",
      " \t task.sim.pose=[-13.48291729  -2.89119052  35.63842837   2.07801949   2.082741     0.        ]\n",
      "Episode =  914, total_reward =  171.34, , z=  35.61, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83058156 -1.32718775  9.35907212],\n",
      " \t action=[899.93572965302417, -0.13409302410722523, 900.43320733665325, 0.031354853675801701], \n",
      " \t task.sim.pose=[-13.51296324  -4.50396333  35.6070703    2.08709599   2.09399498   0.        ]\n",
      "Episode =  915, total_reward =  170.71, , z=  35.30, v_z=   9.15, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74813885  2.69543239  9.15303787],\n",
      " \t action=[900.54999709467677, 0.14283119620492579, 899.78550339871981, 0.58265858672140169], \n",
      " \t task.sim.pose=[-13.19115438   5.22115572  35.29818536   2.12732006   2.0238579    0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  916, total_reward =  170.67, , z=  35.38, v_z=   9.27, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73317647  0.81138614  9.26679801],\n",
      " \t action=[899.86773450048156, -0.66688539222177123, 899.73452820259399, 0.3862673394323225], \n",
      " \t task.sim.pose=[-13.22349532   2.14635408  35.37993327   2.12330201   2.08878931   0.        ]\n",
      "Episode =  917, total_reward =  172.55, , z=  35.83, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8172849  -1.23296803  9.36800992],\n",
      " \t action=[900.35478645103342, 0.60754879493573333, 900.36577648132618, 0.1916564311883113], \n",
      " \t task.sim.pose=[-13.62109588  -4.33638878  35.83296205   2.13246054   2.14684423   0.        ]\n",
      "Episode =  918, total_reward =  171.00, , z=  35.52, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80268975 -0.7124044   9.32467339],\n",
      " \t action=[899.78817340053968, 0.17566205880955846, 900.5143388176881, -0.27249684691501991], \n",
      " \t task.sim.pose=[-13.42831248  -1.90405846  35.52429238   2.06980636   2.08257153   0.        ]\n",
      "Episode =  919, total_reward =  171.40, , z=  35.59, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82606709  0.69671335  9.31987139],\n",
      " \t action=[900.07093954148002, 0.26856597943877858, 900.27784958710004, 0.019127528518002007], \n",
      " \t task.sim.pose=[-13.56727164  -0.3089426   35.58910847   2.11889527   2.06834384   0.        ]\n",
      "Episode =  920, total_reward =  170.67, , z=  35.40, v_z=   9.29, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73391572  0.37534658  9.28725162],\n",
      " \t action=[899.88371564324666, 0.52993451039699957, 900.21946106257042, 0.36624687576841541], \n",
      " \t task.sim.pose=[-13.19586634   1.48940844  35.3990492    2.08780941   2.0869015    0.        ]\n",
      "Episode =  921, total_reward =  171.06, , z=  35.54, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82605648 -1.73440718  9.33919117],\n",
      " \t action=[899.87773018018174, -0.23711065761915054, 900.21071851398256, 0.034391213846742597], \n",
      " \t task.sim.pose=[-13.48494373  -4.9402941   35.53702997   2.08505712   2.09524817   0.        ]\n",
      "Episode =  922, total_reward =  171.25, , z=  35.50, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74565855  0.67040151  9.28588413],\n",
      " \t action=[900.33664251482162, -0.48501048234071314, 900.42136204485837, 0.66173462285453621], \n",
      " \t task.sim.pose=[-13.36013534   2.03211922  35.49621156   2.12338177   2.10623006   0.        ]\n",
      "Episode =  923, total_reward =  170.92, , z=  35.40, v_z=   9.24, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88531449 -3.72364896  9.24321533],\n",
      " \t action=[900.38345761238656, 0.44720451720759613, 900.40591616886547, 0.21972817448219448], \n",
      " \t task.sim.pose=[-13.76322926  -9.62961461  35.39933146   2.09139538   2.14243126   0.        ]\n",
      "Episode =  924, total_reward =  171.80, , z=  35.57, v_z=   9.23, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74904252  1.9108339   9.23157118],\n",
      " \t action=[899.81409021491527, 0.25716814013623251, 900.10501293209074, -0.20781967156625514], \n",
      " \t task.sim.pose=[-13.33767432   2.70303824  35.5741813    2.17311023   2.0919239    0.        ]\n",
      "Episode =  925, total_reward =  170.69, , z=  35.36, v_z=   9.23, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.91335401 -4.14182097  9.2261628 ],\n",
      " \t action=[900.43171404446559, -0.48007004394380864, 900.17461950113704, -0.75388003758854283], \n",
      " \t task.sim.pose=[-13.80768804 -11.43743243  35.36342595   2.07131764   2.13122395   0.        ]\n",
      "Episode =  926, total_reward =  171.07, , z=  35.54, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8148291  -0.33286447  9.33544509],\n",
      " \t action=[900.45475817146234, 0.054968462482109126, 899.2240920362733, -0.26990558101231055], \n",
      " \t task.sim.pose=[-13.43806396  -2.23827874  35.53963099   2.11066553   2.07558772   0.        ]\n",
      "Episode =  927, total_reward =  171.10, , z=  35.53, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81725891  0.31922411  9.32288302],\n",
      " \t action=[899.7964667750332, -0.16239705881135352, 900.50340541730372, -0.34492261138992936], \n",
      " \t task.sim.pose=[-13.50486239  -1.60044685  35.53016651   2.13632605   2.08391407   0.        ]\n",
      "Episode =  928, total_reward =  171.58, , z=  35.62, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78924074 -0.24795843  9.33099069],\n",
      " \t action=[899.96236130532725, -0.5795166246507274, 899.76036769388395, 0.50229939444427463], \n",
      " \t task.sim.pose=[-13.47084351  -1.49601896  35.62201334   2.12868583   2.11422411   0.        ]\n",
      "Episode =  929, total_reward =  171.75, , z=  35.66, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78031009 -0.42900621  9.34639035],\n",
      " \t action=[899.71216199217201, -0.32976526748273416, 900.08416010975486, 0.24724210535666555], \n",
      " \t task.sim.pose=[-13.40013844  -1.87028435  35.66235772   2.11548098   2.11247691   0.        ]\n",
      "Episode =  930, total_reward =  171.46, , z=  35.61, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78267566 -0.39734531  9.33630649],\n",
      " \t action=[900.05320722802162, -0.57815498911683649, 900.23675618243726, -0.19301709933988825], \n",
      " \t task.sim.pose=[-13.38411304  -0.71516316  35.60539961   2.07111763   2.08107711   0.        ]\n",
      "Episode =  931, total_reward =  171.61, , z=  35.60, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76254485 -1.14057236  9.31400679],\n",
      " \t action=[899.64825445477538, -0.42867403399042592, 900.23723618119675, -0.28463579205573875], \n",
      " \t task.sim.pose=[-13.3749615   -1.37842294  35.59928233   2.08661954   2.12338519   0.        ]\n",
      "Episode =  932, total_reward =  171.47, , z=  35.61, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78862125 -0.99549692  9.32913325],\n",
      " \t action=[899.79559055900802, -0.11796159571338877, 899.54978290444046, -0.074542340252533534], \n",
      " \t task.sim.pose=[-13.43568806  -3.11941141  35.6141747    2.11162956   2.12623531   0.        ]\n",
      "Episode =  933, total_reward =  171.26, , z=  35.57, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79719339 -1.067407    9.32985192],\n",
      " \t action=[899.14979381183446, 0.11397501016269129, 900.26790057073572, 0.30725218176106617], \n",
      " \t task.sim.pose=[-13.4794798   -3.25481597  35.56784269   2.10084782   2.12669528   0.        ]\n",
      "Episode =  934, total_reward =  172.32, , z=  35.73, v_z=   9.31, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80005112 -2.14343322  9.31055091],\n",
      " \t action=[899.92774911270612, 0.34926117332331991, 900.43425302067851, -0.28660835806851537], \n",
      " \t task.sim.pose=[-13.61410064  -4.76892256  35.73377581   2.12852292   2.1790787    0.        ]\n",
      "Episode =  935, total_reward =  171.13, , z=  35.45, v_z=   9.26, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74196295  1.22413882  9.25536079],\n",
      " \t action=[900.0782757336043, 0.55751768489296483, 900.25259706947895, 1.1440802082138339], \n",
      " \t task.sim.pose=[-13.31533347   2.95442293  35.4474912    2.12060737   2.09224155   0.        ]\n",
      "Episode =  936, total_reward =  170.89, , z=  35.52, v_z=   9.35, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86315825 -1.91538463  9.35118139],\n",
      " \t action=[899.88244572928716, -0.075111031769974163, 899.95190105007111, -0.024493500220147263], \n",
      " \t task.sim.pose=[-13.57710843  -6.38603244  35.51636702   2.07181459   2.08171013   0.        ]\n",
      "Episode =  937, total_reward =  171.58, , z=  35.64, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81453506 -0.88075835  9.35391452],\n",
      " \t action=[900.01402220704017, 0.94837981715246833, 899.46523979247343, 0.04291615920106364], \n",
      " \t task.sim.pose=[-13.46448501  -2.70638338  35.64335646   2.09930367   2.08260979   0.        ]\n",
      "Episode =  938, total_reward =  172.39, , z=  35.78, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76199511 -0.35842214  9.35119229],\n",
      " \t action=[900.24096838932462, 0.42218065709959612, 900.29341503057333, 0.33581247084533117], \n",
      " \t task.sim.pose=[-13.40875981  -1.42114601  35.78001537   2.12328564   2.13627026   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  939, total_reward =  171.76, , z=  35.61, v_z=   9.30, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7451805   0.63780905  9.29835894],\n",
      " \t action=[900.18458486913005, 0.10599100134637918, 899.7783486963059, 0.14187702118290335], \n",
      " \t task.sim.pose=[-13.36021113   1.61763173  35.60853525   2.11652305   2.1104197    0.        ]\n",
      "Episode =  940, total_reward =  170.10, , z=  35.35, v_z=   9.32, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85392225 -1.98232761  9.32055668],\n",
      " \t action=[899.67346515713632, -0.016155921681603264, 900.14130864615402, 0.12379773058448057], \n",
      " \t task.sim.pose=[-13.54744531  -6.64586425  35.34690558   2.08302261   2.09663146   0.        ]\n",
      "Episode =  941, total_reward =  170.33, , z=  35.21, v_z=   9.16, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.71928495  2.28273863  9.16431294],\n",
      " \t action=[899.51524095291529, -0.95360548264141465, 900.43926506952448, -0.72054731784373227], \n",
      " \t task.sim.pose=[-13.21035476   4.93068962  35.2126505    2.1321919    2.07798546   0.        ]\n",
      "Episode =  942, total_reward =  171.47, , z=  35.61, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81532823 -1.32006578  9.33521815],\n",
      " \t action=[899.94294714398063, 0.5560822747612777, 899.86057616463256, -0.58179820185761577], \n",
      " \t task.sim.pose=[-13.52979438  -3.74534972  35.60997509   2.09996576   2.11564804   0.        ]\n",
      "Episode =  943, total_reward =  172.12, , z=  35.76, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82990814 -1.35432046  9.36868886],\n",
      " \t action=[900.05732821925699, -0.16179024374935719, 900.09101600870736, -0.42483300187799722], \n",
      " \t task.sim.pose=[-13.5939138   -4.72793962  35.76268953   2.11052417   2.12092836   0.        ]\n",
      "Episode =  944, total_reward =  171.04, , z=  35.49, v_z=   9.27, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80081273 -2.61667408  9.26743264],\n",
      " \t action=[899.34510091175002, -0.43176651123472082, 899.88268994076407, 0.058706856002999658], \n",
      " \t task.sim.pose=[-13.43328174  -5.58759396  35.49094392   2.06406527   2.1281856    0.        ]\n",
      "Episode =  945, total_reward =  171.47, , z=  35.54, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74175507  1.08957804  9.28321421],\n",
      " \t action=[900.5403598981419, 0.38053304693019135, 899.87325907645891, -0.14131042856205672], \n",
      " \t task.sim.pose=[-13.22913877   2.67963084  35.53992184   2.11779284   2.06916681   0.        ]\n",
      "Episode =  946, total_reward =  170.66, , z=  35.33, v_z=   9.18, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.88239334 -4.53456813  9.18164335],\n",
      " \t action=[899.72554030491585, 0.63255335004098279, 900.16571829195902, 0.31572777417596992], \n",
      " \t task.sim.pose=[-13.59554733 -11.33183004  35.32709607   2.0306746    2.10723466   0.        ]\n",
      "Episode =  947, total_reward =  171.12, , z=  35.37, v_z=   9.16, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.73149784  2.51995124  9.1632269 ],\n",
      " \t action=[899.23037796692279, -0.14268702107245429, 900.25393726233426, 0.05197923591304171], \n",
      " \t task.sim.pose=[-13.26224539   4.60168802  35.37460989   2.14002554   2.07171082   0.        ]\n",
      "Episode =  948, total_reward =  171.80, , z=  35.67, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80273231  0.10683342  9.33968967],\n",
      " \t action=[899.90766421909791, 0.35746069893443577, 899.82889507852008, 0.2076132919727931], \n",
      " \t task.sim.pose=[-13.49435308  -1.58189942  35.66989204   2.15233498   2.10239923   0.        ]\n",
      "Episode =  949, total_reward =  170.73, , z=  35.20, v_z=   9.08, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.72121701  3.23040001  9.07696384],\n",
      " \t action=[900.47284398944464, -0.2189127777731486, 899.7077057676787, -0.1088355088657619], \n",
      " \t task.sim.pose=[-13.25492469   6.77584124  35.19644353   2.15025059   2.06179048   0.        ]\n",
      "Episode =  950, total_reward =  171.65, , z=  35.63, v_z=   9.31, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80857984 -2.10004968  9.30999936],\n",
      " \t action=[899.97719634551652, 0.076930318168288325, 900.88173456009122, -0.39513679096094922], \n",
      " \t task.sim.pose=[-13.55200373  -5.12893308  35.63167292   2.08936446   2.14500689   0.        ]\n",
      "Episode =  951, total_reward =  171.26, , z=  35.59, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82882675 -0.36745351  9.35047334],\n",
      " \t action=[900.26183114591527, 0.0066652620227147241, 899.43181342877972, 0.3292930130426715], \n",
      " \t task.sim.pose=[-13.45591232  -2.38544757  35.58674782   2.10767433   2.05778971   0.        ]\n",
      "Episode =  952, total_reward =  171.07, , z=  35.55, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83300345 -1.62268285  9.35532234],\n",
      " \t action=[899.57377066347669, -0.319987283722732, 900.4960973367364, 0.089984558067704556], \n",
      " \t task.sim.pose=[-13.47636795  -5.30501196  35.54944915   2.07545256   2.08739289   0.        ]\n",
      "Episode =  953, total_reward =  172.73, , z=  35.88, v_z=   9.37, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81128816  0.18623879  9.36851118],\n",
      " \t action=[899.79616686981819, 0.63035257268185663, 900.06077150403098, 0.44071307110462976], \n",
      " \t task.sim.pose=[-13.53167715  -1.464175    35.88290003   2.13027355   2.09174991   0.        ]\n",
      "Episode =  954, total_reward =  171.16, , z=  35.50, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.85583264 -3.00322063  9.28895076],\n",
      " \t action=[900.15589087178796, -0.088297678071632635, 899.518548039547, -0.57992322777383076], \n",
      " \t task.sim.pose=[-13.62854454  -7.81886755  35.50491038   2.08674244   2.12673215   0.        ]\n",
      "Episode =  955, total_reward =  171.10, , z=  35.45, v_z=   9.26, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77168158  1.32158745  9.26239847],\n",
      " \t action=[901.00083640295361, -0.52232637048993991, 900.31374315093478, -0.38389380210951562], \n",
      " \t task.sim.pose=[-13.41869888   2.07441488  35.45099085   2.12451501   2.08144321   0.        ]\n",
      "Episode =  956, total_reward =  170.52, , z=  35.34, v_z=   9.22, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79157051 -2.83928873  9.22022426],\n",
      " \t action=[899.32605784146483, 0.093066534412786575, 900.31747564911291, -0.058894765682528438], \n",
      " \t task.sim.pose=[-13.42947077  -5.54709883  35.34433595   2.06365847   2.14894534   0.        ]\n",
      "Episode =  957, total_reward =  170.35, , z=  35.33, v_z=   9.27, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.90965692 -3.62043188  9.27035029],\n",
      " \t action=[900.08036976433141, -0.56711456887247758, 900.12774657619332, 0.019539525138345004], \n",
      " \t task.sim.pose=[-13.7255078  -10.48254913  35.33323575   2.0536947    2.10455369   0.        ]\n",
      "Episode =  958, total_reward =  171.70, , z=  35.59, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76527682  1.12669963  9.2841213 ],\n",
      " \t action=[899.85830170625013, 0.012766331588501476, 900.1623620107913, 0.11383042977970959], \n",
      " \t task.sim.pose=[-13.43037096   1.6804653   35.58919657   2.14741052   2.09921353   0.        ]\n",
      "Episode =  959, total_reward =  172.05, , z=  35.71, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76456124  0.05842102  9.32574361],\n",
      " \t action=[899.91780403068435, -0.043293181242519935, 900.80715869320704, 0.17629301715888054], \n",
      " \t task.sim.pose=[-13.41680786   0.26743218  35.70633017   2.10329626   2.1098336    0.        ]\n",
      "Episode =  960, total_reward =  170.84, , z=  35.48, v_z=   9.32, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78593063 -0.04725666  9.31651474],\n",
      " \t action=[899.53343915067762, 0.34334847926810302, 899.89450404137563, -0.1844927518956927], \n",
      " \t task.sim.pose=[-13.36663108  -0.80736766  35.47660839   2.09765456   2.07917131   0.        ]\n",
      "Episode =  961, total_reward =  171.27, , z=  35.46, v_z=   9.23, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74937934  1.91476618  9.23020243],\n",
      " \t action=[900.03273914128215, -0.028729421625495966, 900.44489945742328, -0.50704574272502823], \n",
      " \t task.sim.pose=[-13.30572196   3.13694507  35.46018646   2.13469494   2.07151007   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  962, total_reward =  170.58, , z=  35.41, v_z=   9.33, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.91186821 -2.92466202  9.32793436],\n",
      " \t action=[899.69742267916843, -0.10707900190361969, 900.47715339091758, -0.1446728051363626], \n",
      " \t task.sim.pose=[-13.7294458   -9.91687521  35.40766718   2.10015838   2.09890952   0.        ]\n",
      "Episode =  963, total_reward =  171.29, , z=  35.48, v_z=   9.25, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.74156992  1.20264483  9.24931962],\n",
      " \t action=[899.75835690100814, 0.3915186121337218, 899.77163072894791, 0.03711163001462997], \n",
      " \t task.sim.pose=[-13.37265872   3.00678384  35.47961135   2.11795302   2.10627188   0.        ]\n",
      "Episode =  964, total_reward =  172.06, , z=  35.73, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82206747 -2.36958447  9.33042829],\n",
      " \t action=[900.0914065590888, -0.1417645172925176, 900.49814273674531, -0.032093507310682612], \n",
      " \t task.sim.pose=[-13.57017063  -5.8866294   35.72524729   2.08346208   2.13376112   0.        ]\n",
      "Episode =  965, total_reward =  170.84, , z=  35.45, v_z=   9.28, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78831488  0.94383172  9.28065947],\n",
      " \t action=[899.76121641329576, 0.27806079504939729, 899.42074837543259, -0.0014286862574837966], \n",
      " \t task.sim.pose=[-13.39630377   0.51229332  35.44628194   2.14539774   2.07365214   0.        ]\n",
      "Episode =  966, total_reward =  171.25, , z=  35.55, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77282237 -0.07902089  9.31915599],\n",
      " \t action=[900.4359617536054, -0.73913837683665673, 899.69128818359081, -0.10457558272605438], \n",
      " \t task.sim.pose=[-13.35915071   0.31700025  35.5524953    2.08060293   2.0801683    0.        ]\n",
      "Episode =  967, total_reward =  171.03, , z=  35.50, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81472325 -2.06757791  9.31737349],\n",
      " \t action=[900.55648489558871, 0.023397342448279984, 899.80752888314225, 0.49776505057160436], \n",
      " \t task.sim.pose=[-13.48491896  -5.61129411  35.49766698   2.1042976    2.13107987   0.        ]\n",
      "Episode =  968, total_reward =  170.98, , z=  35.49, v_z=   9.28, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80869725  0.82708806  9.28480894],\n",
      " \t action=[899.71569561029946, -0.50568625810783019, 899.27060449213161, 0.055589661879491936], \n",
      " \t task.sim.pose=[-13.46299159  -0.21253188  35.48873641   2.1539307    2.07229752   0.        ]\n",
      "Episode =  969, total_reward =  171.42, , z=  35.62, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80232482 -0.83164966  9.34361711],\n",
      " \t action=[899.54005446162535, 0.070270921210518394, 899.47667869662951, -0.6502900725273838], \n",
      " \t task.sim.pose=[-13.43591052  -2.65522172  35.61597135   2.09185569   2.09098224   0.        ]\n",
      "Episode =  970, total_reward =  171.59, , z=  35.65, v_z=   9.36, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86701608 -2.41854851  9.35943968],\n",
      " \t action=[900.12527168023053, -0.41211012936903746, 899.82626093901308, 0.4896991646534668], \n",
      " \t task.sim.pose=[-13.57696973  -7.54884     35.65063993   2.06876622   2.0888222    0.        ]\n",
      "Episode =  971, total_reward =  171.53, , z=  35.57, v_z=   9.29, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76172042  0.88536085  9.29338372],\n",
      " \t action=[899.80409537385856, -0.34585048304299576, 900.31767014483557, 0.043096093642067207], \n",
      " \t task.sim.pose=[-13.34477017   1.41416661  35.56815986   2.13107398   2.08744626   0.        ]\n",
      "Episode =  972, total_reward =  172.35, , z=  35.78, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.7897267   0.52165651  9.3407572 ],\n",
      " \t action=[900.39845582273904, -0.25769030861700171, 900.08155369937231, 0.10087648527950421], \n",
      " \t task.sim.pose=[-13.48062171  -0.6990252   35.77536114   2.14864467   2.10191048   0.        ]\n",
      "Episode =  973, total_reward =  170.22, , z=  35.20, v_z=   9.19, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.71562286  1.96079121  9.18544318],\n",
      " \t action=[900.31273548819445, -0.40373988811332273, 900.29856476993245, -0.5786392468657835], \n",
      " \t task.sim.pose=[-13.21620784   5.31789502  35.20283799   2.11933074   2.07954825   0.        ]\n",
      "Episode =  974, total_reward =  171.04, , z=  35.53, v_z=   9.33, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81679925  0.03741797  9.32525839],\n",
      " \t action=[900.15812491880763, 0.00035816512967300207, 899.68751957942561, -0.55363687006432616], \n",
      " \t task.sim.pose=[-13.45405761  -1.26430225  35.53153108   2.09787735   2.06003337   0.        ]\n",
      "Episode =  975, total_reward =  172.19, , z=  35.78, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81186061 -1.79739345  9.37066821],\n",
      " \t action=[900.72720583421824, 0.21436614314536429, 900.21410164144095, 0.41494329799766283], \n",
      " \t task.sim.pose=[-13.48782267  -4.85151217  35.7821788    2.06781014   2.11170046   0.        ]\n",
      "Episode =  976, total_reward =  171.05, , z=  35.52, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.76627641  0.0404627   9.31703955],\n",
      " \t action=[899.72152999815364, 0.006759974722297668, 899.54528003206678, -0.73587149773663629], \n",
      " \t task.sim.pose=[-13.27347233  -0.4617155   35.51787518   2.10167477   2.07798329   0.        ]\n",
      "Episode =  977, total_reward =  170.89, , z=  35.51, v_z=   9.33, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8115451  -1.63765937  9.33158145],\n",
      " \t action=[899.72255542127471, 0.31040256322122206, 899.82835287932073, -0.076350052649404074], \n",
      " \t task.sim.pose=[-13.39858528  -4.68039324  35.51120326   2.06683926   2.0890092    0.        ]\n",
      "Episode =  978, total_reward =  171.59, , z=  35.64, v_z=   9.35, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81020586 -1.10982246  9.35138127],\n",
      " \t action=[900.3908599360077, 0.62054365679628709, 899.72768448357635, 0.20754015280331922], \n",
      " \t task.sim.pose=[-13.44345806  -3.1293124   35.63989846   2.10127747   2.0896015    0.        ]\n",
      "Episode =  979, total_reward =  171.83, , z=  35.71, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84347274 -1.15721867  9.37206946],\n",
      " \t action=[900.32164960962461, -0.58121990546472757, 900.51467355517934, -0.77547873266147083], \n",
      " \t task.sim.pose=[-13.62320697  -4.63461109  35.70894886   2.11472588   2.10577801   0.        ]\n",
      "Episode =  980, total_reward =  172.56, , z=  35.82, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8855757  -2.90002617  9.36615513],\n",
      " \t action=[899.8569826645562, 0.34433521705899794, 899.77056001759661, 0.40857386714461502], \n",
      " \t task.sim.pose=[-13.7496411   -9.16904185  35.81716314   2.11598969   2.13202241   0.        ]\n",
      "Episode =  981, total_reward =  172.75, , z=  35.87, v_z=   9.38, \n",
      " \t score = 2.06 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.82444321 -1.80312044  9.37632073],\n",
      " \t action=[900.26169905211987, 0.072605737811918758, 899.66778721179594, 0.49261689602954117], \n",
      " \t task.sim.pose=[-13.58324789  -5.94007164  35.87072465   2.14165321   2.14558416   0.        ]\n",
      "Episode =  982, total_reward =  169.95, , z=  35.33, v_z=   9.33, \n",
      " \t score = 2.02 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81912077 -0.56064214  9.33105572],\n",
      " \t action=[900.35354027141864, 0.36558060946781457, 900.54908293139761, -0.69961634906195413], \n",
      " \t task.sim.pose=[-13.29062238  -2.80650247  35.33008585   2.06454295   2.03025783   0.        ]\n",
      "Episode =  983, total_reward =  171.82, , z=  35.68, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.79105826 -0.43835754  9.34378622],\n",
      " \t action=[900.10276477892069, -0.1150717026760604, 900.29813936412199, -0.063164286686288151], \n",
      " \t task.sim.pose=[-13.46315246  -2.1670466   35.6807575    2.11387816   2.11403881   0.        ]\n",
      "Episode =  984, total_reward =  170.73, , z=  35.40, v_z=   9.27, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78366256  1.00854301  9.27411985],\n",
      " \t action=[900.60144510983923, -0.070232625530112419, 899.77322768017746, 0.64635865533082226], \n",
      " \t task.sim.pose=[-13.40704114   2.06218571  35.40442497   2.09366204   2.05770642   0.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode =  985, total_reward =  170.95, , z=  35.50, v_z=   9.32, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86792157 -2.54908202  9.32168791],\n",
      " \t action=[900.56108022598926, 0.24756797036650102, 899.49723871163769, 0.19424677298027704], \n",
      " \t task.sim.pose=[-13.62111855  -7.40053741  35.49550715   2.08330619   2.09822181   0.        ]\n",
      "Episode =  986, total_reward =  170.79, , z=  35.32, v_z=   9.20, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.71312755  1.74836645  9.19750564],\n",
      " \t action=[899.82886804044961, -0.14683940085073102, 899.73576477876202, 0.64164267509226347], \n",
      " \t task.sim.pose=[-13.27929023   4.77589006  35.32084913   2.12807004   2.10857983   0.        ]\n",
      "Episode =  987, total_reward =  171.77, , z=  35.67, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81428973 -2.00479912  9.34355543],\n",
      " \t action=[900.04998368593567, -0.2075477334003169, 899.88280355631946, -0.42969988555735711], \n",
      " \t task.sim.pose=[-13.47592117  -5.02896662  35.67469535   2.08329929   2.11344043   0.        ]\n",
      "Episode =  988, total_reward =  172.21, , z=  35.77, v_z=   9.37, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86362422 -2.43907207  9.37164754],\n",
      " \t action=[899.64252297419262, 0.094507245960007452, 900.31756561018972, 0.59358470110413997], \n",
      " \t task.sim.pose=[-13.65290783  -7.70424287  35.76779748   2.10786623   2.12070762   0.        ]\n",
      "Episode =  989, total_reward =  172.06, , z=  35.70, v_z=   9.33, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77311197 -0.03932572  9.32931354],\n",
      " \t action=[899.55728558134615, 0.84299158094680038, 900.43937353848332, -0.081426127914674018], \n",
      " \t task.sim.pose=[-13.47617875  -0.52464056  35.70359078   2.12387943   2.12498119   0.        ]\n",
      "Episode =  990, total_reward =  171.16, , z=  35.48, v_z=   9.27, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.89607866 -3.8875403   9.26613674],\n",
      " \t action=[899.78763697157012, -0.30561632460389226, 899.78858863902406, -0.020467268906662117], \n",
      " \t task.sim.pose=[-13.74550388 -11.11333561  35.48178164   2.08749102   2.13704675   0.        ]\n",
      "Episode =  991, total_reward =  170.55, , z=  35.39, v_z=   9.28, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80628832 -2.34744042  9.27739759],\n",
      " \t action=[900.27187022367309, 0.21272733058096213, 900.52206490530307, 0.51073848414850231], \n",
      " \t task.sim.pose=[-13.43668843  -4.97328071  35.3860849    2.06085615   2.11713582   0.        ]\n",
      "Episode =  992, total_reward =  170.72, , z=  35.42, v_z=   9.28, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.90486664 -3.48812168  9.2846143 ],\n",
      " \t action=[900.27001997303796, -0.2417330050029769, 900.61972722662608, -0.41710425486405672], \n",
      " \t task.sim.pose=[-13.76164172 -10.27689882  35.42377221   2.05797803   2.114267     0.        ]\n",
      "Episode =  993, total_reward =  170.45, , z=  35.36, v_z=   9.29, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.86170161 -2.93325711  9.28881311],\n",
      " \t action=[899.53197127516341, -0.43870056037157085, 899.54122693708246, 0.11376038207027608], \n",
      " \t task.sim.pose=[-13.56430213  -8.60367811  35.36108547   2.09421716   2.11805152   0.        ]\n",
      "Episode =  994, total_reward =  171.36, , z=  35.60, v_z=   9.34, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.84008917 -1.51287444  9.33887576],\n",
      " \t action=[899.87625791554888, -0.12753738848543339, 899.66276918325968, -0.97094019569001033], \n",
      " \t task.sim.pose=[-13.64711838  -4.63496987  35.60215448   2.09004486   2.11915867   0.        ]\n",
      "Episode =  995, total_reward =  171.38, , z=  35.49, v_z=   9.25, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.8920724  -3.99717435  9.248905  ],\n",
      " \t action=[900.3260664926047, -0.51594034991019444, 899.69626516568974, 0.52474485390044734], \n",
      " \t task.sim.pose=[-13.79149927 -11.17639812  35.49336107   2.11363366   2.16390085   0.        ]\n",
      "Episode =  996, total_reward =  171.87, , z=  35.69, v_z=   9.32, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.83834295 -2.62251435  9.32041629],\n",
      " \t action=[899.23272647538954, 0.022570472779772185, 900.51567934297202, -0.35321469803536154], \n",
      " \t task.sim.pose=[-13.59311924  -6.19118411  35.68730318   2.04430163   2.1139395    0.        ]\n",
      "Episode =  997, total_reward =  171.95, , z=  35.72, v_z=   9.35, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.80652144 -0.98842242  9.35335192],\n",
      " \t action=[900.33892396011845, -0.067327394705509996, 899.79860615083373, 0.00061057036473798065], \n",
      " \t task.sim.pose=[-13.50609971  -2.26820173  35.71502684   2.07597623   2.09445398   0.        ]\n",
      "Episode =  998, total_reward =  172.02, , z=  35.70, v_z=   9.34, \n",
      " \t score = 2.05 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.78126662 -0.75077099  9.34083319],\n",
      " \t action=[900.49575017429231, -0.10489030563497273, 899.74046253128574, -0.38057669936486105], \n",
      " \t task.sim.pose=[-13.48223697  -2.35834193  35.69946865   2.15815707   2.14571127   0.        ]\n",
      "Episode =  999, total_reward =  170.94, , z=  35.50, v_z=   9.32, \n",
      " \t score = 2.03 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.81301176 -1.95335141  9.32227119],\n",
      " \t action=[900.65918804846058, -0.019930649191600612, 900.38052239430272, 0.090709405372613489], \n",
      " \t task.sim.pose=[-13.45173258  -5.19683697  35.50344265   2.06915086   2.10899907   0.        ]\n",
      "Episode = 1000, total_reward =  171.39, , z=  35.53, v_z=   9.27, \n",
      " \t score = 2.04 (best = 2.95), total_steps =  84, \n",
      " \t task.sim.v=[-1.77687552  1.48816232  9.26664944],\n",
      " \t action=[899.41150936665451, -0.70503166396426586, 900.01711946355476, 0.29281863425116572], \n",
      " \t task.sim.pose=[-13.41212504   2.38190708  35.52501232   2.10852067   2.06772322   0.        ]\n"
     ]
    }
   ],
   "source": [
    "## TODO: Train your agent here.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from task import TaskTakeOff\n",
    "from agents.agent import DDPG_Agent\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "num_episodes = 1000\n",
    "task = TaskTakeOff()\n",
    "agent = DDPG_Agent(task)\n",
    "\n",
    "period_plot = 1\n",
    "history = pd.DataFrame(columns=['score', 'best_score', 'total_reward', 'time', \\\n",
    "                                'x', 'y', 'z', 'phi', 'theta', 'psi', \\\n",
    "                                'x_velocity', 'y_velocity', 'z_velocity', \\\n",
    "                                'phi_velocity', 'theta_velocity', 'psi_velocity'])\n",
    "\n",
    "history.index.name = 'episode'\n",
    "start_time = time.time()\n",
    "\n",
    "for i_episode in range(1, num_episodes+1):\n",
    "    # reset enviroment\n",
    "    state = agent.reset_episode()\n",
    "    total_rewards = 0\n",
    "    total_steps = 0\n",
    "    \n",
    "    while True:\n",
    "        # get next action\n",
    "        action = agent.act(state)\n",
    "        \n",
    "        # step to next state and get reward\n",
    "        next_state, reward, done = task.step(action)\n",
    "        \n",
    "        # update agent's weights\n",
    "        agent.step(action, reward, next_state, done)\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        if done:\n",
    "            print(\"Episode = {:4d}, total_reward = {:7.2f}, , z={:7.2f}, v_z={:7.2f}, \\n \\t score = {:3.2f} (best = {:3.2f}), total_steps = {:3d}, \\n \\t task.sim.v={},\\n \\t action={}, \\n \\t task.sim.pose={}\".format(\n",
    "                    i_episode, agent.total_reward, task.sim.pose[2], task.sim.v[2], agent.score, agent.best_score, agent.count, task.sim.v, action, task.sim.pose, end=\" \"))\n",
    "            sys.stdout.flush()\n",
    "            break     \n",
    "    \n",
    "    if i_episode % period_plot == 0:\n",
    "        history.loc[i_episode] = [agent.score, agent.best_score, agent.total_reward, task.sim.time, \\\n",
    "                                  task.sim.pose[0], task.sim.pose[1], task.sim.pose[2], task.sim.pose[3], task.sim.pose[4], task.sim.pose[5], \\\n",
    "                                  task.sim.v[0], task.sim.v[1], task.sim.v[2], \\\n",
    "                                  task.sim.angular_v[0], task.sim.angular_v[1], task.sim.angular_v[2]]\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time = 1103.7481787204742, time per episode = 1.1037481787204741\n",
      "logs/log-[episodes:1000][<actor>lr:0.001][<critic>lr:0.001][<noise>mu:0_sigma:0.2_theta:0.15][<algorithm>gamma:0.99_tau:0.35].csv\n"
     ]
    }
   ],
   "source": [
    "# print average time\n",
    "print('total time = {}, time per episode = {}'.format(\n",
    "        end_time-start_time, float(end_time-start_time) / float(num_episodes)))\n",
    "\n",
    "# save log to file\n",
    "import os\n",
    "dir_name = './logs/'\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "    \n",
    "filename = 'logs/log-[episodes:{}]{}.csv'.format(num_episodes, str(agent))\n",
    "history.to_csv(filename)\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Plot the Rewards\n",
    "\n",
    "Once you are satisfied with your performance, plot the episode rewards, either from a single run, or averaged over multiple runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'episode')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f02394dcda0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TODO: Plot the rewards.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# ax = history.iloc[:, 0:1].plot()\n",
    "ax = history['total_reward'].plot()\n",
    "ax.set_xlabel('episode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average reward over the last 10 episodes: 152.55\n",
      "average height over the last 10 episodes: 32.81\n",
      "average x over the last 10 episodes: -12.40\n",
      "average y over the last 10 episodes: -2.28\n"
     ]
    }
   ],
   "source": [
    "## print statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# # load data\n",
    "file_names = []\n",
    "\n",
    "dir_name = './logs/'\n",
    "\n",
    "for f in file_names:\n",
    "    print(f.split('\\['))\n",
    "file_name = 'log-[episodes:1000][<actor>lr:0.001][<critic>lr:0.001][<noise>mu:0_sigma:0.2_theta:0.15][<algorithm>gamma:0.99_tau:0.35][run:1].csv'\n",
    "history = pd.read_csv(dir_name + file_name)\n",
    "history.set_index('episode')\n",
    "\n",
    "# plot data\n",
    "# ax = history['z'][0:300].plot()\n",
    "# ax.set_ylabel('total reward')\n",
    "# ax.set_xlabel('episode')\n",
    "\n",
    "print('average reward over the last 10 episodes: {:2.2f}'.format(history['total_reward'][:-10].mean()))\n",
    "print('average height over the last 10 episodes: {:2.2f}'.format(history['z'][:-10].mean()))\n",
    "print('average x over the last 10 episodes: {:2.2f}'.format(history['x'][:-10].mean()))\n",
    "print('average y over the last 10 episodes: {:2.2f}'.format(history['y'][:-10].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reflections\n",
    "\n",
    "**Question 1**: Describe the task that you specified in `task.py`.  How did you design the reward function?\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "I tried different combinations. Firstly, I penalize and reward upon distance in x-y-z plane as following:\n",
    "\n",
    "* reward = $ 1 - 0.3* \\sum (|Position_{current} - Position_{target}|)^2$\n",
    "\n",
    "However, it hardly can fly. Then I use complicate reward function. It reward velocity z and distance z. Morever, it contrains x-y distance for stability reason.\n",
    "* reward = $ -(D_{xy}/ 10.0)  + (z_{current} - z_{target} ) / 10.0 + (v_z) / 2.0 $\n",
    ", where  $D_{xy} = \\sqrt{ (\\sum Position_{current} - Position_{target})^2}$\n",
    "\n",
    "penalizae Euclidean distance in x-y-z plane. Things are getting better. Nonetheless, it is hard to converge.\n",
    "\n",
    "\n",
    "Lastly, I took mentor's advice posted in fourm. I only provide incentives to z-velocity and use tanh to bound the reward.\n",
    "* reward = tanh($v_{z}$)\n",
    "\n",
    "At first, the result was not good. After tweaking other parameters defined in agent, the reward converges."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**: Discuss your agent briefly, using the following questions as a guide:\n",
    "\n",
    "- What learning algorithm(s) did you try? What worked best for you?\n",
    "- What was your final choice of hyperparameters (such as $\\alpha$, $\\gamma$, $\\epsilon$, etc.)?\n",
    "- What neural network architecture did you use (if any)? Specify layers, sizes, activation functions, etc.\n",
    "\n",
    "**Answer**:\n",
    "- What learning algorithm(s) did you try? What worked best for you?\n",
    "\n",
    "I tried the DDPG (Deep Deterministic Policy Gradient) because it is recommendded in the project. I wish I could try another one after tweaking parameters for 2 weeks.\n",
    "\n",
    "\n",
    "- What was your final choice of hyperparameters (such as $\\alpha$, $\\gamma$, $\\epsilon$, etc.)?\n",
    "\n",
    "At first, I tried different exploration $theta$. By expecting the noise only, $theta$ is inversely related to variation, as shown in the local notebook ('agents/OUNoiseTest.ipynb'). However, it don't work. I also tried different learning rate between critic and actor as adapted in DDPG paper (Lilicrap 2016). Still it doesn't work. Finally, I tweek 'tau' from 0.01 to 0.35. And it produces good result. The other parameters are shown below:\n",
    "\n",
    "    * actor\n",
    "        - learning rate:0.001\n",
    "    * critic\n",
    "        - learning rate:0.001\n",
    "    * noise\n",
    "        - mu:0\n",
    "        - sigma:0.2\n",
    "        - theta:0.15\n",
    "    * algorithm\n",
    "        - gamma:0.99\n",
    "        - tau: 0.35\n",
    "\n",
    "- What neural network architecture did you use (if any)? Specify layers, sizes, activation functions, etc.\n",
    "\n",
    "I use the recommended architecture. Previously, I tried batch normalization and drop as the paper (Lilicrap 2016) did. Also I tweeked the number of neurons in every layer. Nonetheless it does not help the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: Using the episode rewards plot, discuss how the agent learned over time.\n",
    "\n",
    "- Was it an easy task to learn or hard?\n",
    "- Was there a gradual learning curve, or an aha moment?\n",
    "- How good was the final performance of the agent? (e.g. mean rewards over the last 10 episodes)\n",
    "\n",
    "**Answer**:\n",
    "- Was it an easy task to learn or hard?\n",
    "\n",
    "It's difficult to make drone lift vertically. Most of time, the networks stuck at bad minima. There are too many parameters to tweak. I read an [blog](https://medium.com/@BonsaiAI/deep-reinforcement-learning-models-tips-tricks-for-writing-reward-functions-a84fe525e8e0) talking about tricks and tips on reward function. But it does not help too much.\n",
    "\n",
    "- Was there a gradual learning curve, or an aha moment?\n",
    "\n",
    "It was aha moment that networks learn to fly.\n",
    "\n",
    "- How good was the final performance of the agent? (e.g. mean rewards over the last 10 episodes)\n",
    "\n",
    "I think the performance is not bad. At least, the drone take off. The mean reward over the last 10 episodes is 152.55. It is not the higheset one, but the average height is 32 which is above the starting point 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**: Briefly summarize your experience working on this project. You can use the following prompts for ideas.\n",
    "\n",
    "- What was the hardest part of the project? (e.g. getting started, plotting, specifying the task, etc.)\n",
    "- Did you find anything interesting in how the quadcopter or your agent behaved?\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "It is the hardest project through the entire deep learning nano-degree program. There are too many parameters to tweak including reward function. Additionally, taking the training time into consideration, it is a time-consuming project. I spent 2 weeks to check the parameters. What more frustrucated is that, most of the time, the experiment is hard to reproduce. The solution space is extremely narrow than GAN project. Despite of these, this project allows me to know more about reinforcement learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
